{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from folder  sink/plates_cups_and_bowls/plates\n",
      "sink:plates_cups_and_bowls:plates:Threshold_Bistro_Ceramic_Dinner_Plate_Ruby_Ring :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:plates:Threshold_Bistro_Ceramic_Dinner_Plate_Ruby_Ring'>\n",
      "sink:plates_cups_and_bowls:plates:Ecoforms_Plate_S20Avocado :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:plates:Ecoforms_Plate_S20Avocado'>\n",
      "sink:plates_cups_and_bowls:plates:Room_Essentials_Salad_Plate_Turquoise :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:plates:Room_Essentials_Salad_Plate_Turquoise'>\n",
      "sink:plates_cups_and_bowls:plates:Ecoforms_Plant_Plate_S11Turquoise :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:plates:Ecoforms_Plant_Plate_S11Turquoise'>\n",
      "Generating from folder  sink/plates_cups_and_bowls/cups\n",
      "sink:plates_cups_and_bowls:cups:Cole_Hardware_Mug_Classic_Blue :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:cups:Cole_Hardware_Mug_Classic_Blue'>\n",
      "sink:plates_cups_and_bowls:cups:Room_Essentials_Mug_White_Yellow :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:cups:Room_Essentials_Mug_White_Yellow'>\n",
      "sink:plates_cups_and_bowls:cups:Threshold_Porcelain_Coffee_Mug_All_Over_Bead_White :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:cups:Threshold_Porcelain_Coffee_Mug_All_Over_Bead_White'>\n",
      "Generating from folder  sink/plates_cups_and_bowls/bowls\n",
      "sink:plates_cups_and_bowls:bowls:Bradshaw_International_11642_7_Qt_MP_Plastic_Bowl :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:bowls:Bradshaw_International_11642_7_Qt_MP_Plastic_Bowl'>\n",
      "sink:plates_cups_and_bowls:bowls:Cole_Hardware_Bowl_Scirocco_YellowBlue :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:bowls:Cole_Hardware_Bowl_Scirocco_YellowBlue'>\n",
      "sink:plates_cups_and_bowls:bowls:Room_Essentials_Bowl_Turquiose :  <class 'spatial_scene_grammars_examples.dish_bin.grammar.sink:plates_cups_and_bowls:bowls:Room_Essentials_Bowl_Turquiose'>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.visualization import *\n",
    "from spatial_scene_grammars_examples.dish_bin.grammar import *\n",
    "from spatial_scene_grammars.parsing import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "from spatial_scene_grammars.parameter_estimation import *\n",
    "from spatial_scene_grammars.dataset import *\n",
    "\n",
    "import meshcat\n",
    "import meshcat.geometry as meshcat_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7004/static/\n",
      "Meshcat url:  http://127.0.0.1:7004/static/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom IPython.display import HTML\\nHTML(\"\"\"\\n    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\\n    <iframe src=\"{url}\" style=\"width: 100%; height: 100%; border: none\"></iframe>\\n</div>\\n\"\"\".format(url=meshcat_url))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'vis' not in globals():\n",
    "    vis = meshcat.Visualizer()\n",
    "vis.delete()\n",
    "base_url = \"http://127.0.0.1\"\n",
    "meshcat_url = base_url + \":\" + vis.url().split(\":\")[-1]\n",
    "print(\"Meshcat url: \", meshcat_url)\n",
    "'''\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
    "    <iframe src=\"{url}\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
    "</div>\n",
    "\"\"\".format(url=meshcat_url))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-26 20:28:13.045] [console] [warning] FindResource ignoring DRAKE_RESOURCE_ROOT='/home/gizatt/drake' because it does not contain a 'drake' subdirectory.\n"
     ]
    }
   ],
   "source": [
    "# Convert dataset to observed node sets (caching output) and draw a few examples.\n",
    "\n",
    "RECONVERT_DATASET = True\n",
    "DATASET_YAML_FILE = \"sink/saved_scenes.yaml\"\n",
    "DATASET_SAVE_FILE = \"observed_node_sets.dat\"\n",
    "#DATASET_YAML_FILE = \"sink/saved_outlier_scenes.yaml\"\n",
    "#DATASET_SAVE_FILE = \"observed_outlier_node_sets.dat\"\n",
    "\n",
    "if RECONVERT_DATASET or not os.path.exists(DATASET_SAVE_FILE):\n",
    "    type_map = {\n",
    "        \"bin\": DishBin\n",
    "    }\n",
    "    model_map = {\n",
    "    }\n",
    "    for model_type_set in [PlateModels, CupModels, BowlModels]:\n",
    "        for model_type in model_type_set:\n",
    "            # Have to cut off the \"sink\" folder to match model names;\n",
    "            # dataset management is ugly and should get reorganized...\n",
    "            model_map[os.path.join(*model_type.sdf.split(\"/\")[1:])] = model_type\n",
    "    observed_node_sets = convert_scenes_yaml_to_observed_nodes(DATASET_YAML_FILE, type_map, model_map)\n",
    "    print(\"Saving...\")\n",
    "    with open(DATASET_SAVE_FILE, \"wb\") as f:\n",
    "        pickle.dump(observed_node_sets, f)\n",
    "\n",
    "print(\"Loading...\")\n",
    "with open(DATASET_SAVE_FILE, \"rb\") as f:\n",
    "    observed_node_sets = pickle.load(f)\n",
    "\n",
    "draw_scene_tree_contents_meshcat(\n",
    "    SceneTree.make_from_observed_nodes(observed_node_sets[0]),\n",
    "    zmq_url=vis.window.zmq_url, prefix=\"observed/contents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DishBin': 30, 'sink:plates_cups_and_bowls:plates:Threshold_Bistro_Ceramic_Dinner_Plate_Ruby_Ring': 12, 'sink:plates_cups_and_bowls:plates:Ecoforms_Plate_S20Avocado': 12, 'sink:plates_cups_and_bowls:plates:Room_Essentials_Salad_Plate_Turquoise': 21, 'sink:plates_cups_and_bowls:plates:Ecoforms_Plant_Plate_S11Turquoise': 0, 'sink:plates_cups_and_bowls:cups:Cole_Hardware_Mug_Classic_Blue': 12, 'sink:plates_cups_and_bowls:cups:Room_Essentials_Mug_White_Yellow': 12, 'sink:plates_cups_and_bowls:cups:Threshold_Porcelain_Coffee_Mug_All_Over_Bead_White': 14, 'sink:plates_cups_and_bowls:bowls:Bradshaw_International_11642_7_Qt_MP_Plastic_Bowl': 9, 'sink:plates_cups_and_bowls:bowls:Cole_Hardware_Bowl_Scirocco_YellowBlue': 10, 'sink:plates_cups_and_bowls:bowls:Room_Essentials_Bowl_Turquiose': 8}\n"
     ]
    }
   ],
   "source": [
    "total_of_each_type = {\"DishBin\": 0}\n",
    "for model_type_set in [PlateModels, CupModels, BowlModels]:\n",
    "    for model_type in model_type_set:\n",
    "        total_of_each_type[model_type.__name__] = 0\n",
    "for observed_nodes in observed_node_sets:\n",
    "    for node in observed_nodes:\n",
    "        total_of_each_type[type(node).__name__] += 1\n",
    "print(total_of_each_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Detaching BinghamDistribution parameters.\n",
      "WARNING:root:Prior over parameters of WorldFrameBinghamRotationRule are Deltas.\n"
     ]
    }
   ],
   "source": [
    "# Draw a random sample from the grammar with its initial params and visualize it.\n",
    "#torch.random.manual_seed(5)\n",
    "\n",
    "pyro.set_rng_seed(42)\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = DishBin,\n",
    "    root_node_tf = drake_tf_to_torch_tf(RigidTransform(p=[0.5, 0., 0.]))\n",
    ")\n",
    "\n",
    "sampled_tree = grammar.sample_tree(detach=True)\n",
    "observed_nodes = sampled_tree.get_observed_nodes()\n",
    "\n",
    "vis[\"sample\"].delete()\n",
    "draw_scene_tree_contents_meshcat(sampled_tree, zmq_url=vis.window.zmq_url, prefix=\"sample/contents\")\n",
    "draw_scene_tree_structure_meshcat(sampled_tree, zmq_url=vis.window.zmq_url, prefix=\"sample/structure\", node_sphere_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sink:plates_cups_and_bowls:bowls:Bradshaw_International_11642_7_Qt_MP_Plastic_Bowl', 'DishBin']\n"
     ]
    }
   ],
   "source": [
    "observed_node_set_test = [\n",
    "    BowlModels[0](drake_tf_to_torch_tf(RigidTransform(\n",
    "        p=[0.5, 0.0, 0.1],\n",
    "        R=UniformlyRandomRotationMatrix(RandomGenerator(0))))\n",
    "    ),\n",
    "    DishBin(drake_tf_to_torch_tf(\n",
    "        RigidTransform(p=[0.5, 0., 0.]))\n",
    "    )\n",
    "]\n",
    "print([type(node).__name__ for node in observed_node_set_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supertree size  202\n"
     ]
    }
   ],
   "source": [
    "supertree = grammar.make_super_tree(max_recursion_depth=10)\n",
    "print(\"Supertree size \", len(supertree.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting setup.\n",
      "Activation vars allocated.\n",
      "Continuous variables and SO(3) constraints allocated for all equivalence sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Hitting bad MIP case\n",
      "WARNING:root:Hitting bad MIP case\n",
      "WARNING:root:Hitting bad MIP case\n",
      "WARNING:root:Hitting bad MIP case\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n",
      "WARNING:root:TODO here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup time:  1.9066143035888672\n",
      "Num vars:  4773\n",
      "Num constraints:  14310\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-86b6acb794b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Parse that dummy observation; it should have only one unique parse, since there's only one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_optimized_trees_from_mip_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_mle_tree_with_mip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_solutions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_recursion_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parses\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdraw_scene_tree_contents_meshcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmq_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzmq_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parses/contents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/spatial_scene_grammars/spatial_scene_grammars/parsing.py\u001b[0m in \u001b[0;36minfer_mle_tree_with_mip\u001b[0;34m(grammar, observed_nodes, max_recursion_depth, solver, verbose, num_intervals_per_half_axis, max_scene_extent_in_any_dir, N_solutions, use_random_rotation_offset)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PoolSearchMode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Hacky method getter because `num_suboptimal_solution()` was bound with () in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# method name. Should fix this upstream!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parse that dummy observation; it should have only one unique parse, since there's only one\n",
    "# object.\n",
    "trees = get_optimized_trees_from_mip_results(infer_mle_tree_with_mip(grammar, sampled_tree, N_solutions=5, max_recursion_depth=10, verbose=True))\n",
    "vis[\"parses\"].delete()\n",
    "draw_scene_tree_contents_meshcat(trees[0], zmq_url=vis.window.zmq_url, prefix=\"parses/contents\")\n",
    "for k, tree in enumerate(trees[:]):\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"parses/structure/%d\" % k, node_sphere_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parse score: \", trees[0].score(include_continuous=True))\n",
    "print(\"GT tree score: \", sampled_tree.score(include_continuous=True))\n",
    "deviations = []\n",
    "for node in trees[0]:\n",
    "    R = node.rotation.detach().numpy()\n",
    "    deviations.append(np.sum(R.T.dot(R) - np.eye(3)))\n",
    "print(\"Max deviation: \", np.max(np.abs(deviations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIPMAP-EM alternation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = EMWrapper(grammar, observed_node_sets)\n",
    "em.do_iterated_em_fitting(em_iterations=10, tqdm=tqdm, N_solutions=10, num_workers=10, max_recursion_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our grammar params\n",
    "torch.save(grammar.state_dict(), \"fit_grammar.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot_grammar_parameter_history(DishBin)\n",
    "em.plot_grammar_parameter_history(Object)\n",
    "print(\"Plate\")\n",
    "em.plot_grammar_parameter_history(Plate)\n",
    "print(\"PlateStack\")\n",
    "em.plot_grammar_parameter_history(PlateStack)\n",
    "print(\"AssortedPlateStacks\")\n",
    "em.plot_grammar_parameter_history(AssortedPlateStacks)\n",
    "print(\"AssortedFullBowls\")\n",
    "em.plot_grammar_parameter_history(AssortedFullBowls)\n",
    "print(\"FullBowl\")\n",
    "em.plot_grammar_parameter_history(FullBowl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_node_xyzs(sampled_trees, node_type):\n",
    "    l = []\n",
    "    for tree in sampled_trees:\n",
    "        for node in tree:\n",
    "            if isinstance(node, node_type):\n",
    "                l.append(node.translation.detach().cpu().numpy())\n",
    "    return np.stack(l)\n",
    "def plot_post_fit_tree_samples(em, N_samples=100):\n",
    "    pre_fit_samples= []\n",
    "    em.grammar.load_state_dict(em.grammar_iters[0])\n",
    "    for k in range(N_samples):\n",
    "        pre_fit_samples.append(em.grammar.sample_tree(detach=True))\n",
    "    fit_samples = []\n",
    "    em.grammar.load_state_dict(em.grammar_iters[-1])\n",
    "    for k in range(N_samples):\n",
    "        fit_samples.append(em.grammar.sample_tree(detach=True))\n",
    "\n",
    "    for node_type in [PlateModels[0], CupModels[0], BowlModels[0]]:\n",
    "        plt.figure(dpi=300).set_size_inches(16, 4)\n",
    "        plt.suptitle(\"%s XYZ histogram comparisons\" % node_type.__name__)\n",
    "\n",
    "        gt_l = get_all_node_xyzs([SceneTree.make_from_observed_nodes(sample) for sample in observed_node_sets], node_type)\n",
    "        fit_l = get_all_node_xyzs([sample for sample in fit_samples], node_type)\n",
    "        pre_fit_l = get_all_node_xyzs([sample for sample in pre_fit_samples], node_type)\n",
    "        # Pre fit\n",
    "        for k in range(3):\n",
    "            plt.subplot(2, 3, k+1)\n",
    "            plt.title(\"Before fit %s\" % \"xyz\"[k:(k+1)])\n",
    "            plt.hist(pre_fit_l[:, k], label=\"Pre-fitting\", alpha=0.5, density=True)\n",
    "            plt.hist(gt_l[:, k], label=\"Ground truth\", alpha=0.5, density=True)\n",
    "            if k == 2:\n",
    "                plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "\n",
    "        for k in range(3):\n",
    "            plt.subplot(2, 3, k+1+3)\n",
    "            plt.title(\"After fit %s\" % \"xyz\"[k:(k+1)])\n",
    "            plt.hist(fit_l[:, k], label=\"Post-fitting\", alpha=0.5, density=True)\n",
    "            plt.hist(gt_l[:, k], label=\"Ground truth\", alpha=0.5, density=True)\n",
    "            if k == 2:\n",
    "                plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "        plt.tight_layout()\n",
    "plot_post_fit_tree_samples(em, N_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw some samples from the fit posterior\n",
    "vis[\"fit_samples\"].delete()\n",
    "for k in range(5):\n",
    "    tree = grammar.sample_tree(detach=True)\n",
    "    draw_scene_tree_contents_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"fit_samples/%d/contents\" % k)\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"fit_samples/%d/structure\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test parsing a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up grammar\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = DishBin,\n",
    "    root_node_tf = drake_tf_to_torch_tf(RigidTransform(p=[0.5, 0., 0.]))\n",
    ")\n",
    "grammar.load_state_dict(torch.load(\"fit_grammar.torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse that dummy observation; it should have only one unique parse, since there's only one\n",
    "# object.\n",
    "results = infer_mle_tree_with_mip(grammar, observed_node_sets[8], N_solutions=1, max_recursion_depth=10, verbose=True)\n",
    "trees = get_optimized_trees_from_mip_results(results)\n",
    "vis[\"parses\"].delete()\n",
    "for k, tree in enumerate(trees[:1]):\n",
    "    if k == 0:\n",
    "        draw_scene_tree_contents_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"parses/contents/%d\" % k)\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"parses/structure/%d\" % k, alpha=0.25, node_sphere_size=0.01)\n",
    "    print(\"Computed score %f, optimization score %f\" % (tree.score(verbose=0), results.optim_result.get_suboptimal_objective(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all scenes in dataset, and return by best score.\n",
    "# Parse that dummy observation; it should have only one unique parse, since there's only one\n",
    "# object.\n",
    "\n",
    "with open(\"observed_outlier_node_sets.dat\", \"rb\") as f:\n",
    "    observed_node_sets_outliers = pickle.load(f)\n",
    "    \n",
    "parses = get_map_trees_for_observed_node_sets(grammar, observed_node_sets, N_solutions=1, num_workers=10, tqdm=tqdm)\n",
    "parses = [parse[0] for parse in parses]\n",
    "scores = torch.stack([parse.score() for parse in parses]).detach().numpy()\n",
    "\n",
    "parses_outliers = get_map_trees_for_observed_node_sets(grammar, observed_node_sets_outliers, N_solutions=1, num_workers=10, tqdm=tqdm)\n",
    "parses_outliers = [parse[0] for parse in parses_outliers]\n",
    "scores_outliers = torch.stack([parse.score() for parse in parses_outliers]).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_ascending = np.argsort(scores, axis=0)\n",
    "print(\"Ranking: \", inds_ascending)\n",
    "plt.hist(scores, bins=100, label=\"Training set\")\n",
    "plt.hist(scores_outliers, bins=100, label=\"Outliers\")\n",
    "plt.xlabel(\"Log-prob of best parse tree\")\n",
    "plt.ylabel(\"Occurance in dataset\")\n",
    "plt.legend()\n",
    "print(parses[-1].score(verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
