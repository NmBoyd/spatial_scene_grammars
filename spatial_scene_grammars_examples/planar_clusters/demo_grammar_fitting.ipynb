{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.visualization import *\n",
    "from spatial_scene_grammars_examples.planar_clusters.grammar import *\n",
    "from spatial_scene_grammars.parsing import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "\n",
    "import meshcat\n",
    "import meshcat.geometry as meshcat_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7012/static/\n",
      "Meshcat url:  http://127.0.0.1:7012/static/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "    <iframe src=\"http://127.0.0.1:7012/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'vis' not in globals():\n",
    "    vis = meshcat.Visualizer()\n",
    "\n",
    "base_url = \"http://127.0.0.1\"\n",
    "meshcat_url = base_url + \":\" + vis.url().split(\":\")[-1]\n",
    "print(\"Meshcat url: \", meshcat_url)\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
    "    <iframe src=\"{url}\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
    "</div>\n",
    "\"\"\".format(url=meshcat_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 scenes.\n"
     ]
    }
   ],
   "source": [
    "# Sample a dataset of scenes from the default grammar params.\n",
    "# Draw a random sample from the grammar and visualize it.\n",
    "# (Cache output.)\n",
    "torch.random.manual_seed(2)\n",
    "N_samples = 3\n",
    "RESAMPLE = True\n",
    "scenes_file = \"sampled_scenes_%d.dat\" % N_samples\n",
    "\n",
    "ground_truth_grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4)\n",
    ")\n",
    "\n",
    "if not os.path.exists(scenes_file) or RESAMPLE:\n",
    "    samples = []\n",
    "    for k in range(N_samples):\n",
    "        tree = ground_truth_grammar.sample_tree(detach=True)\n",
    "        observed_nodes = tree.get_observed_nodes()\n",
    "        samples.append((tree, observed_nodes))\n",
    "\n",
    "    with open(scenes_file, \"wb\") as f:\n",
    "        pickle.dump(samples, f)\n",
    "\n",
    "with open(scenes_file, \"rb\") as f:\n",
    "    samples = pickle.load(f)\n",
    "print(\"Loaded %d scenes.\" % len(samples))\n",
    "observed_node_sets = [x[1] for x in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a175c1876647b992f7f7787857624a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting posterior samples:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a grammar with bad parameter guesses.\n",
    "torch.random.manual_seed(2)\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4),\n",
    "    sample_params_from_prior=True\n",
    ")\n",
    "\n",
    "def do_vis(tree):\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"sampled_in_progress\")\n",
    "    \n",
    "def get_posterior_tree_samples_from_observation(grammar, observed_nodes, num_mcmc_steps=15, subsample_rate=3, verbose=0):\n",
    "    draw_scene_tree_contents_meshcat(\n",
    "        SceneTree.make_from_observed_nodes(observed_nodes), zmq_url=vis.window.zmq_url, prefix=\"observed\"\n",
    "    )\n",
    "    \n",
    "    # Use a MIP to get MAP structure.\n",
    "    mip_results = infer_mle_tree_with_mip(\n",
    "        grammar, observed_nodes, verbose=verbose, max_scene_extent_in_any_dir=10.\n",
    "    )\n",
    "    mip_optimized_tree = get_optimized_tree_from_mip_results(mip_results)\n",
    "    if not mip_optimized_tree:\n",
    "        return None\n",
    "    # Use NLP to refine that to a MAP estimate.\n",
    "    refinement_results = optimize_scene_tree_with_nlp(mip_optimized_tree, verbose=verbose)\n",
    "    refined_tree = refinement_results.refined_tree\n",
    "\n",
    "    # And sample trees around that MAP estimate with the\n",
    "    # same structure.\n",
    "    sampled_trees = do_fixed_structure_mcmc(\n",
    "        grammar, refined_tree, num_samples=num_mcmc_steps, verbose=verbose,\n",
    "        perturb_in_config_space=True, translation_variance=1.0, rotation_variance=1.0,\n",
    "        do_hit_and_run_postprocess=False, vis_callback=do_vis\n",
    "    )\n",
    "    \n",
    "    # Finally, subsample the sampled trees as requested and return\n",
    "    # the sampled set.\n",
    "    return sampled_trees[::subsample_rate]\n",
    "\n",
    "def collect_posterior_sample_sets(observed_node_sets):\n",
    "    posterior_sample_sets = []\n",
    "    for observed_nodes in tqdm(observed_node_sets, desc='Collecting posterior samples'):\n",
    "        posterior_samples = get_posterior_tree_samples_from_observation(\n",
    "            grammar, observed_nodes, verbose=0, subsample_rate=2, num_mcmc_steps=10)\n",
    "        if posterior_samples is not None:\n",
    "            posterior_sample_sets.append(posterior_samples)\n",
    "    return posterior_sample_sets\n",
    "posterior_sample_sets = collect_posterior_sample_sets(observed_node_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8815ad9dad84e8faad80653491c2fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing parameters:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And now do gradient descent on the grammar parameters\n",
    "# by summing the score of all of those trees.\n",
    "\n",
    "# Reattach tree params to prepare for grad descent.\n",
    "tree_set = sum(posterior_sample_sets, [])\n",
    "\n",
    "def calc_mean_score(tree_set):\n",
    "    total_score = 0.\n",
    "    total_k = 0.\n",
    "    for tree in tree_set:\n",
    "        total_score = total_score + tree.score()\n",
    "        total_k += 1\n",
    "    return total_score / total_k\n",
    "\n",
    "log_by_node_type = {node_type.__name__: [] for node_type in grammar.all_types}\n",
    "def log_params(grammar):\n",
    "    for node_type_name, params in grammar.params_by_node_type.items():\n",
    "        if params is not None:\n",
    "            log_by_node_type[node_type_name].append(params().detach())\n",
    "        \n",
    "optimizer = torch.optim.Adam(grammar.parameters(), lr=0.1)\n",
    "pbar = tqdm(range(100), desc=\"Optimizing parameters\")\n",
    "score_history = []\n",
    "for step_k in pbar:\n",
    "    # Update parameter settings\n",
    "    log_params(grammar)\n",
    "    for tree in tree_set:\n",
    "        grammar.update_tree_grammar_parameters(tree)\n",
    "    score = calc_mean_score(tree_set)\n",
    "    score_history.append(score)\n",
    "    # Gradient step\n",
    "    optimizer.zero_grad()\n",
    "    (-score).backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    pbar.set_description(\"Mean score %2.2f\" % score)\n",
    "plt.plot(score_history)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.title(\"Score history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot param logs\n",
    "cm = plt.get_cmap('viridis')\n",
    "for node_type_name, log in log_by_node_type.items():\n",
    "    if len(log) > 0:\n",
    "        plt.figure()\n",
    "        data = torch.stack(log, axis=0).numpy()\n",
    "        n_vars = data.shape[1]\n",
    "        ground_truth_values = ground_truth_grammar.params_by_node_type[node_type_name]()\n",
    "        for var_k in range(n_vars):\n",
    "            c = cm(float(var_k) / max(1, (n_vars-1)))\n",
    "            plt.plot(data[:, var_k], color=c, label=\"Fit\")\n",
    "            plt.axhline(ground_truth_values[var_k], color=c, linestyle=\"--\", label=\"GT\")\n",
    "        plt.title(node_type_name + \" child weights\")\n",
    "        plt.xlabel(\"Step\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "py36_pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
