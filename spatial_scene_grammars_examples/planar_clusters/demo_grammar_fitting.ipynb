{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.visualization import *\n",
    "from spatial_scene_grammars_examples.planar_clusters.grammar import *\n",
    "from spatial_scene_grammars.parsing import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "\n",
    "import meshcat\n",
    "import meshcat.geometry as meshcat_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7001/static/\n",
      "Meshcat url:  http://127.0.0.1:7001/static/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "    <iframe src=\"http://127.0.0.1:7001/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'vis' not in globals():\n",
    "    vis = meshcat.Visualizer()\n",
    "\n",
    "base_url = \"http://127.0.0.1\"\n",
    "meshcat_url = base_url + \":\" + vis.url().split(\":\")[-1]\n",
    "print(\"Meshcat url: \", meshcat_url)\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
    "    <iframe src=\"{url}\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
    "</div>\n",
    "\"\"\".format(url=meshcat_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 scenes.\n"
     ]
    }
   ],
   "source": [
    "# Sample a dataset of scenes from the default grammar params.\n",
    "# Draw a random sample from the grammar and visualize it.\n",
    "# (Cache output.)\n",
    "torch.random.manual_seed(2)\n",
    "N_samples = 3\n",
    "RESAMPLE = True\n",
    "scenes_file = \"sampled_scenes_%d.dat\" % N_samples\n",
    "\n",
    "ground_truth_grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4)\n",
    ")\n",
    "\n",
    "if not os.path.exists(scenes_file) or RESAMPLE:\n",
    "    samples = []\n",
    "    for k in range(N_samples):\n",
    "        tree = ground_truth_grammar.sample_tree(detach=True)\n",
    "        observed_nodes = tree.get_observed_nodes()\n",
    "        samples.append((tree, observed_nodes))\n",
    "\n",
    "    with open(scenes_file, \"wb\") as f:\n",
    "        pickle.dump(samples, f)\n",
    "\n",
    "with open(scenes_file, \"rb\") as f:\n",
    "    samples = pickle.load(f)\n",
    "print(\"Loaded %d scenes.\" % len(samples))\n",
    "observed_node_sets = [x[1] for x in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f87a0fc78b44bc8dc994bd428823da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a grammar with wide parameter guesses.\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4),\n",
    "    sample_params_from_prior=False\n",
    ")\n",
    "# Force parameter guesses for rules as wide as possible.\n",
    "# TODO: Make this a grammar method.\n",
    "for node_type in grammar.all_types:\n",
    "    for xyz_param_dict, rot_param_dict in grammar.rule_params_by_node_type[node_type.__name__]:\n",
    "        if \"width\" in xyz_param_dict.keys():\n",
    "            xyz_param_dict[\"width\"].set(torch.ones_like(xyz_param_dict[\"width\"]()) * 5.)\n",
    "        \n",
    "\n",
    "def do_vis(tree):\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"sampled_in_progress\")\n",
    "    \n",
    "def get_posterior_tree_samples_from_observation(grammar, observed_nodes, num_mcmc_steps=15, subsample_rate=3, verbose=0):\n",
    "    draw_scene_tree_contents_meshcat(\n",
    "        SceneTree.make_from_observed_nodes(observed_nodes), zmq_url=vis.window.zmq_url, prefix=\"observed\"\n",
    "    )\n",
    "    \n",
    "    # Use a MIP to get MAP structure.\n",
    "    mip_results = infer_mle_tree_with_mip(\n",
    "        grammar, observed_nodes, verbose=verbose, max_scene_extent_in_any_dir=10.\n",
    "    )\n",
    "    mip_optimized_tree = get_optimized_tree_from_mip_results(mip_results)\n",
    "    if not mip_optimized_tree:\n",
    "        return None\n",
    "    # Use NLP to refine that to a MAP estimate.\n",
    "    refinement_results = optimize_scene_tree_with_nlp(mip_optimized_tree, verbose=verbose)\n",
    "    refined_tree = refinement_results.refined_tree\n",
    "\n",
    "    # And sample trees around that MAP estimate with the\n",
    "    # same structure.\n",
    "    sampled_trees = do_fixed_structure_mcmc(\n",
    "        grammar, refined_tree, num_samples=num_mcmc_steps, verbose=verbose,\n",
    "        perturb_in_config_space=True, translation_variance=1.0, rotation_variance=1.0,\n",
    "        do_hit_and_run_postprocess=False, vis_callback=do_vis\n",
    "    )\n",
    "    \n",
    "    # Finally, subsample the sampled trees as requested and return\n",
    "    # the sampled set.\n",
    "    return sampled_trees[::subsample_rate]\n",
    "\n",
    "def collect_posterior_sample_sets(grammar, observed_node_sets):\n",
    "    posterior_sample_sets = []\n",
    "    for observed_nodes in tqdm(observed_node_sets, desc='Collecting posterior samples'):\n",
    "        posterior_samples = get_posterior_tree_samples_from_observation(\n",
    "            grammar, observed_nodes, verbose=0, subsample_rate=2, num_mcmc_steps=10)\n",
    "        if posterior_samples is not None:\n",
    "            posterior_sample_sets.append(posterior_samples)\n",
    "    return posterior_sample_sets\n",
    "posterior_sample_sets = collect_posterior_sample_sets(grammar, observed_node_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(grammar, \"/tmp/test_saved_grammar.torch\")\n",
    "orig_grammar = torch.load(\"/tmp/test_saved_grammar.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "**********  BEFORE ***************\n",
      "************************************\n",
      "\tDesk:\n",
      "\t\tchild weights: [0.2]\n",
      "\t\tRule 0:\n",
      "\t\t\tXYZ center: Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.0000], requires_grad=True)\n",
      "\t\t\tXYZ width: tensor([5., 5., 5.], grad_fn=<AddBackward0>)\n",
      "\t\t\tRot center: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "\t\t\tRot width: tensor([6.2832], grad_fn=<AddBackward0>)\n",
      "**********************************\n",
      "**********  AFTER ***************\n",
      "************************************\n",
      "\tDesk:\n",
      "\t\tchild weights: [0.3]\n",
      "\t\tRule 0:\n",
      "\t\t\tXYZ center: Parameter containing:\n",
      "tensor([0.0484, 0.3992, 0.0000], requires_grad=True)\n",
      "\t\t\tXYZ width: tensor([4.0968, 4.7985, 5.0000], grad_fn=<AddBackward0>)\n",
      "\t\t\tRot center: Parameter containing:\n",
      "tensor(-0.2500, requires_grad=True)\n",
      "\t\t\tRot width: tensor([5.0829], grad_fn=<AddBackward0>)\n",
      "**********************************\n",
      "**********  TRUTH ***************\n",
      "************************************\n",
      "\tDesk:\n",
      "\t\tchild weights: [0.2]\n",
      "\t\tRule 0:\n",
      "\t\t\tXYZ center: Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.0000], requires_grad=True)\n",
      "\t\t\tXYZ width: tensor([ 6.0000e-01,  6.0000e-01, 2.2251e-307], grad_fn=<AddBackward0>)\n",
      "\t\t\tRot center: Parameter containing:\n",
      "tensor(0., requires_grad=True)\n",
      "\t\t\tRot width: tensor([6.2832], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def fit_grammar_params_to_sample_sets(grammar, posterior_sample_sets):\n",
    "    ## Try hand-fitting the node and rule parameters, assuming an uninformative prior.\n",
    "    observed_child_sets_per_node_type = {}\n",
    "    for node_type in grammar.all_types:\n",
    "        observed_child_sets_per_node_type[node_type.__name__] = []\n",
    "    for sample_set in posterior_sample_sets:\n",
    "        for tree in sample_set:\n",
    "            for node in tree:\n",
    "                if isinstance(node, TerminalNode):\n",
    "                    pass\n",
    "                observed_child_sets_per_node_type[type(node).__name__].append( (node, tree.get_children(node)) )\n",
    "\n",
    "    for node_type in grammar.all_types:\n",
    "\n",
    "        ## Fit the child weights for the node type.\n",
    "        observed_child_sets = observed_child_sets_per_node_type[node_type.__name__]\n",
    "        if issubclass(node_type, AndNode):\n",
    "            continue\n",
    "        elif issubclass(node_type, OrNode):\n",
    "            # Sum up the rule_k weights, and set\n",
    "            # the new weighting to the average.\n",
    "            count = torch.zeros(len(node_type.generate_rules()))\n",
    "            for (_, children) in observed_child_sets:\n",
    "                for child in children:\n",
    "                    count[child.rule_k] += 1\n",
    "            avg_count = count / torch.sum(count)\n",
    "            grammar.params_by_node_type[node_type.__name__].set(avg_count)\n",
    "        elif issubclass(node_type, GeometricSetNode):\n",
    "            # Record average count of children, whose inverse\n",
    "            # is a maximum likelihood estimate of p.\n",
    "            # https://en.wikipedia.org/wiki/Geometric_distribution#Statistical_inference\n",
    "            n_children = [len(children) for (_, children) in observed_child_sets]\n",
    "            p = 1./torch.mean(torch.tensor(n_children, dtype=torch.double))\n",
    "            grammar.params_by_node_type[node_type.__name__].set(p)\n",
    "        elif issubclass(node_type, IndependentSetNode):\n",
    "            # For each child, record how often it's active.\n",
    "            count = torch.zeros(len(node_type.generate_rules()))\n",
    "            for (_, children) in observed_child_sets:\n",
    "                for child in children:\n",
    "                    count[child.rule_k] += 1.\n",
    "            count /= len(observed_child_sets)\n",
    "            grammar.params_by_node_type[node_type.__name__].set(count)\n",
    "        elif issubclass(node_type, TerminalNode):\n",
    "            continue\n",
    "        else:\n",
    "            raise NotImplementedError(node_type)\n",
    "\n",
    "        ## For each rule type expected under this node, find optimal parameters.\n",
    "        rules = node_type.generate_rules()\n",
    "\n",
    "        # Go collect all parent/child pairs for the rules.\n",
    "        parent_child_pairs_for_rules = [[] for k in range(len(rules))]\n",
    "        if issubclass(node_type, GeometricSetNode):\n",
    "            # Special case: only one rule that all children\n",
    "            # correspond to.\n",
    "            assert len(rules) == 1\n",
    "            for parent, children in observed_child_sets:\n",
    "                for child in children:\n",
    "                    parent_child_pairs_for_rules[0].append((parent, child))\n",
    "        else:\n",
    "            for parent, children in observed_child_sets:\n",
    "                for child in children:\n",
    "                    parent_child_pairs_for_rules[child.rule_k].append((parent, child))\n",
    "\n",
    "        for rule_k, (xyz_param_dict, rot_param_dict) in enumerate(\n",
    "                grammar.rule_params_by_node_type[node_type.__name__]):\n",
    "            xyz_rule = rules[rule_k].xyz_rule\n",
    "            rot_rule = rules[rule_k].rotation_rule\n",
    "            parent_child_pairs = parent_child_pairs_for_rules[rule_k]\n",
    "            if len(parent_child_pairs) == 0:\n",
    "                continue\n",
    "            ## XYZ Rules\n",
    "            if type(xyz_rule) == WorldBBoxRule:\n",
    "                # The inferred lb/ub (from which we'll derive center/width)\n",
    "                # will be the biggest deviation between parent and child.\n",
    "                offsets = torch.stack([child.translation for (_, child) in parent_child_pairs])\n",
    "                lb = torch.min(offsets, axis=0)[0]\n",
    "                ub = torch.max(offsets, axis=0)[0]\n",
    "                xyz_param_dict[\"center\"].set((lb + ub) / 2.)\n",
    "                xyz_param_dict[\"width\"].set(ub - lb)\n",
    "            elif type(xyz_rule) == AxisAlignedBBoxRule:\n",
    "                # The inferred lb/ub (from which we'll derive center/width)\n",
    "                # will be the biggest deviation between parent and child.\n",
    "                offsets = torch.stack([child.translation - parent.translation for (parent, child) in parent_child_pairs])\n",
    "                lb = torch.min(offsets, axis=0)[0]\n",
    "                ub = torch.max(offsets, axis=0)[0]\n",
    "                xyz_param_dict[\"center\"].set((lb + ub) / 2.)\n",
    "                xyz_param_dict[\"width\"].set(ub - lb)\n",
    "            else:\n",
    "                raise NotImplementedError(\"type %s under node %s\" % (type(xyz_rule), node_type))\n",
    "            ## Rotation rules\n",
    "            if type(rot_rule) == UnconstrainedRotationRule:\n",
    "                # No parameters\n",
    "                pass\n",
    "            elif type(rot_rule) == UniformBoundedRevoluteJointRule:\n",
    "                # The inferred lb/ub (from which we'll derive center/width)\n",
    "                # will be the biggest deviation between parent and child in terms\n",
    "                # of axis/angle rotation.\n",
    "                offsets = []\n",
    "                for parent, child in parent_child_pairs:\n",
    "                    angle, _ = rot_rule._recover_relative_angle_axis(parent, child)\n",
    "                    offsets.append(angle)\n",
    "                offsets = torch.stack(offsets)\n",
    "                lb = torch.min(offsets)\n",
    "                ub = torch.max(offsets)\n",
    "                rot_param_dict[\"center\"].set((lb + ub) / 2.)\n",
    "                rot_param_dict[\"width\"].set(ub - lb)\n",
    "    return grammar\n",
    "fit_grammar_params_to_sample_sets(grammar, posterior_sample_sets)\n",
    "print(\"**********************************\\n\"\n",
    "      \"**********  BEFORE ***************\\n\"\n",
    "      \"************************************\")\n",
    "orig_grammar.print_params(node_names=[\"Desk\"])\n",
    "print(\"**********************************\\n\"\n",
    "      \"**********  AFTER ***************\\n\"\n",
    "      \"************************************\")\n",
    "grammar.print_params(node_names=[\"Desk\"])\n",
    "print(\"**********************************\\n\"\n",
    "      \"**********  TRUTH ***************\\n\"\n",
    "      \"************************************\")\n",
    "ground_truth_grammar.print_params(node_names=[\"Desk\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28bf48294594c07be83d4f58119327f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e50eb1105745edbe242b53611bf5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fff361a6fd4db78ca6acb1763316ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b133bae8eb2c499194c1818639998c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1513b4c66cec494cbf40839f46b5ec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ed9fd5a1ba461baeb15e540d50c040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b197c100e44e38a29316e15b70ddba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b6b5bebb0a4f998b766b1fe7b50962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4096c1497d6490bab9e70385065344b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bbcba2eae4487aa47ae0b1ddaa10cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Collecting posterior samples', max=3.0, style=ProgressStyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "state_dict_history = []\n",
    "for iter_k in range(10):\n",
    "    state_dict_history.append(deepcopy(grammar.state_dict()))\n",
    "    posterior_sample_sets = collect_posterior_sample_sets(grammar, observed_node_sets)\n",
    "    fit_grammar_params_to_sample_sets(grammar, posterior_sample_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f31c5fdb278>,\n",
       " <matplotlib.lines.Line2D at 0x7f31c5fdb390>,\n",
       " <matplotlib.lines.Line2D at 0x7f31c5fdb4e0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# XYZ width history, illustrative example:\n",
    "desk_xyz_width_history = []\n",
    "for state_dict in state_dict_history:\n",
    "    grammar.load_state_dict(state_dict)\n",
    "    desk_xyz_width_history.append(grammar.rule_params_by_node_type[\"Desk\"][0][0][\"width\"]().detach().numpy())\n",
    "plt.plot(desk_xyz_width_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now do gradient descent on the grammar parameters\n",
    "# by summing the score of all of those trees.\n",
    "\n",
    "# Reattach tree params to prepare for grad descent.\n",
    "tree_set = sum(posterior_sample_sets, [])\n",
    "\n",
    "def calc_mean_score(tree_set):\n",
    "    total_score = 0.\n",
    "    total_k = 0.\n",
    "    for tree in tree_set:\n",
    "        total_score = total_score + tree.score()\n",
    "        total_k += 1\n",
    "    return total_score / total_k\n",
    "\n",
    "log_by_node_type = {node_type.__name__: [] for node_type in grammar.all_types}\n",
    "def log_params(grammar):\n",
    "    for node_type_name, params in grammar.params_by_node_type.items():\n",
    "        if params is not None:\n",
    "            log_by_node_type[node_type_name].append(params().detach())\n",
    "        \n",
    "optimizer = torch.optim.Adam(grammar.parameters(), lr=0.1)\n",
    "pbar = tqdm(range(100), desc=\"Optimizing parameters\")\n",
    "score_history = []\n",
    "for step_k in pbar:\n",
    "    # Update parameter settings\n",
    "    log_params(grammar)\n",
    "    for tree in tree_set:\n",
    "        grammar.update_tree_grammar_parameters(tree)\n",
    "    score = calc_mean_score(tree_set)\n",
    "    score_history.append(score)\n",
    "    # Gradient step\n",
    "    optimizer.zero_grad()\n",
    "    (-score).backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    pbar.set_description(\"Mean score %2.2f\" % score)\n",
    "plt.plot(score_history)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.title(\"Score history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot param logs\n",
    "cm = plt.get_cmap('viridis')\n",
    "for node_type_name, log in log_by_node_type.items():\n",
    "    if len(log) > 0:\n",
    "        plt.figure()\n",
    "        data = torch.stack(log, axis=0).numpy()\n",
    "        n_vars = data.shape[1]\n",
    "        ground_truth_values = ground_truth_grammar.params_by_node_type[node_type_name]()\n",
    "        for var_k in range(n_vars):\n",
    "            c = cm(float(var_k) / max(1, (n_vars-1)))\n",
    "            plt.plot(data[:, var_k], color=c, label=\"Fit\")\n",
    "            plt.axhline(ground_truth_values[var_k], color=c, linestyle=\"--\", label=\"GT\")\n",
    "        plt.title(node_type_name + \" child weights\")\n",
    "        plt.xlabel(\"Step\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
