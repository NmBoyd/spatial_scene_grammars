{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.visualization import *\n",
    "from spatial_scene_grammars_examples.planar_clusters_gaussians.grammar import *\n",
    "from spatial_scene_grammars.parsing import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "\n",
    "import meshcat\n",
    "import meshcat.geometry as meshcat_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshcat url:  http://127.0.0.1:7013/static/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "    <iframe src=\"http://127.0.0.1:7013/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'vis' not in globals():\n",
    "    vis = meshcat.Visualizer()\n",
    "vis.delete()\n",
    "base_url = \"http://127.0.0.1\"\n",
    "meshcat_url = base_url + \":\" + vis.url().split(\":\")[-1]\n",
    "print(\"Meshcat url: \", meshcat_url)\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
    "    <iframe src=\"{url}\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
    "</div>\n",
    "\"\"\".format(url=meshcat_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 scenes.\n"
     ]
    }
   ],
   "source": [
    "# Sample a dataset of scenes from the default grammar params.\n",
    "# Draw a random sample from the grammar and visualize it.\n",
    "# (Cache output.)\n",
    "torch.random.manual_seed(2)\n",
    "N_samples = 1\n",
    "RESAMPLE = True\n",
    "scenes_file = \"sampled_scenes_%d.dat\" % N_samples\n",
    "\n",
    "ground_truth_grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4)\n",
    ")\n",
    "\n",
    "if not os.path.exists(scenes_file) or RESAMPLE:\n",
    "    samples = []\n",
    "    for k in range(N_samples):\n",
    "        tree = ground_truth_grammar.sample_tree(detach=True)\n",
    "        observed_nodes = tree.get_observed_nodes()\n",
    "        samples.append((tree, observed_nodes))\n",
    "\n",
    "    with open(scenes_file, \"wb\") as f:\n",
    "        pickle.dump(samples, f)\n",
    "\n",
    "with open(scenes_file, \"rb\") as f:\n",
    "    samples = pickle.load(f)\n",
    "print(\"Loaded %d scenes.\" % len(samples))\n",
    "observed_node_sets = [x[1] for x in samples]\n",
    "\n",
    "draw_scene_tree_contents_meshcat(samples[0][0], zmq_url=vis.window.zmq_url, prefix=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0801f125b584a40b6e4e72844bb92ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting posterior samples:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 30/30 [00:30,  1.03s/it, step size=2.60e-03, acc. prob=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                        mean       std    median     25.0%     75.0%     n_eff     r_hat\n",
      "    Desk_84/ObjectCluster_153/AxisAlignedGaussianOffsetRule_xyz[0]      0.80      0.02      0.80      0.80      0.82      5.36      1.00\n",
      "    Desk_84/ObjectCluster_153/AxisAlignedGaussianOffsetRule_xyz[1]      0.72      0.02      0.71      0.70      0.71      3.20      1.83\n",
      "    Desk_84/ObjectCluster_153/AxisAlignedGaussianOffsetRule_xyz[2]     -0.00      0.01     -0.00     -0.01      0.00   1343.53      0.95\n",
      "        Desk_84/ObjectCluster_153/GaussianChordOffsetRule_theta[0]     -1.07      0.01     -1.07     -1.07     -1.05     10.57      1.11\n",
      "    Desk_84/ObjectCluster_154/AxisAlignedGaussianOffsetRule_xyz[0]      0.34      0.01      0.33      0.33      0.34      9.58      1.18\n",
      "    Desk_84/ObjectCluster_154/AxisAlignedGaussianOffsetRule_xyz[1]      0.40      0.02      0.40      0.37      0.40      6.41      0.95\n",
      "    Desk_84/ObjectCluster_154/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.00      0.01     10.24      0.95\n",
      "        Desk_84/ObjectCluster_154/GaussianChordOffsetRule_theta[0]      0.23      0.02      0.23      0.22      0.25      4.58      1.41\n",
      "    Desk_84/ObjectCluster_155/AxisAlignedGaussianOffsetRule_xyz[0]      0.58      0.02      0.58      0.57      0.59      7.62      1.06\n",
      "    Desk_84/ObjectCluster_155/AxisAlignedGaussianOffsetRule_xyz[1]      0.18      0.01      0.18      0.18      0.19      5.55      1.03\n",
      "    Desk_84/ObjectCluster_155/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.00      0.01     56.62      0.95\n",
      "        Desk_84/ObjectCluster_155/GaussianChordOffsetRule_theta[0]     -0.33      0.01     -0.34     -0.34     -0.32      7.09      0.95\n",
      "    Desk_84/ObjectCluster_156/AxisAlignedGaussianOffsetRule_xyz[0]      0.98      0.01      0.98      0.98      0.99     52.96      0.95\n",
      "    Desk_84/ObjectCluster_156/AxisAlignedGaussianOffsetRule_xyz[1]      0.48      0.02      0.48      0.47      0.49      3.36      1.68\n",
      "    Desk_84/ObjectCluster_156/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.01      0.01     19.94      0.98\n",
      "        Desk_84/ObjectCluster_156/GaussianChordOffsetRule_theta[0]     -1.83      0.05     -1.84     -1.89     -1.84      3.06      1.84\n",
      "    Desk_84/ObjectCluster_157/AxisAlignedGaussianOffsetRule_xyz[0]      0.81      0.02      0.81      0.80      0.82      2.98      2.12\n",
      "    Desk_84/ObjectCluster_157/AxisAlignedGaussianOffsetRule_xyz[1]      0.80      0.02      0.80      0.79      0.82      3.76      1.56\n",
      "    Desk_84/ObjectCluster_157/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00      0.00      0.00    199.46      0.95\n",
      "        Desk_84/ObjectCluster_157/GaussianChordOffsetRule_theta[0]     -0.68      0.04     -0.68     -0.70     -0.67      3.23      1.78\n",
      "    Desk_84/ObjectCluster_158/AxisAlignedGaussianOffsetRule_xyz[0]      0.50      0.02      0.50      0.50      0.52      4.83      1.39\n",
      "    Desk_84/ObjectCluster_158/AxisAlignedGaussianOffsetRule_xyz[1]      0.28      0.02      0.29      0.28      0.30      4.52      1.32\n",
      "    Desk_84/ObjectCluster_158/AxisAlignedGaussianOffsetRule_xyz[2]      0.01      0.01      0.00     -0.00      0.01     35.46      0.97\n",
      "        Desk_84/ObjectCluster_158/GaussianChordOffsetRule_theta[0]     -1.67      0.04     -1.69     -1.71     -1.67      3.03      1.63\n",
      " PencilCluster_125/Pencil_169/AxisAlignedGaussianOffsetRule_xyz[0]     -0.01      0.02     -0.02     -0.03     -0.01      6.16      0.97\n",
      " PencilCluster_125/Pencil_169/AxisAlignedGaussianOffsetRule_xyz[1]      0.01      0.02      0.01      0.01      0.03      3.02      2.09\n",
      " PencilCluster_125/Pencil_169/AxisAlignedGaussianOffsetRule_xyz[2]     -0.01      0.01     -0.01     -0.01     -0.01     19.82      0.96\n",
      "     PencilCluster_125/Pencil_169/GaussianChordOffsetRule_theta[0]      2.95      0.02      2.95      2.94      2.96      9.44      1.27\n",
      " PencilCluster_125/Pencil_170/AxisAlignedGaussianOffsetRule_xyz[0]      0.03      0.02      0.02      0.01      0.02      5.59      0.97\n",
      " PencilCluster_125/Pencil_170/AxisAlignedGaussianOffsetRule_xyz[1]      0.02      0.02      0.02      0.02      0.04      4.15      1.44\n",
      " PencilCluster_125/Pencil_170/AxisAlignedGaussianOffsetRule_xyz[2]     -0.00      0.01     -0.00     -0.00      0.01     55.50      0.98\n",
      "     PencilCluster_125/Pencil_170/GaussianChordOffsetRule_theta[0]      1.70      0.02      1.70      1.69      1.72      9.52      1.23\n",
      "   PaperCluster_125/Paper_162/AxisAlignedGaussianOffsetRule_xyz[0]     -0.00      0.01     -0.00     -0.00      0.01     10.81      1.27\n",
      "   PaperCluster_125/Paper_162/AxisAlignedGaussianOffsetRule_xyz[1]      0.00      0.02      0.00     -0.00      0.02      7.85      0.95\n",
      "   PaperCluster_125/Paper_162/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.00      0.01     10.00      0.95\n",
      "       PaperCluster_125/Paper_162/GaussianChordOffsetRule_theta[0]      1.44      0.02      1.43      1.40      1.43      4.57      1.39\n",
      "FoodWasteCluster_125/Plate_90/AxisAlignedGaussianOffsetRule_xyz[0]     -0.17      0.02     -0.16     -0.17     -0.15     10.34      0.98\n",
      "FoodWasteCluster_125/Plate_90/AxisAlignedGaussianOffsetRule_xyz[1]     -0.14      0.01     -0.14     -0.15     -0.14      8.87      0.97\n",
      "FoodWasteCluster_125/Plate_90/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.00      0.01     54.55      0.96\n",
      "    FoodWasteCluster_125/Plate_90/GaussianChordOffsetRule_theta[0]     -1.44      0.01     -1.44     -1.44     -1.42      5.97      0.95\n",
      "FoodWasteCluster_125/Drink_90/AxisAlignedGaussianOffsetRule_xyz[0]     -0.13      0.01     -0.13     -0.15     -0.13     17.15      0.99\n",
      "FoodWasteCluster_125/Drink_90/AxisAlignedGaussianOffsetRule_xyz[1]     -0.22      0.02     -0.23     -0.24     -0.22      5.19      1.11\n",
      "FoodWasteCluster_125/Drink_90/AxisAlignedGaussianOffsetRule_xyz[2]     -0.01      0.01     -0.01     -0.01     -0.01    277.86      0.96\n",
      "    FoodWasteCluster_125/Drink_90/GaussianChordOffsetRule_theta[0]      2.67      0.02      2.67      2.66      2.68      6.05      0.97\n",
      "   PaperCluster_126/Paper_163/AxisAlignedGaussianOffsetRule_xyz[0]      0.01      0.01      0.01      0.01      0.01     19.26      0.99\n",
      "   PaperCluster_126/Paper_163/AxisAlignedGaussianOffsetRule_xyz[1]      0.00      0.02     -0.00     -0.02     -0.00      3.29      1.80\n",
      "   PaperCluster_126/Paper_163/AxisAlignedGaussianOffsetRule_xyz[2]     -0.03      0.01     -0.02     -0.03     -0.01     19.43      1.08\n",
      "       PaperCluster_126/Paper_163/GaussianChordOffsetRule_theta[0]      0.85      0.05      0.86      0.85      0.90      3.06      1.81\n",
      "FoodWasteCluster_126/Plate_91/AxisAlignedGaussianOffsetRule_xyz[0]     -0.06      0.02     -0.06     -0.06     -0.04      3.28      2.05\n",
      "FoodWasteCluster_126/Plate_91/AxisAlignedGaussianOffsetRule_xyz[1]      0.03      0.02      0.03      0.02      0.04      4.15      1.53\n",
      "FoodWasteCluster_126/Plate_91/AxisAlignedGaussianOffsetRule_xyz[2]     -0.01      0.01     -0.01     -0.01      0.00     60.89      0.95\n",
      "    FoodWasteCluster_126/Plate_91/GaussianChordOffsetRule_theta[0]     -1.73      0.04     -1.73     -1.74     -1.72      3.25      1.79\n",
      "FoodWasteCluster_126/Drink_91/AxisAlignedGaussianOffsetRule_xyz[0]     -0.01      0.01     -0.01     -0.01      0.01      3.84      1.71\n",
      "FoodWasteCluster_126/Drink_91/AxisAlignedGaussianOffsetRule_xyz[1]     -0.03      0.02     -0.03     -0.05     -0.03      3.90      1.46\n",
      "FoodWasteCluster_126/Drink_91/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.00      0.00     -0.00      0.00     36.10      0.97\n",
      "    FoodWasteCluster_126/Drink_91/GaussianChordOffsetRule_theta[0]      1.41      0.04      1.41      1.39      1.43      3.24      1.81\n",
      " PencilCluster_126/Pencil_171/AxisAlignedGaussianOffsetRule_xyz[0]      0.01      0.02      0.00     -0.00      0.01      5.63      1.30\n",
      " PencilCluster_126/Pencil_171/AxisAlignedGaussianOffsetRule_xyz[1]     -0.01      0.02     -0.02     -0.03     -0.02      4.46      1.42\n",
      " PencilCluster_126/Pencil_171/AxisAlignedGaussianOffsetRule_xyz[2]     -0.00      0.01     -0.00     -0.01      0.00     25.14      1.04\n",
      "     PencilCluster_126/Pencil_171/GaussianChordOffsetRule_theta[0]      1.51      0.05      1.52      1.52      1.56      3.01      1.66\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a grammar with wide parameter guesses.\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4),\n",
    "    sample_params_from_prior=False\n",
    ")\n",
    "# Force parameter guesses for rules as wide as possible.\n",
    "# TODO: Make this a grammar method.\n",
    "for node_type in grammar.all_types:\n",
    "    for xyz_param_dict, rot_param_dict in grammar.rule_params_by_node_type[node_type.__name__]:\n",
    "        if \"width\" in xyz_param_dict.keys():\n",
    "            xyz_param_dict[\"width\"].set(torch.ones_like(xyz_param_dict[\"width\"]()) * 5.)\n",
    "        \n",
    "\n",
    "def do_vis(tree):\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"sampled_in_progress\")\n",
    "    \n",
    "def get_posterior_tree_samples_from_observation(\n",
    "            grammar, observed_nodes, verbose=0,\n",
    "            num_samples=20, subsample_step=1, hmc_strategy=\"NUTS\"):\n",
    "    draw_scene_tree_contents_meshcat(\n",
    "        SceneTree.make_from_observed_nodes(observed_nodes), zmq_url=vis.window.zmq_url, prefix=\"observed\"\n",
    "    )\n",
    "    \n",
    "    # Use a MIP to get MAP structure.\n",
    "    mip_results = infer_mle_tree_with_mip(\n",
    "        grammar, observed_nodes, verbose=verbose>1, max_scene_extent_in_any_dir=10.\n",
    "    )\n",
    "    mip_optimized_tree = get_optimized_tree_from_mip_results(mip_results)\n",
    "    if not mip_optimized_tree:\n",
    "        return None\n",
    "    \n",
    "    draw_scene_tree_structure_meshcat(mip_optimized_tree, zmq_url=vis.window.zmq_url, prefix=\"mip_refined\")\n",
    "                                      \n",
    "    # Use NLP to refine that to a MAP estimate.\n",
    "    refinement_results = optimize_scene_tree_with_nlp(mip_optimized_tree, verbose=verbose>1)\n",
    "    refined_tree = refinement_results.refined_tree\n",
    "    \n",
    "    # And sample trees around that MAP estimate with the\n",
    "    # same structure.\n",
    "    # Langevin-esque:\n",
    "    if hmc_strategy==\"langevin\":\n",
    "        sampled_trees = do_fixed_structure_hmc_with_constraint_penalties(\n",
    "            grammar, tree, num_samples=num_samples, subsample_step=subsample_step, verbose=1,\n",
    "            kernel_type=\"HMC\", num_steps=1, step_size=1E-3, adapt_step_size=True\n",
    "        )\n",
    "    # NUTS, defaults except limiting tree depth, to save on calls to\n",
    "    # the slow model. Much slower, but should theoretically get much more\n",
    "    # diversity as long as it doesn't diverge.\n",
    "    elif hmc_strategy==\"NUTS\":\n",
    "        sampled_trees = do_fixed_structure_hmc_with_constraint_penalties(\n",
    "            grammar, tree, num_samples=num_samples, subsample_step=subsample_step, verbose=1,\n",
    "            kernel_type=\"NUTS\", max_tree_depth=4\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(hmc_strategy)\n",
    "    \n",
    "    \n",
    "    # Finally, subsample the sampled trees as requested and return\n",
    "    # the sampled set.\n",
    "    return sampled_trees\n",
    "\n",
    "def collect_posterior_sample_sets(grammar, observed_node_sets):\n",
    "    posterior_sample_sets = []\n",
    "    for observed_nodes in tqdm(observed_node_sets, desc='Collecting posterior samples'):\n",
    "        posterior_samples = get_posterior_tree_samples_from_observation(\n",
    "            grammar, observed_nodes, verbose=0, hmc_strategy=\"NUTS\", num_samples=20, subsample_step=1)\n",
    "        if posterior_samples is not None:\n",
    "            posterior_sample_sets.append(posterior_samples)\n",
    "    return posterior_sample_sets\n",
    "posterior_sample_sets = collect_posterior_sample_sets(grammar, observed_node_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, tree in enumerate(posterior_sample_sets[-1]):\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"guesses/%d\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(grammar, \"/tmp/test_saved_grammar.torch\")\n",
    "orig_grammar = torch.load(\"/tmp/test_saved_grammar.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now do gradient descent on the grammar parameters\n",
    "# by summing the score of all of those trees.\n",
    "\n",
    "def fit_grammar_params_to_sample_sets(grammar, posterior_sample_sets):\n",
    "    # Reattach tree params to prepare for grad descent.\n",
    "    tree_set = sum(posterior_sample_sets, [])\n",
    "    tree_set = [deepcopy(tree) for tree in tree_set]\n",
    "\n",
    "    def calc_mean_score(tree_set):\n",
    "        total_score = 0.\n",
    "        total_k = 0.\n",
    "        for tree in tree_set:\n",
    "            total_score = total_score + tree.score()\n",
    "            total_k += 1\n",
    "        return total_score / total_k\n",
    "\n",
    "    log_by_node_type = {node_type.__name__: [] for node_type in grammar.all_types}\n",
    "    def log_params(grammar):\n",
    "        for node_type_name, params in grammar.params_by_node_type.items():\n",
    "            if params is not None:\n",
    "                log_by_node_type[node_type_name].append(params().detach())\n",
    "\n",
    "    optimizer = torch.optim.Adam(grammar.parameters(), lr=0.01)\n",
    "    pbar = tqdm(range(50), desc=\"Optimizing parameters\")\n",
    "    score_history = []\n",
    "    for step_k in pbar:\n",
    "        # Update parameter settings\n",
    "        log_params(grammar)\n",
    "        for tree in tree_set:\n",
    "            grammar.update_tree_grammar_parameters(tree)\n",
    "        score = calc_mean_score(tree_set)\n",
    "        score_history.append(score)\n",
    "        # Gradient step\n",
    "        optimizer.zero_grad()\n",
    "        (-score).backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        pbar.set_description(\"Mean score %2.2f\" % score)\n",
    "    return grammar, score_history\n",
    "\n",
    "if 0:\n",
    "    grammar, score_history = fit_grammar_params_to_sample_sets(grammar, posterior_sample_sets)\n",
    "    plt.plot(score_history)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.title(\"Score history\")\n",
    "    print(\"**********************************\\n\"\n",
    "          \"**********  BEFORE ***************\\n\"\n",
    "          \"************************************\")\n",
    "    orig_grammar.print_params(node_names=[\"Desk\"])\n",
    "    print(\"**********************************\\n\"\n",
    "          \"**********  AFTER ***************\\n\"\n",
    "          \"************************************\")\n",
    "    grammar.print_params(node_names=[\"Desk\"])\n",
    "    print(\"**********************************\\n\"\n",
    "          \"**********  TRUTH ***************\\n\"\n",
    "          \"************************************\")\n",
    "    ground_truth_grammar.print_params(node_names=[\"Desk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76267171622640a5b3eb209f2259ff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting posterior samples:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 30/30 [00:30,  1.02s/it, step size=2.83e-03, acc. prob=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                        mean       std    median     25.0%     75.0%     n_eff     r_hat\n",
      "    Desk_84/ObjectCluster_153/AxisAlignedGaussianOffsetRule_xyz[0]      0.80      0.01      0.80      0.80      0.80      6.37      1.82\n",
      "    Desk_84/ObjectCluster_153/AxisAlignedGaussianOffsetRule_xyz[1]      0.73      0.01      0.73      0.73      0.74     10.03      1.06\n",
      "    Desk_84/ObjectCluster_153/AxisAlignedGaussianOffsetRule_xyz[2]     -0.00      0.01     -0.00     -0.00      0.00    -28.55      0.96\n",
      "        Desk_84/ObjectCluster_153/GaussianChordOffsetRule_theta[0]     -0.91      0.04     -0.91     -0.93     -0.88      2.74      2.13\n",
      "    Desk_84/ObjectCluster_154/AxisAlignedGaussianOffsetRule_xyz[0]      0.34      0.03      0.35      0.35      0.38      3.19      1.66\n",
      "    Desk_84/ObjectCluster_154/AxisAlignedGaussianOffsetRule_xyz[1]      0.43      0.02      0.43      0.42      0.45      9.18      0.96\n",
      "    Desk_84/ObjectCluster_154/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.01      0.00     19.96      0.95\n",
      "        Desk_84/ObjectCluster_154/GaussianChordOffsetRule_theta[0]      0.11      0.01      0.11      0.11      0.11     13.02      0.97\n",
      "    Desk_84/ObjectCluster_155/AxisAlignedGaussianOffsetRule_xyz[0]      0.52      0.02      0.53      0.52      0.54      7.37      1.61\n",
      "    Desk_84/ObjectCluster_155/AxisAlignedGaussianOffsetRule_xyz[1]      0.17      0.02      0.16      0.16      0.17      4.96      1.22\n",
      "    Desk_84/ObjectCluster_155/AxisAlignedGaussianOffsetRule_xyz[2]      0.01      0.01      0.00      0.00      0.01     21.97      0.95\n",
      "        Desk_84/ObjectCluster_155/GaussianChordOffsetRule_theta[0]     -0.52      0.02     -0.52     -0.53     -0.51      8.76      1.17\n",
      "    Desk_84/ObjectCluster_156/AxisAlignedGaussianOffsetRule_xyz[0]      1.00      0.02      1.00      0.99      1.01      6.89      1.16\n",
      "    Desk_84/ObjectCluster_156/AxisAlignedGaussianOffsetRule_xyz[1]      0.47      0.01      0.46      0.45      0.47     10.12      1.04\n",
      "    Desk_84/ObjectCluster_156/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.01     -0.00      0.01     57.13      1.01\n",
      "        Desk_84/ObjectCluster_156/GaussianChordOffsetRule_theta[0]     -1.90      0.02     -1.91     -1.92     -1.90      4.27      1.38\n",
      "    Desk_84/ObjectCluster_157/AxisAlignedGaussianOffsetRule_xyz[0]      0.82      0.03      0.81      0.79      0.81      3.20      1.66\n",
      "    Desk_84/ObjectCluster_157/AxisAlignedGaussianOffsetRule_xyz[1]      0.85      0.03      0.86      0.85      0.87     10.15      0.95\n",
      "    Desk_84/ObjectCluster_157/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.00      0.00     21.96      0.98\n",
      "        Desk_84/ObjectCluster_157/GaussianChordOffsetRule_theta[0]     -0.80      0.02     -0.80     -0.81     -0.80      5.46      1.40\n",
      "    Desk_84/ObjectCluster_158/AxisAlignedGaussianOffsetRule_xyz[0]      0.52      0.02      0.52      0.51      0.54      8.99      1.16\n",
      "    Desk_84/ObjectCluster_158/AxisAlignedGaussianOffsetRule_xyz[1]      0.29      0.02      0.29      0.28      0.30      8.77      1.13\n",
      "    Desk_84/ObjectCluster_158/AxisAlignedGaussianOffsetRule_xyz[2]      0.01      0.01      0.01      0.00      0.01     29.28      0.95\n",
      "        Desk_84/ObjectCluster_158/GaussianChordOffsetRule_theta[0]     -1.49      0.06     -1.51     -1.55     -1.47      2.65      2.39\n",
      " PencilCluster_125/Pencil_169/AxisAlignedGaussianOffsetRule_xyz[0]     -0.02      0.01     -0.02     -0.03     -0.02     14.78      1.22\n",
      " PencilCluster_125/Pencil_169/AxisAlignedGaussianOffsetRule_xyz[1]     -0.01      0.01     -0.01     -0.01      0.00     21.63      1.00\n",
      " PencilCluster_125/Pencil_169/AxisAlignedGaussianOffsetRule_xyz[2]     -0.01      0.01     -0.00     -0.00      0.01    -95.98      0.95\n",
      "     PencilCluster_125/Pencil_169/GaussianChordOffsetRule_theta[0]      2.79      0.04      2.79      2.79      2.85      2.57      2.25\n",
      " PencilCluster_125/Pencil_170/AxisAlignedGaussianOffsetRule_xyz[0]      0.02      0.01      0.02      0.02      0.03     15.06      1.25\n",
      " PencilCluster_125/Pencil_170/AxisAlignedGaussianOffsetRule_xyz[1]     -0.00      0.01     -0.00     -0.01      0.01     15.57      0.96\n",
      " PencilCluster_125/Pencil_170/AxisAlignedGaussianOffsetRule_xyz[2]     -0.01      0.01     -0.01     -0.02     -0.00    332.03      0.95\n",
      "     PencilCluster_125/Pencil_170/GaussianChordOffsetRule_theta[0]      1.55      0.04      1.54      1.53      1.59      2.68      2.07\n",
      "   PaperCluster_125/Paper_162/AxisAlignedGaussianOffsetRule_xyz[0]     -0.02      0.03     -0.03     -0.06     -0.03      3.30      1.67\n",
      "   PaperCluster_125/Paper_162/AxisAlignedGaussianOffsetRule_xyz[1]     -0.02      0.02     -0.02     -0.02      0.01      8.93      0.97\n",
      "   PaperCluster_125/Paper_162/AxisAlignedGaussianOffsetRule_xyz[2]     -0.01      0.02     -0.00     -0.01      0.01     16.89      0.96\n",
      "       PaperCluster_125/Paper_162/GaussianChordOffsetRule_theta[0]      1.56      0.01      1.56      1.55      1.57     18.35      1.03\n",
      "FoodWasteCluster_125/Plate_90/AxisAlignedGaussianOffsetRule_xyz[0]     -0.12      0.02     -0.13     -0.14     -0.12      7.41      1.59\n",
      "FoodWasteCluster_125/Plate_90/AxisAlignedGaussianOffsetRule_xyz[1]     -0.13      0.02     -0.13     -0.14     -0.12      6.70      1.16\n",
      "FoodWasteCluster_125/Plate_90/AxisAlignedGaussianOffsetRule_xyz[2]     -0.00      0.01     -0.00     -0.00      0.00    245.15      0.95\n",
      "    FoodWasteCluster_125/Plate_90/GaussianChordOffsetRule_theta[0]     -1.26      0.02     -1.26     -1.27     -1.26      9.29      1.03\n",
      "FoodWasteCluster_125/Drink_90/AxisAlignedGaussianOffsetRule_xyz[0]     -0.06      0.02     -0.06     -0.07     -0.05      9.72      1.27\n",
      "FoodWasteCluster_125/Drink_90/AxisAlignedGaussianOffsetRule_xyz[1]     -0.20      0.02     -0.20     -0.22     -0.19      6.40      1.17\n",
      "FoodWasteCluster_125/Drink_90/AxisAlignedGaussianOffsetRule_xyz[2]     -0.00      0.01     -0.01     -0.02     -0.01     59.44      0.96\n",
      "    FoodWasteCluster_125/Drink_90/GaussianChordOffsetRule_theta[0]      2.86      0.02      2.86      2.86      2.88      8.88      1.07\n",
      "   PaperCluster_126/Paper_163/AxisAlignedGaussianOffsetRule_xyz[0]     -0.01      0.02     -0.01     -0.01      0.01      6.68      1.19\n",
      "   PaperCluster_126/Paper_163/AxisAlignedGaussianOffsetRule_xyz[1]      0.01      0.01      0.01      0.01      0.01     13.39      0.99\n",
      "   PaperCluster_126/Paper_163/AxisAlignedGaussianOffsetRule_xyz[2]     -0.03      0.01     -0.04     -0.05     -0.03     23.18      1.08\n",
      "       PaperCluster_126/Paper_163/GaussianChordOffsetRule_theta[0]      0.92      0.02      0.91      0.90      0.93      4.17      1.45\n",
      "FoodWasteCluster_126/Plate_91/AxisAlignedGaussianOffsetRule_xyz[0]     -0.05      0.03     -0.05     -0.06     -0.03      3.54      1.52\n",
      "FoodWasteCluster_126/Plate_91/AxisAlignedGaussianOffsetRule_xyz[1]     -0.02      0.02     -0.02     -0.03     -0.02      9.93      0.97\n",
      "FoodWasteCluster_126/Plate_91/AxisAlignedGaussianOffsetRule_xyz[2]     -0.01      0.01     -0.01     -0.01     -0.00     26.15      0.99\n",
      "    FoodWasteCluster_126/Plate_91/GaussianChordOffsetRule_theta[0]     -1.62      0.02     -1.61     -1.63     -1.61      6.31      1.28\n",
      "FoodWasteCluster_126/Drink_91/AxisAlignedGaussianOffsetRule_xyz[0]     -0.01      0.03     -0.01     -0.02      0.01      3.93      1.58\n",
      "FoodWasteCluster_126/Drink_91/AxisAlignedGaussianOffsetRule_xyz[1]     -0.10      0.03     -0.11     -0.12     -0.10     10.18      0.95\n",
      "FoodWasteCluster_126/Drink_91/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.00     -0.00      0.01    -45.71      0.95\n",
      "    FoodWasteCluster_126/Drink_91/GaussianChordOffsetRule_theta[0]      1.52      0.02      1.52      1.52      1.54      6.52      1.26\n",
      " PencilCluster_126/Pencil_171/AxisAlignedGaussianOffsetRule_xyz[0]     -0.01      0.02     -0.02     -0.02      0.01     11.67      1.13\n",
      " PencilCluster_126/Pencil_171/AxisAlignedGaussianOffsetRule_xyz[1]      0.00      0.02      0.01      0.01      0.02      7.76      1.16\n",
      " PencilCluster_126/Pencil_171/AxisAlignedGaussianOffsetRule_xyz[2]      0.00      0.01      0.01      0.00      0.02    -41.42      0.95\n",
      "     PencilCluster_126/Pencil_171/GaussianChordOffsetRule_theta[0]      1.32      0.06      1.32      1.30      1.36      2.66      2.32\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddbd6cb68cc45a590a54fda558c0327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing parameters:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_dict_history = []\n",
    "for iter_k in range(10):\n",
    "    state_dict_history.append(deepcopy(grammar.state_dict()))\n",
    "    posterior_sample_sets = collect_posterior_sample_sets(grammar, observed_node_sets)\n",
    "    fit_grammar_params_to_sample_sets(grammar, posterior_sample_sets)    \n",
    "state_dict_history.append(deepcopy(grammar.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a couple of interesting parameters\n",
    "param_getters_of_interest = {\n",
    "    \"Desk child mean: \", lambda x: x.rule_params_by_node_type[\"Desk\"][0][0][\"mean\"]().detach().numpy()\n",
    "    \"Desk child var: \", lambda x: x.rule_params_by_node_type[\"Desk\"][0][0][\"variance\"]().detach().numpy(),\n",
    "    \"Desk child rate: \", lambda x: x.params_by_node_type[\"Desk\"]().detach().numpy()\n",
    "}\n",
    "\n",
    "for key, getter in param_getters_of_interest.items():\n",
    "    plt.figure()\n",
    "    history = []\n",
    "    for state_dict in state_dict_history:\n",
    "        grammar.load_state_dict(state_dict)\n",
    "        history.append(getter(grammar)\n",
    "                       \n",
    "    plt.plot(history)\n",
    "    plt.xlabel(\"Iter\")\n",
    "    plt.ylabel(key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "py36_pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
