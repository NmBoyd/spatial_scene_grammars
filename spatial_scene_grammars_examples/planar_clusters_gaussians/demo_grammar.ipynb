{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.visualization import *\n",
    "from spatial_scene_grammars_examples.planar_clusters_gaussians.grammar import *\n",
    "from spatial_scene_grammars.parsing import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "from spatial_scene_grammars.parameter_estimation import *\n",
    "\n",
    "import meshcat\n",
    "import meshcat.geometry as meshcat_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7003/static/\n",
      "Meshcat url:  http://127.0.0.1:7003/static/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "    <iframe src=\"http://127.0.0.1:7003/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'vis' not in globals():\n",
    "    vis = meshcat.Visualizer()\n",
    "vis.delete()\n",
    "base_url = \"http://127.0.0.1\"\n",
    "meshcat_url = base_url + \":\" + vis.url().split(\":\")[-1]\n",
    "print(\"Meshcat url: \", meshcat_url)\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
    "    <iframe src=\"{url}\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
    "</div>\n",
    "\"\"\".format(url=meshcat_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6981d81e7a47c280c21ad02daad214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving...\n",
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-09-08 02:03:26.029] [console] [warning] FindResource ignoring DRAKE_RESOURCE_ROOT='/home/gizatt/drake' because it does not contain a 'drake' subdirectory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 scenes.\n"
     ]
    }
   ],
   "source": [
    "# Sample a dataset of scenes from the default grammar params.\n",
    "# Draw a random sample from the grammar and visualize it.\n",
    "# (Cache output.)\n",
    "torch.random.manual_seed(2)\n",
    "N_samples = 50\n",
    "RESAMPLE = True\n",
    "scenes_file = \"sampled_scenes_%d.dat\" % N_samples\n",
    "\n",
    "ground_truth_grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4)\n",
    ")\n",
    "\n",
    "if not os.path.exists(scenes_file) or RESAMPLE:\n",
    "    samples = []\n",
    "    for k in tqdm(range(N_samples)):\n",
    "        tree = ground_truth_grammar.sample_tree(detach=True)\n",
    "        observed_nodes = tree.get_observed_nodes()\n",
    "        samples.append((tree, observed_nodes))\n",
    "\n",
    "    print(\"Saving...\")\n",
    "    with open(scenes_file, \"wb\") as f:\n",
    "        pickle.dump(samples, f)\n",
    "\n",
    "print(\"Loading...\")\n",
    "with open(scenes_file, \"rb\") as f:\n",
    "    samples = pickle.load(f)\n",
    "print(\"Loaded %d scenes.\" % len(samples))\n",
    "observed_node_sets = [x[1] for x in samples]\n",
    "\n",
    "draw_scene_tree_contents_meshcat(samples[0][0], zmq_url=vis.window.zmq_url, prefix=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a grammar with wide parameter guesses.\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4),\n",
    "    sample_params_from_prior=True\n",
    ")\n",
    "\n",
    "def do_vis(tree):\n",
    "    draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"sampled_in_progress\")\n",
    "    \n",
    "\n",
    "\n",
    "if 0:\n",
    "    posterior_sample_sets = collect_posterior_sample_sets(grammar, observed_node_sets)\n",
    "    for k, tree in enumerate(posterior_sample_sets[-1]):\n",
    "        draw_scene_tree_structure_meshcat(tree, zmq_url=vis.window.zmq_url, prefix=\"guesses/%d\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(grammar, \"/tmp/test_saved_grammar.torch\")\n",
    "orig_grammar = torch.load(\"/tmp/test_saved_grammar.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    grammar = fit_grammar_params_to_sample_sets_with_uninformative_prior(grammar, posterior_sample_sets)\n",
    "    print(\"**********************************\\n\"\n",
    "          \"**********  BEFORE ***************\\n\"\n",
    "          \"************************************\")\n",
    "    orig_grammar.print_params(node_names=[\"Desk\"])\n",
    "    print(\"**********************************\\n\"\n",
    "          \"**********  AFTER ***************\\n\"\n",
    "          \"************************************\")\n",
    "    grammar.print_params(node_names=[\"Desk\"])\n",
    "    print(\"**********************************\\n\"\n",
    "          \"**********  TRUTH ***************\\n\"\n",
    "          \"************************************\")\n",
    "    ground_truth_grammar.print_params(node_names=[\"Desk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e32ddbc47d141e88e660a9618f4d33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Major iteration', max=20.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Multiprocessing takes tons of FDs: make sure ulimit is large (~100k).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779d2457aa0b4b0da67de1dc6d192303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Multiprocessing takes tons of FDs: make sure ulimit is large (~100k).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d637fd07fa97482ba141bf6cb5cc64a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gizatt/miniconda3/envs/py36_pyro/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/gizatt/miniconda3/envs/py36_pyro/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gizatt/miniconda3/envs/py36_pyro/lib/python3.6/multiprocessing/pool.py\", line 463, in _handle_results\n",
      "    task = get()\n",
      "  File \"/home/gizatt/miniconda3/envs/py36_pyro/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "MemoryError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_dict_history = []\n",
    "for iter_k in tqdm(range(20), desc=\"Major iteration\"):\n",
    "    state_dict_history.append(deepcopy(grammar.state_dict()))\n",
    "    posterior_sample_sets = collect_posterior_sample_sets(grammar, observed_node_sets, num_workers=8, tqdm=tqdm)\n",
    "    # Check out if it does good fitting on the sample set itself -- which it should!\n",
    "    #posterior_sample_sets = [[x[0] for x in samples]]\n",
    "    grammar = fit_grammar_params_to_sample_sets_with_uninformative_prior(grammar, posterior_sample_sets)\n",
    "state_dict_history.append(deepcopy(grammar.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a couple of interesting parameters\n",
    "param_getters_of_interest = {\n",
    "    \"Desk child xyz mean: \": lambda x: x.rule_params_by_node_type[\"Desk\"][0][0][\"mean\"]().detach().numpy(),\n",
    "    \"Desk child xyz var: \": lambda x: x.rule_params_by_node_type[\"Desk\"][0][0][\"variance\"]().detach().numpy(),\n",
    "    \"Desk child rot loc: \": lambda x: x.rule_params_by_node_type[\"Desk\"][0][1][\"loc\"]().detach().numpy(),\n",
    "    \"Desk child rot var: \": lambda x: x.rule_params_by_node_type[\"Desk\"][0][1][\"concentration\"]().detach().numpy(),\n",
    "    \"Pencil child rot var: \": lambda x: x.rule_params_by_node_type[\"PencilCluster\"][0][1][\"concentration\"]().detach().numpy(),\n",
    "    \"Desk child rate: \": lambda x: x.params_by_node_type[\"Desk\"]().detach().numpy(),\n",
    "    \"Object cluster child rate: \": lambda x: x.params_by_node_type[\"ObjectCluster\"]().detach().numpy(),\n",
    "    \"FoodWasteCluster child rate: \": lambda x: x.params_by_node_type[\"FoodWasteCluster\"]().detach().numpy(),\n",
    "    \n",
    "}\n",
    "\n",
    "for key, getter in param_getters_of_interest.items():\n",
    "    plt.figure()\n",
    "    history = []\n",
    "    for state_dict in state_dict_history:\n",
    "        grammar.load_state_dict(state_dict)\n",
    "        history.append(getter(grammar).copy().flatten())\n",
    "    data = np.stack(history)\n",
    "\n",
    "    gt_x = getter(ground_truth_grammar).flatten()\n",
    "    cm = plt.get_cmap(\"viridis\")\n",
    "    N = len(gt_x)\n",
    "    for k in range(N):\n",
    "        color = cm(k / max(1, N))\n",
    "        plt.plot(data[:, k], color=color)\n",
    "        plt.axhline(gt_x[k], color=color, linestyle=\"--\")\n",
    "    plt.xlabel(\"Iter\")\n",
    "    plt.ylabel(key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "py36_pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
