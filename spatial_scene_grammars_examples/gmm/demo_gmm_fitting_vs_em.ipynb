{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.visualization import *\n",
    "from spatial_scene_grammars_examples.gmm.grammar import *\n",
    "from spatial_scene_grammars.parsing import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "from spatial_scene_grammars.parameter_estimation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "GT Mode 0: [-5. -5. -5.] +/- [1.  1.5 3.5]\n",
      "GT Mode 1: [5. 5. 5.] +/- [1.25 0.25 0.25]\n",
      "GT Mode 2: [-2.  0.  2.] +/- [1.  2.  1.5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac32df46ee0d402b8a8bafbe7927bf88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4383f47ce7cf43f28997ef2f536c4cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make the ground truth GMM grammar.\n",
    "pyro.set_rng_seed(42)\n",
    "gt_grammar =SpatialSceneGrammar(\n",
    "    root_node_type = Root,\n",
    "    root_node_tf = torch.eye(4),\n",
    "    sample_params_from_prior=True\n",
    ")\n",
    "root_prototype = Root(gt_grammar.root_node_tf)\n",
    "\n",
    "# Reset params to values we control (different from prior).\n",
    "desired_mode_means = [\n",
    "    torch.tensor([-5., -5., -5.]),\n",
    "    torch.tensor([5., 5., 5.]),\n",
    "    torch.tensor([-2., 0., 2.])\n",
    "]\n",
    "desired_mode_vars = [\n",
    "    torch.tensor([1.0, 1.5, 3.5]),\n",
    "    torch.tensor([1.25, 0.25, 0.25]),\n",
    "    torch.tensor([1., 2., 1.5])\n",
    "]\n",
    "desired_mode_weights = torch.tensor([0.4, 0.4, 0.2])\n",
    "rule_probs_param = gt_grammar.params_by_node_type[\"Root\"]\n",
    "rule_probs_param.set(desired_mode_weights)\n",
    "print(\"GT rule probs: \", rule_probs_param())\n",
    "for k, rule_params in enumerate(gt_grammar.rule_params_by_node_type[\"Root\"]):\n",
    "    mode_name = \"Mode_%d\" % k\n",
    "    mean_param = rule_params[0][\"mean\"]\n",
    "    mean_param.set(desired_mode_means[k])\n",
    "    var_param = rule_params[0][\"variance\"]\n",
    "    var_param.set(desired_mode_vars[k])\n",
    "    print(\"GT Mode %d: %s +/- %s\" % (k, mean_param().detach().numpy(), var_param().detach().numpy()))\n",
    "    \n",
    "    \n",
    "# Make our fitting grammar. This'll also have randomly sampled means + vars, but\n",
    "# different ones.\n",
    "torch.random.manual_seed(3)\n",
    "fit_grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Root,\n",
    "    root_node_tf = torch.eye(4),\n",
    "    sample_params_from_prior=True\n",
    ")\n",
    "initial_mode_means = [\n",
    "    torch.tensor([-2., -2., -2.]),\n",
    "    torch.tensor([2., 2., 2.]),\n",
    "    torch.tensor([-1., 0., 1.])\n",
    "]\n",
    "initial_mode_vars , 1.5, 3.5]),\n",
    "    torch.tensor([1.25, 0.25, 0.25]),\n",
    "    torch.tensor([1., 2., 1.5])\n",
    "]\n",
    "initial_mode_weights = torch.tensor([0.333, 0.333, 0.333])\n",
    "rule_probs_param = fit_grammar.params_by_node_type[\"Root\"]\n",
    "rule_probs_param.set(desired_mode_weights)\n",
    "for k, rule_params in enumerate(fit_grammar.rule_params_by_node_type[\"Root\"]):\n",
    "    mode_name = \"Mode_%d\" % k\n",
    "    mean_param = rule_params[0][\"mean\"]\n",
    "    mean_param.set(initial_mode_means[k])\n",
    "    var_param = rule_params[0][\"variance\"]\n",
    "    var_param.set(initial_mode_vars[k])\n",
    "#fit_grammar = deepcopy(gt_grammar)\n",
    "pre_fit_grammar = deepcopy(fit_grammar)\n",
    "\n",
    "def get_all_node_xyzs(sampled_trees, node_type):\n",
    "    l = []\n",
    "    for tree in sampled_trees:\n",
    "        for node in tree:\n",
    "            if isinstance(node, node_type):\n",
    "                l.append(node.translation.detach().cpu().numpy())\n",
    "    return np.stack(l)\n",
    "\n",
    "# Draw random samples from our randomly-initialized GMM\n",
    "def get_draws_from_grammar(grammar, N_samples):\n",
    "    samples = []\n",
    "    for k in tqdm(range(N_samples)):\n",
    "        tree = grammar.sample_tree(detach=True)\n",
    "        observed_nodes = tree.get_observed_nodes()\n",
    "        samples.append((tree, observed_nodes))\n",
    "    return samples\n",
    "\n",
    "gt_samples = get_draws_from_grammar(gt_grammar, 1000)\n",
    "pre_fit_samples = get_draws_from_grammar(fit_grammar, 1000)\n",
    "l_gt = get_all_node_xyzs([sample[0] for sample in gt_samples], Point)\n",
    "l_pre_fit = get_all_node_xyzs([sample[0] for sample in pre_fit_samples], Point)\n",
    "for k, label in enumerate(\"xyz\"):\n",
    "    plt.subplot(1, 3, k+1)\n",
    "    plt.hist(l_gt[:, k], bins=25, label=\"GT\", alpha=0.5)\n",
    "    plt.hist(l_pre_fit[:, k], bins=25, label=\"Pre fit\", alpha=0.5)\n",
    "    plt.title(label)\n",
    "    if k == 2:\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}, {})\n",
      "Optimization success?:  True\n",
      "Logfile: \n",
      "\n",
      "Gurobi 9.0.2 (linux64) logging started Wed Jan 12 15:52:14 2022\n",
      "\n",
      "Gurobi Optimizer version 9.0.2 build v9.0.2rc0 (linux64)\n",
      "Optimize a model with 31 rows, 15 columns and 67 nonzeros\n",
      "Model fingerprint: 0xd1a54dc6\n",
      "Variable types: 0 continuous, 15 integer (15 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-01, 1e+00]\n",
      "  Objective range  [9e-01, 4e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective 351.9636972\n",
      "Presolve removed 30 rows and 12 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 1 rows, 3 columns, 3 nonzeros\n",
      "Variable types: 0 continuous, 3 integer (3 binary)\n",
      "Found heuristic solution: objective 21.5640130\n",
      "\n",
      "Root relaxation: objective 5.302449e+00, 1 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       5.3024494    5.30245  0.00%     -    0s\n",
      "\n",
      "Optimal solution found at node 0 - now completing solution pool...\n",
      "\n",
      "    Nodes    |    Current Node    |      Pool Obj. Bounds     |     Work\n",
      "             |                    |   Worst                   |\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0       351.96370    5.30245  98.5%     -    0s\n",
      "     0     0          -    0       351.96370    5.30245  98.5%     -    0s\n",
      "     0     2          -    0       351.96370    5.30245  98.5%     -    0s\n",
      "\n",
      "Explored 5 nodes (2 simplex iterations) in 0.00 seconds\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 5.30245 21.564 351.964 \n",
      "No other solutions better than 351.964\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-03)\n",
      "Best objective 5.302449362583e+00, best bound 5.302449362583e+00, gap 0.0000%\n",
      "\n",
      "Building tree for sol 0...\n",
      "Added Root_2005--(0)>Point_2010\n",
      "Building tree for sol 1...\n",
      "Added Root_2006--(2)>Point_2011\n",
      "Building tree for sol 2...\n",
      "Added Root_2007--(1)>Point_2012\n"
     ]
    }
   ],
   "source": [
    "# Try parsing this grammar\n",
    "pyro.set_rng_seed(42)\n",
    "test_tree = gt_grammar.sample_tree(detach=True)\n",
    "print(test_tree.get_root().rules[0].parameters)\n",
    "test_observed = test_tree.get_observed_nodes()\n",
    "mip_optimized_trees = infer_mle_tree_with_mip_from_proposals(\n",
    "    gt_grammar, test_observed, {}, verbose=2, N_solutions=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb88c2194c97440ca4931e00e446a139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgbklEQVR4nO3df3CdV33n8fenlpVAgMS11TRcKbGNEk2sDRNAcnanLewCiYwoctqaIGi3yTqdlKnMzoSyJfwYQUXTKqEldNYui4FsKR1b0FCwprGduqQsS0v8I8EYrNSxsYIttRscJ4RmjKNY/u4f95FzdXVtXVu6v577ec1o/DznOc+95+pcf3We8zznHEUEZmaWXj9X6QKYmVlpOdCbmaWcA72ZWco50JuZpZwDvZlZyjVUugD5lixZEkuXLq10MQx49NFHn46Ipvl6PddtdXC9ptO56rXqAv3SpUvZs2dPpYthgKQfzefruW6rg+s1nc5Vr+66MTNLOQd6M7OUc6A3S5nt27fT1tZGa2srg4ODhbI0Sfq+pL2Svi1pxdQBSR+SdEjSAUld5Su1lVLV9dGb2YWbnJykr6+PHTt20NzcTGdnJz09PaxYsSI32/GIeD2ApB7gU8CqJOD3Au3Aq4F/kHRNREyebzlefPFFxsbGOHny5Nw/VAVcfPHFNDc3s3DhwkoXZV440JulyK5du2htbWX58uUA9Pb2smXLlvxAfzpn+xJgasKr1cBQRLwAjEo6BKwEvnO+5RgbG+OVr3wlS5cuRdKFfJSKiQiOHz/O2NgYy5Ytq3Rx5oW7buqYL/HTZ3x8nJaWljP7zc3NjI+Pz8gnqU/SD4F7gf+eJGeAoznZxpK0QuffIWmPpD3Hjh2bcfzkyZMsXry45oI8gCQWL15cs1cjhTjQ16mpS/xt27YxMjLC5s2bGRkZyc92PCKui4jryQaETwHkXeKvAv5C0oIyFt/mKCI2RMRrgA8CH72A8zdGREdEdDQ1FX4kvxaD/JRaLnshDvR1KvcSv7Gx8cwlfp5ZL/EjYhSYusS3CstkMhw9+lKjfGxsjEymYKN8yhBwc7I9DrTkHGtO0qzGuY++ThW6xN+5c+eMfJL6gPcDjcCbk+QM8EhOtnNe4gN3AFx55ZXzUXQ7h87OTg4ePMjo6CiZTIahoSE2bdqUn+2inO23AweT7WFgk6RPkb0ZezWwaz7Kdd+OJ+bjZc6488ZrZs3z1FNPceedd/LII4+waNEiGhsb+elPf8rChQuZmJhgdHSUtrY2AD760Y+yZs2aeS1jNUl1oM//chXz5bDpImIDsEHSe8he4t96nudvBDYCdHR0eJWbeZL73c79Xjc0NLB+/Xq6urqYnJxk7dq1tLe309/fT0dHBz09PQC/IGk/8CLwLEmdRsR+SV8BRoBTQN+FPHFTDSKCm2++mVtvvfXMH7of/ehHDA8P8773vY8nn3ySX/3VX2Xv3r2VLWieUsWsVAd6O7sLvMT/TLLtS/wq1t3dTXd397S0gYGB3N2jEdFR6NyIuBu4u3SlK4+HH36YxsZG3vve955Ju+qqq3jf+95XwVJVjvvo61TuJf7ExARDQ0NTrb1c57rE75V0kaRlzOMlvtl82L9/P69//esrXYyq4RZ9nfIlvtWTvr4+vv3tb9PY2Mju3bsrXZyyc6CvY77Et7Rqb2/nq1/96pn9DRs28PTTT9PRUfDrnHruujGz1Hnzm9/MyZMn+cxnPnMm7cSJExUsUWUV1aKXtAr4c2AB8PmIGMw7/kbg08Brgd6IeCDn2JXA58nevAugOyKenI/Cm1ltKPcTb5L4+te/zp133sm9995LU1MTl1xyCffcc09Zy1EtZg30yYjHDcCNZJ+X3i1pOCJyh1EeAW4DPlDgJf4KuDsidkh6BdMH4ZiZlcQVV1zB0NBQwWNLly7lBz/4QZlLVDnFtOhXAoci4jCApCGyIyPPBPqpFrqkaUE8GSrfEBE7knzPz0+xzcysWMX00Rc90VEB1wA/kfS3kr4r6ZOF5kSZbYIkMzO7cKW+GdsA/ArZLp1OYDnZLp5pipkgycxqS0TtDoSu5bIXUkygn8soyDFgb0QcjohTwNcBj2IwS7mLL76Y48eP12TAnJqP/uKLL650UeZNMX30u4GrkxGQ42Snp31Pka+/G7hMUlNEHCM7KZaXizdLuebmZsbGxqjVrtipFabSYtZAHxGnJK0DHiL7eOX9ycjIAWBPRAxL6gS+BiwC3iHpDyOiPSImJX0A+IayEzw/CnyudB/HzKrBwoULU7M6UxoU9Rx9RGwFtual9eds7ybbpVPo3B1kn683M7MK8MhYM7OUc6A3M0s5B3ozs5RzoDczSzkHejOzlHOgNzNLOQd6M7OUc6A3M0s5LyWYAvfteOLMdrkXeDCz6ucWvZlZyjnQm5mlnAO9mVnKuY++BuX2yZuZzcYterOU2b59O21tbbS2tjI4OFgoy+WSRiTtk/QNSVdNHZA0KWlv8jNcvlJbKTnQm6XI5OQkfX19bNu2jZGRETZv3szIyEh+thNAR0S8FngAuDfn2M8i4vrkp6dc5bbScqCvY275pc+uXbtobW1l+fLlNDY20tvby5YtW/Kz/XtEnEi2H+Esa0lYehQV6CWtknRA0iFJdxU4/kZJj0k6JWlNgeOvkjQmaf18FNrmzi2/dBofH6el5aUlnpubmxkfP+cSz7cD23L2L5a0R9Ijkm4+20mS7kjy7anV5QLryayBXtICYAPwNmAF8G5JK/KyHQFuAzad5WU+AXzrwotp880tP5P0W0AH8Mmc5KsiooPsutCflvSaQudGxMaI6IiIjqampjKU1uaimBb9SuBQRByOiAlgCFidmyEinoyIfcDp/JMlvQG4HPj7eSivzRO3/NIpk8lw9OjRM/tjY2NkMpkZ+SS9FfgI0BMRL0ylR8R48u9h4JvA60pcZCuDYgJ9Bjiasz+WpM1K0s8BfwZ8YJZ8DgZVzC2/2tHZ2cnBgwcZHR1lYmKCoaEhenpm9Ky9DPgs2SD/46lESYskXZRsLwF+CZjRn2e1p9Q3Y38P2BoRY+fK5GBQfm75pVNDQwPr16+nq6uLa6+9lltuuYX29nb6+/sZHj5zz7wFeAXwN3k3068F9kj6HvCPwGBEONCnQDEDpsbJfjGmNCdpxfhPwK9I+j2yX6xGSc9HxIwbulZeuS2/TCbD0NAQmzbNuMUy1fJbld/yA05ExAs5Lb9780+2yuju7qa7u3ta2sDAQO7uE8nV2DQR8c/AdaUtnVVCMYF+N3C1pGVkA3wv2cv1WUXEb05tS7qN7BMcDvJVILflNzk5ydq1a8+0/Do6OqYu91uAn5Ft+QEcSZ6wuRb4rKTTZK8K3fIzq2KzBvqIOCVpHfAQsAC4PyL2SxoA9kTEsKRO4GvAIuAdkv4wItpLWnKbM7f8zOpDUXPdRMRWYGteWn/O9m5mefQuIv4S+MvzLuF58jwwZmbTeWSsmVnKOdCbmaWcA72ZWco50JuZpZwDvZlZyjnQm5mlnAO9mVnKOdCbmaWcA72ZWco50JuZpZwDvZlZyjnQm5mlXFGTmplZ9cqfyO/OG6+pUEmsWrlFb2aWcg70ZmYpV1Sgl7RK0gFJhyTNWCFK0hslPSbplKQ1OenXS/qOpP2S9kl613wW3szMZjdroJe0ANgAvA1YAbxb0oq8bEeA24D8RUdPAL+drDa1Cvi0pMvmWGYzMzsPxdyMXQkciojDAJKGgNXAmTVCI+LJ5Njp3BMj4omc7X+V9GOgCfjJXAt+IXJvWvmGlZnVi2K6bjLA0Zz9sSTtvEhaCTQCPyxw7A5JeyTtOXbs2Pm+tJmZnUNZbsZKugL4EvDfIuJ0/vGI2BgRHRHR0dTUVI4imZnVjWK6bsaBlpz95iStKJJeBTwIfCQiHjm/4pmZ1a/56m4upkW/G7ha0jJJjUAvMFzMiyf5vwb8VUQ8cMGlNDOzCzZroI+IU8A64CHgceArEbFf0oCkHgBJnZLGgHcCn5W0Pzn9FuCNwG2S9iY/15fig5iZWWFF9dFHxNaIuCYiXhMRdydp/RExnGzvjojmiLgkIhYnj1MSEX8dEQsj4vqcn70l+zRmxvbt22lra6O1tZXBwcFCWS6XNJKMbfmGpKumDki6VdLB5OfW8pXaSskjY81S5PTkJH19fWzbto2RkRE2b97MyMhIfrYTQEdEvBZ4ALgXQNLPAx8DbiD7WPXHJC0qY/GtRBzo65hbfulz5MA+WltbWb58OY2NjfT29rJly5b8bP8eESeS7UfIPmAB0AXsiIhnIuJZYAfZgY5W4xzo69SkW36p9NzTT9HS8tJDcs3NzYyPn/MhuduBbcl20WNmPPaltjjQ16ldu3a55VfnJP0W0AF88nzP9diX2uJAX6fGx8fd8kuhS5dcztGjL1XN2NgYmczMqpH0VuAjQE9EvJAkz2nMjFUvB3qblVt+taOl7ToOHjzI6OgoExMTDA0N0dPTk5/tZcBnyQb5H+ekPwTcJGlR0hV3U5JmNc6Bvk5lMhm3/FJowYIG1q9fT1dXF9deey233HIL7e3t9Pf3Mzx8ZpxjC/AK4G+SsS1Tj0k/A3yC7CDJ3cBAkmY1zksJ1qnOzs4zLb9MJsPQ0BCbNuXPMn2m5beqQMvvj3NuwN4EfKj0pbZidHd3093dPS1tYGAgd/eJiOgodG5E3A/cX7rSWSW4RV+nGhrc8jOrF27R1zG3/Mzqg1v0ZmYp50BvZpZyDvRmZinnQG9mlnIO9GZmKedAb2aWckUFekmrJB2QdEjSXQWOv1HSY5JOSVqTd8zT2ZqZVdCsgV7SAmAD8DZgBfBuSSvysh0BbgM25Z3r6WzNzCqsmBb9SuBQRByOiAlgCFidmyEinoyIfcDpvHM9na2ZWYUVE+iLnpL2Qs/1VLZmZqVTFTdjPZWtmVnpFBPo5zIlraezNTOrsGImNdsNXC1pGdkg3Qu8p8jXr9rpbO/b8cS0/TtvvKZCJTEzK61ZW/QRcQpYRzZoPw58JSL2SxqQ1AMgqVPSGPBO4LOS9ifnejpbM7MKK2qa4ojYCmzNS+vP2d7NSwtH55/r6WzNzCqoKm7GmplZ6TjQm5mlnAO9mVnKeSnBlPHTRGaWzy16M7OUc4u+BuS30s3Mzodb9GZmKedAb2aWcg70ZmYp50BvljLbt2+nra2N1tZWBgcHC2V5xTlWhJuUtDf5GS5Pia3UfDPWLEVOT07S19fHjh07aG5uprOzk56eHlasmLYo3ATZFeE+UOAlfhYR15ehqFZGbtHXMbf80ufIgX20trayfPlyGhsb6e3tZcuWLfnZJs6yIpyllAN9nZpMWn7btm1jZGSEzZs3MzIykp9tquW3acYLJC2/5Ken1OW14jz39FO0tLy0BERzczPj4+e1BMTFyWpvj0i6+WyZvCpcbXGgr1O7du1yy88KuSoiOsiuOfFpSa8plMmrwtUWB/o6NT4+7pZfCl265HKOHn1pmeaxsTEymWKXeIaIGE/+PQx8E3jdPBfRKsCB3i6UW35VqKXtOg4ePMjo6CgTExMMDQ3R01Ncz5qkRZIuSraXAL8EzOjPs9pTVKCXtErSAUmHJN1V4PhFkr6cHN8paWmSvlDSFyV9X9LjkqpiGUGDTCbjll8KLVjQwPr16+nq6uLaa6/llltuob29nf7+foaHz9wzf3mhFeGAa4E9kr4H/CMwGBEO9Ckw6+OVkhYAG4AbgTFgt6ThvC/A7cCzEdEqqRe4B3gX2S/SRRFxnaSXAyOSNkfEk/P9Qez8dHZ2nmn5ZTIZhoaG2LSp0D3XmZI1gE9ExAs5Lb97S1leK153dzfd3d3T0gYGBnJ3T0TEtOctASLin4HrSls6q4RiWvQrgUMRcTgiJoAhYHVentXAF5PtB4C3SBIQwCWSGoCXkX2K46fzUnKbk4YGt/zM6kUxA6YywNGc/THghrPliYhTkp4DFpMN+quBfwNeDtxZaHFwSXcAdwBceeWV5/UBPLPjhXPLz6w+lPpm7EpgEng1sAz4fUnL8zP5hp2ZWekU06IfB1py9puTtEJ5xpJumkuB42SfyNgeES8CP5b0T0AHcHiuBS+13CsFr9JkZrWsmBb9buBqScskNQK9QP6Q92Hg1mR7DfBwRARwBHgzgKRLgP8I/Mt8FNzMzIoza6CPiFPAOuAh4HHgKxGxX9KApKkHdL8ALJZ0CHg/MPUI5gay86XsJ/sH438nIy3NzKxMipq9MiK2Alvz0vpztk+SfTIj/7znC6WbmVn5eGSsmVnKeT56q3n5j9j65rnZdA70ljp+YspsOnfdmJmlnFv0KefWrZm5RW9mlnJu0Sc8Z46ZpZVb9GZmKedAb2aWcg70ZmYp50BvZpZyDvRmZinnp26KcK4ncvxsuplVO7fozcxSzoHezCzligr0klZJOiDpkKS7Chy/SNKXk+M7JS3NOfZaSd+RtF/S9yVdPI/lNzOzWcwa6CUtILtS1NuAFcC7Ja3Iy3Y78GxEtAL3Afck5zYAfw28NyLagf8MvDhvpTczs1kV06JfCRyKiMMRMQEMAavz8qwGvphsPwC8RZKAm4B9EfE9gIg4HhGT81N0MzMrRjGBPgMczdkfS9IK5knWmH0OWAxcA4SkhyQ9JukP5l5kMzM7H6W+GdsA/DLwm8m/vybpLfmZJN0haY+kPceOHStxkczSbfv27bS1tdHa2srg4GChLK9IGl6nJK3JPSDpVkkHk59by1NiK7ViAv040JKz35ykFcyT9MtfChwn2/r/VkQ8HREnyC4w/vr8N4iIjRHREREdTU1N5/8p7II4IKTP6clJ+vr62LZtGyMjI2zevJmRkZH8bBPAbcCm3ERJPw98DLiBbJftxyQtKkOx69Z9O56Y9lMqxQyY2g1cLWkZ2YDeC7wnL88wcCvwHWAN8HBEhKSHgD+Q9HKyX643kb1ZaxU2mQSEHTt20NzcTGdnJz09PaxYMe0++1RA+EBuYk5A6AACeFTScEQ8W46ye0rpsztyYB+tra0sX74cgN7eXrZs2TKjXiNin6TTead3ATsi4hkASTuAVcDmMhTdSmjWFn3S574OeAh4HPhKROyXNCCpJ8n2BWCxpEPA+4G7knOfBT5F9o/FXuCxiHhw3j+Fnbddu3adCQiNjY1nAkKeiYjYB5w1ICR1PBUQrMKee/opWlpeugBvbm5mfDz/AvysirkfB7i7tdYUNQVCRGwl2+2Sm9afs30SeOdZzv1rso9YWhUZHx+fERB27txZ7OnnFRCAOwCuvPLKCyqrVZ+I2AhsBOjo6IgKF8dm4ZGxVlK+/1Jely65nKNHX/obPDY2RiZT8G9wIcXcj7Ma5EBfpzKZjANCCrW0XcfBgwcZHR1lYmKCoaEhenp6Zj8x6yHgJkmLkpuwNyVpVuM8e2Wd6uzsPBMQMpkMQ0NDbNq0afYTsx4C/jjniYybgA+VpKBzlH/jNu2zjS5Y0MD69evp6upicnKStWvX0t7eTn9/Px0dHVNB/+WSxoBFwDsk/WFEtEfEM5I+QfaeGsDA1I1Zq20O9HWqocEBIa26u7vp7u6eljYwMJC7eyIi8qcxASAi7gfuL13prBIc6OuYA4JZfXAfvZlZyjnQm5mlnLtuzKzm1NtN9rlyoDezmuCpLy6cu27MzFLOLXozq3m5rX1348zkQG9WA9xtYXPhQG9mVcl/3OaP++jNzFLOgd7MLOUc6M3MUq6oQC9plaQDkg5JuqvA8YskfTk5vlPS0rzjV0p6XtIH8s81M7PSmjXQS1oAbADeBqwA3i0pf6Kr24FnI6KV7Jqw9+Qd/xSwbe7FNTOz81VMi34lcCgiDkfEBDAErM7Lsxr4YrL9APAWSQKQdDMwCuyflxKbmdl5KebxykLrg95wtjwRcUrSc2QXCz8JfBC4EThrt43XFTUz8COVpVLq5+g/DtwXEc8nDfyCvNCwlYtHUFo9KibQF7M+6FSeMUkNwKXAcbIt/zWS7gUuA05LOhkR6+dacDMzK04xgX43cLWkZWQDei/wnrw8w8CtwHeANcDDERHAr0xlkPRx4HkHeTOz8po10Cd97uvILgi9ALg/IvZLGgD2RMQw8AXgS5IOAc+Q/WNgZhXgudrLr9p/50X10UfEVmBrXlp/zvZJ4J2zvMbHL6B8ZmY2R57UzMxsnlXbTX9PgWBmlnIO9GZmKeeuG7M5qvYbcWZu0ZuZpZwDvVnKPL77W/zJ2i7uvu1GvjG0sVAWFZptVtJSST+TtDf5+V9lLbiVjAN9Hdu+fTttbW20trYyODhYKIsDQo05PTnJ364f4I67P88HP/cgj33z7xgZGcnPtoSzzzb7w4i4Pvl5b7nKbaXlQF+nJicn6evrY9u2bYyMjLB582YHhBQ4cmAfS159FYuvaKFhYSOve9Pb2bJlS362yzjLbLOWTjV5M7YeZrgr9WfctWsXra2tLF++HIDe3l62bNnCihXTlhq4jOkBYb0DQnV77umnuKzpF8/sX9Z0OePjR/KzNVJgttnk2DJJ3wV+Cnw0Iv5v6UttpVaTgd7mbnx8nJaWl+aqa25uZufOnfnZ5hwQ6n0K6hp7IuffgCsj4rikNwBfl9QeET/Nz1jN9Vptv/NqKI+7buxCTAWE1wHvBzZJelWhjBGxMSI6IqKjqamprIWsR5cuuZyfHPt/Z/Z/cuwpMplMfrYJkhlpc2ebjYgXIuI4QEQ8CvwQKBiVXK+1xS36OpXJZDh69KX1ZMbGxs4VEMbyAkIAL0A2IEiaCgh7ylH2alfJrsWWtus4Nv4kx//tKJcuuZzv/p8Huff3v5qf7ScUmG1WUhPwTERMSloOXA0cLmf5rTQc6OtUZ2cnBw8eZHR0lEwmw9DQEJs2bcrP9hMcEGrKggUN/Pq6fjZ++Hc4fXqSlV2/QXt7O/39/XR0dNDT0wPwNNkV4PJnm30jMCDpReA08N6IeKYiH6QG1NK9Qgf6OtXQ0MD69evp6upicnKStWvXOiCkxIqVb2LFyjdNSxsYGMjdjYiYMdtsRHwVmNH8t9rnQD9H83WjpRytgxll7e6mu7t7Wlq1BoRaaj2ZVRsHerMi+A+N1bKiAr2kVcCfk11h6vMRMZh3/CLgr4A3kF0r9l0R8aSkG4FBso/pTQD/IyIensfym12wanjszawcZg30khYAG4AbgTFgt6ThiMgdRnk7yQhKSb1kR1C+i2wf7zsi4l8l/QeyyxHOeLTDzOqTr5SKN5eGSTEt+pXAoYg4DCBpCFgN5Ab61cDHk+0zIygj4rs5efYDL5N0UUS8UHQJrS45AJjNn2ICfYZkdGRiDLjhbHnyRlA+nZPnN4DHCgX5ah5lZ/XJf2gsTcoyMlZSO9nunN8tdNyj7MzMSqeYFv04yXDpRHOSVijPtBGUAJKaga8Bvx0RP5xzic3MalglrhaLadHvBq6WtExSI9lBM8N5eYbJjqCE6SMoLwMeBO6KiH+apzKbmdl5mLVFn/S5ryP7xMwC4P6I2C9pANgTEcPAF4AvFRhBuQ5oBfol9SdpN0XEj+f7g5iZFeLHaIt8jj4itgJb89L6c7ZPAoVGUP4R8EdzLKOZ2bzJDfz1EvQ9TbGZWcp5CgQzKxs/tloZDvRmVrfqpf/eXTdmZinnFr2ZlZS7ayqvJgK9vyilUY9PH5jVo5oI9GZmlVbLDU4HerNERVb58pWUlYEDvVmVqtUWZK2WO8381I2ZWco50JuZpZy7bszMCkhTF5QDvVWNNP3HMqsmDvQV5MBmZuXgQG8V4z900/n3YaXiQD/P/J/Vzoe/L9UlrfVR1FM3klZJOiDpkKS7Chy/SNKXk+M7JS3NOfahJP2ApK55LLvN0eO7v8WfrO3i7ttuZHBwsFAWuV5rT269fmNoY6Esrtc6M2ugl7QA2AC8DVgBvFvSirxstwPPRkQrcB9wT3LuCrLLCrYDq4C/SF7PKuz05CR/u36AO+7+PB/83INs3ryZkZGR/GxLcL3WlPx6feybf+d6taJa9CuBQxFxOCImgCFgdV6e1cAXk+0HgLdIUpI+FBEvRMQocCh5PauwIwf2seTVV7H4ihYaFjbS29vLli1b8rNdhuu1puTX6+ve9HbXqxXVR58BjubsjwE3nC1Pspj4c8DiJP2RvHMz+W8g6Q7gjmT3eUkHiip9cZYAT8/j66XlPRcBr3r/TW0/SvZ/HnjFhz/84SM5ea5nDvUKJa/bs6nE779a3ndGvW4tT70epzKfvZwqVb8FvX9m0lVny1sVN2MjYiNQsDNxriTtiYiOUrx2Lb+npDXAqoj4nWT/vwI3RMS6nDw/mGu5Slm3Z1OJ33+1vG+l6rVSn72cavkzFtN1Mw605Ow3J2kF80hqAC4Fjhd5rlWG6zWdXK82QzGBfjdwtaRlkhrJ3qwZzsszDNyabK8BHo6ISNJ7k6dylgFXA7vmp+g2R67XdHK92gyzdt0kfXjrgIeABcD9EbFf0gCwJyKGgS8AX5J0CHiG7JeLJN9XgBHgFNAXEZMl+ixnU9Zug1p5zxTU67lU4vdfFe9bwXqt1Gcvp5r9jMr+ITczs7TyNMVmZinnQG9mlnJ1EeglfVzSuKS9yU93id7nnFNFlOg9n5T0/eRz7SnHe9aCctV58l5lr/ec965o/Ut6p6T9kk5L6sg7lorpFCpZv/OlKp6jL5P7IuJPS/XiOVNF3Eh2oMluScMRMWP8eQn8l4iomoEcVaSkdQ4Vr/cplaz/HwC/Dnw2NzFvOoVXA/8g6Zoqu2k/qyqp3zmrixZ9mRQzVYSlT13Xe0Q8HhGFRjunZTqFVNRvPQX6dZL2Sbpf0qISvH6hqSIKDh+fZwH8vaRHk2Hp9pJS1zlUrt6nVGv9V/r3Ml9S8TlS03Uj6R+AXyxw6CPAZ4BPkP1P8Qngz4C15StdSf1yRIxL+gVgh6R/iYhvVbpQ5VDHdZ6r5PV/rt9zRMyYMc2qT2oCfUS8tZh8kj4H/F0JilCR4eMRMZ78+2NJXyN7qVkXgb4K6hwqPG1AOeq/2N9znrRMp5CKz1EXXTeSrsjZ/TWyN5DmWzFDz+eVpEskvXJqG7iJ0ny2mlOmOocK1PuUKq//tEynULH6nU+padHP4l5J15O9jH8S+N35foOzDT2f7/fJcznwNUmQrctNEbG9xO9ZK0pe51Cxep9S8fqX9GvA/wSagAcl7Y2IrhqYJqMoFa7feeMpEMzMUq4uum7MzOqZA72ZWco50JuZpZwDvZlZyjnQm5mlnAO9mVnKOdCbmaXc/wdW26UaWnVeUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.random.manual_seed(43)\n",
    "N_fit_samples = 100\n",
    "\n",
    "# Draw an actual fitting dataset.\n",
    "samples = get_draws_from_grammar(gt_grammar, N_fit_samples)\n",
    "\n",
    "l_gt = get_all_node_xyzs([sample[0] for sample in gt_samples], Point)\n",
    "l_train = get_all_node_xyzs([sample[0] for sample in samples], Point)\n",
    "plt.figure()\n",
    "for k, label in enumerate(\"xyz\"):\n",
    "    plt.subplot(1, 3, k+1)\n",
    "    #plt.hist(l_train[:, k], label=\"Train\", alpha=0.5, bins=25, density=True)\n",
    "    plt.hist(l_gt[:, k], label=\"GT\", alpha=0.5, bins=25, density=True)\n",
    "    if k == 2:\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2995, 0.1439, 0.5566]) [[-0.63322774 -0.16328669  1.52765023]\n",
      " [-1.32648068 -1.24129718 -0.10280493]\n",
      " [-0.94976312  1.24561478  1.08329222]] [[4.62262509 0.8209086  6.83001399]\n",
      " [9.41396026 1.97049415 7.57934202]\n",
      " [7.06759619 7.94534282 6.95327399]]\n",
      "EM fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "EM-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2439, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1622], grad_fn=<AddBackward0>)\n",
      "EM-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7043], requires_grad=True) +/- tensor([0.7268, 1.8225, 4.4287], grad_fn=<AddBackward0>)\n",
      "EM-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038fbd37e3b54deebeee8b5ebd937406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-1.6634, -1.7398,  0.9489])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.1602, 4.1165, 5.3458])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.9295, -3.1208, -3.8979])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.5629, 5.9340, 4.0820])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.8076, -1.0300,  1.6564])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.2979, -6.3699, -8.4596])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.1594, 5.2255, 4.9571])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.1608, -1.5740,  1.2358])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-0.6982, -0.8352,  3.2574])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.5964, -6.3111, -6.8337])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.3219, 5.3567, 4.6818])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.3610, -4.9966, -8.3045])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.9363, 4.9124, 5.1238])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.2246, 5.0427, 4.4356])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1703, -5.6767, -6.0615])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.9305, -0.8665,  3.4460])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.8134, -0.8405,  0.8711])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.4592, 5.2905, 5.2015])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.5048,  1.6353,  2.6859])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.6588,  1.5690,  3.7217])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.6513, -6.5950, -8.1798])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.6164, -0.1910,  1.3849])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([7.0999, 5.2287, 4.1215])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.0513, -6.0348, -3.9330])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.5607, 4.6584, 5.2374])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([7.0051, 4.4912, 4.3205])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([2.0964, 5.5718, 4.6529])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.4534, -5.5747, -5.1460])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.9168, -5.5672, -8.0182])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.9909, -3.3763, -3.8529])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.5615,  1.9412,  3.3433])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.2636, 6.0678, 4.4395])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.7239,  0.3277,  3.6711])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.7020, -5.4570, -2.3317])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4282, 5.2686, 5.4446])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.1515, 4.8272, 4.9420])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.2316, -5.1819, -6.3545])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.4948, -5.5766, -7.0076])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.2982, 4.9258, 4.2889])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.3298, 3.6293, 5.8178])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.9311, 5.6446, 5.7154])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.7917, 5.1223, 5.4254])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.2200,  0.3179,  0.2825])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.7376, -0.1834,  1.2006])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.8893, -4.8552, -7.0728])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.2626, 5.4242, 4.9445])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.3082, 5.2240, 5.2859])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.7369, -6.7512, -5.6183])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0174, -5.5819, -5.0566])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.1086, 4.5577, 4.6929])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.2600, -1.0295,  2.5237])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.2691, 5.0153, 4.3122])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([7.4048, 6.3453, 4.6420])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.8101, 4.8670, 4.9517])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.6419, -3.0171, -6.1490])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.4775, 5.0840, 4.7854])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.7145, 5.1868, 4.7359])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.8637, 4.8323, 4.4552])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.9006, 5.0366, 5.2601])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.0243,  3.2127,  2.5644])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.0576, -8.6645, -6.3241])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.5864, -3.5697, -6.2195])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.5333, 6.0476, 5.7607])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.9262, -3.2239, -3.6432])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.5239,  1.5690,  2.5195])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.3781, -5.3924, -4.9829])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.2432, -4.7619, -6.8975])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-6.1509, -3.8824, -7.2572])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.4156, -2.1946,  2.4959])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.5877, -6.2543, -4.0974])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.4975, -4.6229, -3.1202])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.1365, -2.1672,  4.3314])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.4441, -3.7478, -3.9973])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.3483, 5.0035, 4.8039])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.7580, 4.2892, 4.9975])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.4929,  0.9072,  0.7078])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.9677, -3.6867, -6.3725])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.4870, -1.1813,  1.3234])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([7.1544, 5.0888, 4.7443])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.2697, -7.3891, -6.0402])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.3933,  0.0403,  1.7878])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.2492, 4.3297, 5.2302])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.0007, -8.2390, -2.5394])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7162, -3.7457, -6.4792])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8348, 4.9500, 4.2849])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.9053, 5.4487, 4.8765])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.8370, -3.5196, -0.3758])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.8476, -5.8212, -3.5068])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.1796, -6.3415, -4.4854])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.6811,  1.0331,  2.0664])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.3021, 5.5195, 5.8704])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.7066, -3.3929, -0.0537])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([6.9166, 5.6106, 4.9011])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.2869, 5.2810, 4.5605])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.2828, 4.5753, 5.0271])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1505, -3.6104, -5.3963])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6471, -8.2364, -2.8935])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.8080, -0.6000,  1.1457])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.9052, 5.1962, 5.2084])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.5259,  1.1178,  0.7515])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.5594, -1.2737,  3.9716])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.1411, -4.2824, -3.0675])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.6750, 4.5691, 5.3776])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.5750, -3.8923, -4.0319])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.5025, 5.2177, 5.1928])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.0925, 6.3264, 4.9098])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.9319, -0.3804, -3.3089])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.6796, 4.7394, 4.2796])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.4963, 5.4631, 4.8720])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.6371, -1.6847,  2.5594])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.8448, 4.8241, 4.8918])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.9070, 5.6217, 5.3097])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.7031, 5.3408, 5.4060])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.4621, -5.2609, -2.6504])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.4626, 5.5647, 3.6309])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.0948, -3.6356, -7.7486])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.9803, 5.4528, 4.8233])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.3475, 5.1840, 4.8257])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.5228, 4.0263, 5.1611])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.8625, -4.4112, -4.6113])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.4706, -5.3153, -3.2501])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.6671, -1.9713, -6.3599])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.4604, -5.9492, -7.4546])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.6785,  0.2134,  2.5465])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([7.4042, 4.6805, 4.7997])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-1.0796,  0.7588,  1.2712])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.2765, 5.3178, 5.8945])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.4957, -6.5241, -5.6919])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0594, -5.2847, -8.6005])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8488, 4.6134, 5.0784])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.9154, 4.4975, 4.5775])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.1202, -5.3311, -5.4278])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.4703, -4.5105, -2.5539])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.6728, 5.2208, 4.5904])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.3906, 5.1100, 4.3173])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.1480,  3.0457,  3.7043])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.6286,  0.4113,  3.5313])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.0841, -2.7313,  2.2835])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.5106, -0.8874,  2.1908])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.4088, 4.4582, 4.6166])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8765, -4.7951, -6.8341])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.6244, -5.7753, -5.3380])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.7765, 4.6362, 4.3456])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.3272, -6.0018, -5.0395])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-7.2423, -6.9037, -6.8387])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.7865, -6.2925, -5.2327])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7594, -4.8044, -2.5766])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.2608, -3.0273,  0.3259])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.5117, -5.7072, -2.8561])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.2332,  1.0116,  0.3440])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.6808, -1.4834,  2.9978])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.2427, -4.8994, -4.9404])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.4873, -5.3994, -7.0905])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.6138, 5.4830, 4.7946])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.2600, 5.9392, 5.1262])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.3741, -0.3286,  2.4777])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.1685, -4.6765, -4.4279])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.6691,  0.3606, -0.1384])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.8469, -4.2194, -4.2342])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.6145, -4.9022, -3.5977])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5846, -4.2312, -4.8374])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.7602, -0.0927,  0.2693])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.5716, -4.9426, -1.4707])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.9314, -4.7290, -1.7252])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7092, -5.3951, -7.3860])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.4652, 4.3094, 5.2907])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8415, -5.7354, -3.6027])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8890, 4.6553, 5.6487])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8274, -5.6509, -1.0545])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5116, 5.3317, 4.5712])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.1254, 4.6312, 5.2802])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.9396, 5.3434, 6.3116])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.0608, -0.3054,  1.6798])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.7297, 5.0734, 4.8732])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.6612,  0.4114,  2.6404])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.5208, 4.4949, 4.8844])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.9176, -3.3447, -3.5266])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.5997, 5.2214, 4.5924])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.1289, -8.2614, -2.5058])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8914, 5.0233, 3.8200])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.4630, -5.1804, -3.0211])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.8664, -3.6175, -4.5537])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5792, 4.9282, 4.4529])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.4612, -4.9365, -3.8043])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.1882, 5.3890, 4.9801])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.6365, -4.4889, -1.5230])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.2447, 4.5857, 5.0327])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.5300,  0.3205,  3.0980])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.5981, 5.2403, 5.1800])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.3606, 5.5929, 5.2951])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.8736, 5.0557, 4.4580])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.7764, -2.5826, -9.5793])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.2760, 4.8556, 4.5678])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.7913, -4.0263, -5.5692])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-4.7542, -5.3467, -5.3794])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.9896,  1.3987,  0.0293])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([6.0967, 6.0102, 5.0566])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.9784, 5.5859, 4.9413])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.2710, -1.0040,  3.5027])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.6114, 4.6010, 5.3197])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.8096, 4.4463, 5.0182])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.6374, 5.1582, 4.6607])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.9212, -1.2741, -0.2748])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.8671, 4.2025, 5.0871])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.0068, -6.1175, -4.5960])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([7.2464, 4.9594, 5.4885])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.4306, -5.2702, -5.7254])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.5941, -6.2628, -8.0443])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.0677, -0.9019,  0.3326])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.1540, 5.2050, 4.6518])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([2.2767, 3.7659, 5.5523])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.8124, 4.9544, 4.7361])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.7263, -4.9573, -8.3172])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9614, -4.0283, -1.4945])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.4460, -5.1782, -3.5179])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7962, -5.2333, -5.7642])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8614, -5.0465, -5.8307])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.6846, -4.8189, -6.8284])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7932, -3.7677, -6.0080])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.1198, -0.1970, -0.1201])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([2.5613, 5.6016, 6.1634])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.8488, 5.1682, 5.7479])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.7406, -1.9632,  3.0835])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.2262, -5.6129, -4.8644])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8935, 5.5786, 5.3765])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.6581, 5.1674, 4.6775])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.1330, 5.2824, 4.2769])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.1682, -5.4610, -1.8271])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5633, -5.2298, -6.6302])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5972, -5.7995, -3.2177])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.7845, 5.0888, 5.7027])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.1162, 5.7990, 4.8199])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.6544, -6.7524, -2.4006])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.3668, -4.6364, -5.4569])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.0025, 4.8954, 4.4866])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.8689, 5.0021, 4.8381])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.8572, -0.7334,  0.8516])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.8242, -6.6125, -7.6949])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.7081, -6.1128, -5.4581])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.4849, -5.7796, -6.3778])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7206, -3.6611, -6.3799])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5598, 4.8619, 5.6556])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.9856, -5.3047, -7.4008])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.1349,  0.4709,  2.4928])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.5534, -3.3499, -5.5414])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-7.0177, -5.5285, -5.3489])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.4303, -0.3326,  0.6211])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.7526, -4.7640, -3.1811])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5620, -3.4894, -5.5753])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.3101, -3.9837, -5.0277])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9394, -7.2459, -5.0004])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.9081, 5.1268, 4.4241])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.7477, -5.8469, -6.6798])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.0322, 5.2903, 4.8499])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.3300, 4.9043, 5.2686])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5508, 5.5027, 4.6663])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.6946, 4.5530, 5.6300])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.5677, -3.0846, -6.2539])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([7.2930, 5.9363, 4.6263])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.3040, -3.7056, -7.8049])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.3685, -4.0085, -7.5952])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.1100, -6.1565, -2.4480])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([3.8713, 5.6940, 5.9095])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5565, 5.3953, 4.9074])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.3743, 4.7318, 4.6425])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([7.0363, 5.1539, 4.4684])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.9637, 4.2722, 4.1738])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.4461, 4.8079, 4.5246])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.6638, -6.4586, -4.9664])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8943, -7.0954, -4.8176])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.0527, -4.2479, -1.8924])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.0035,  2.7347,  1.7940])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.6595, 4.7447, 4.5269])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5321, 4.5849, 4.9048])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.5218, -6.6288, -8.9164])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.6607, -5.8386, -6.2088])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.2009, -4.7765, -5.5607])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7119, -5.2414, -4.0935])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4573, 4.3971, 4.6533])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.8165, -4.5589, -8.4165])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.9310, 4.4712, 4.3692])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.7012, -5.3825, -6.8747])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-7.2244, -5.0095, -5.8964])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.4824, 5.2758, 4.4531])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.1736, -3.3452, -6.7268])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.9720, 5.1509, 5.3714])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1887, -3.1691, -6.1204])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.2011, -3.7414, -2.9175])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5391, -5.8840, -3.9776])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.2497,  1.2567,  0.6085])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.5976, -4.0158, -5.3574])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.4517, -5.0022, -5.2806])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.5560, -4.0982, -5.1240])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.5957, -7.3976, -5.1395])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-7.2626, -4.8710, -2.9066])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4395, 4.5985, 5.4632])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.4025, 4.8178, 3.7332])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.4483, 4.7108, 5.0812])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.7994, -5.9759, -3.1073])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.9653, 5.3697, 4.6922])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.1698,  0.6400,  4.4414])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.4851, 5.8334, 6.2157])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.1146,  0.0862,  1.3182])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.2845, 4.5314, 5.3782])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.5293, -5.2168, -6.5783])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8382, 4.5885, 5.9896])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.0507, -4.6414, -5.1424])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.8539, 4.8328, 5.0854])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([2.3489, 6.0357, 4.6828])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.0333, -6.2082, -2.1044])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4927, 4.1804, 5.0042])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.7280, -4.2145, -2.0644])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.2793, -0.5017, -0.7999])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.3977, -1.1102,  2.1215])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-0.9756,  0.4913,  2.3792])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.5714, -2.8999, -4.5292])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.1020, 4.1930, 4.6270])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.0040,  0.8410, -0.1513])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.1015,  1.4911,  2.8281])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.2039,  2.0087, -0.5375])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.1587, -1.1243,  1.1556])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.4426, 4.7843, 5.5946])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.7271, 4.7807, 4.6513])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.4779, -5.8055, -5.4656])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([7.4839, 5.1452, 5.4334])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.9780, -4.8307, -8.9371])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.8177, -4.7970, -5.6004])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.4323, -3.1195, -8.6230])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3591, 5.0500, 4.9459])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-4.6293, -4.6884, -1.7065])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.4349, 5.3465, 5.1200])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.2066, -1.6300,  1.4685])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.4240, -2.7452, -4.9932])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.4413, -1.8572, -4.6965])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.6862, -0.9143,  0.9184])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.6932, -5.5046, -2.3831])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.4575, 4.7600, 5.0383])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8991, -5.3246, -6.6374])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.8553,  0.8203,  2.5695])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.8352,  1.5173,  0.5934])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.1166, -4.5511, -9.8681])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.2252, -4.2307, -4.6741])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.4435, -4.3446, -5.5534])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-8.1447, -4.7489, -5.0208])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.6114, -4.5869, -5.2154])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3954, -5.2065, -6.7311])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4660, 4.1720, 4.8811])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.9970, -4.7634, -7.2470])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.8678, -5.2480, -2.9865])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6930, -6.5166,  0.8577])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.5474, 4.3621, 4.7840])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8661, -2.9652, -6.4397])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5860, -3.1871, -4.7157])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.0796, 5.6244, 5.1492])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.4825, 5.5218, 4.1670])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.5323, 5.4376, 3.6353])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.4924, 4.7482, 5.3109])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.0368, -5.5973, -7.1807])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.1770, -5.1509, -5.3295])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.9809, -4.5111, -5.9869])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6792, -5.0281, -6.9140])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.6617, 4.6165, 4.7347])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5746, 4.5434, 5.1309])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.9825, -6.7573, -4.6255])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.1690, -1.5725, -9.3419])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.0465,  0.0742,  2.3752])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.3284, -2.3069, -7.0952])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.5324, -4.7229, -4.5653])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.3771, -3.3159, -5.6212])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-7.4576, -4.0028, -7.2700])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.2750, -4.7532, -4.3548])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8877, 5.4705, 4.5763])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.6970, -1.0041,  2.2472])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.1883, 5.1412, 5.6559])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.0933, 4.5886, 5.2537])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.6127, 4.7811, 5.2946])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.9367, 4.2879, 5.0089])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.3543, -1.6012,  0.7723])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.3797, 5.3388, 4.4767])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.4408, -4.8325, -5.0749])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4734, 5.3263, 4.9211])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.9471, -4.3850, -8.3268])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.1708, -0.0532,  2.6417])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([2.3296, 5.3656, 4.5303])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.9529, -0.1807,  2.6325])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.0883, -4.5119, -9.0702])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8879, 5.2611, 4.5764])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.8569, -4.2923, -4.2353])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.9547, 4.8336, 5.4107])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.5278, -4.8287, -3.2271])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.4764, 4.3816, 4.5231])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.0266,  1.0126,  2.2526])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.1740, 5.1839, 4.6457])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.6560, -0.5176,  2.5949])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.7303, -6.7161, -6.2469])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.0786, -1.6733, -6.8198])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8384, 5.4485, 5.6110])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-7.0116, -5.1249, -2.5071])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.6593,  3.1403,  1.2760])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.6819,  0.9002,  2.0827])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.5007,  0.7079,  3.2354])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.2507, -5.0492, -4.4231])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.2401, 5.1239, 5.0350])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.5310, -4.3337, -2.5894])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.4416, 4.7483, 5.0200])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.8609, 5.1070, 3.8342])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.2072, -1.4195,  2.4879])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.5267, -0.5513,  2.6021])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.9327, -0.5635,  0.3747])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.6164, 5.9828, 4.6930])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.3638,  0.0202,  3.2334])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.9602, -5.1419, -2.9309])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.6503, -3.8566, -5.7284])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.8023, -3.3715,  2.0829])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.6346, -3.7157, -2.8484])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([7.3184, 5.6161, 4.9240])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5384, 4.7559, 3.9483])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.7337, -5.4570, -2.1211])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.1615,  0.2767,  3.8435])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.5479, 5.1012, 5.4202])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.0091, -3.0032, -7.0381])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.6776,  0.4468,  3.7125])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.9054, 5.2991, 4.7541])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.4467, 4.3099, 4.3618])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.0304, -5.0325, -6.0085])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([2.1173, 4.5504, 4.9279])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.0437,  0.1062,  1.4344])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.3818, -5.9812, -5.4042])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([ 0.5393, -1.2295,  2.4363])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.1126, -4.2421, -6.3538])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.5581,  1.3143,  2.4712])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.4824, 5.4053, 4.6146])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1758, -4.4297, -6.3195])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.0541, 5.0036, 4.2936])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.2498, 4.3680, 4.3941])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([7.4816, 4.8462, 5.2318])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.9021, 5.3412, 4.8526])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.4957, -5.4998, -4.9930])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.2989, -6.2994, -1.5995])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.4048, -0.6597,  3.0566])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.1716, -4.3142, -5.0545])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.4640, 4.3940, 4.3323])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.8072, -1.4167,  2.0271])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.2637, -4.0426, -6.7586])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.3434, -0.4970,  0.8976])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.8878, -6.5109, -4.4895])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3568, -2.8941, -6.1091])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6263, -6.3752, -4.4101])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8686, 4.4726, 4.1697])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.6732, -6.6503, -4.8623])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.5092, 4.4675, 4.4924])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.9090, -1.4476,  2.1726])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.1752,  0.1941,  1.0761])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.6595, -3.4635, -7.0267])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.3802, 4.8945, 5.6035])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.7978, 5.3754, 5.2946])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8805, -5.9046, -4.0800])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.3145, 5.5563, 5.8329])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.4170,  0.0991, -0.2320])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.9289, 4.9308, 5.4759])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-7.5019, -5.3836, -4.3165])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3439, 4.4149, 4.5885])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.1036, 5.2329, 5.3742])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.1846, -2.9624,  0.8734])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.1433, -0.0110,  3.5151])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-3.7701, -6.0055, -5.4363])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.1703, -5.5496, -3.6076])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.7646, 3.9210, 5.5753])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.8700, -5.2351, -9.8148])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.1013, 4.9035, 4.2833])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8724, -5.8490, -5.4811])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8533, 5.1915, 5.1894])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.0031, -4.2367, -3.9234])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3313, 4.8030, 5.2594])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.2695,  1.2269,  3.1096])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.3996, -3.3611, -3.8454])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.1651, -7.2926, -6.6511])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.9624, 4.2573, 4.7289])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.2067, -1.0054,  2.6909])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.1596, 4.8863, 4.5587])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.3203, -4.4072, -4.3837])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.7613, 4.1068, 5.7140])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.0011, -4.4313, -2.8976])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.6158, -0.6921,  3.4336])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([6.0011, 5.0812, 4.8818])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.8124, 3.8313, 4.4389])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.2559, -0.3461,  4.7148])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.1404, -0.1125,  2.4185])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.7467, -1.3123,  2.6919])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-0.9290,  2.1938,  0.4897])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([7.1037, 3.7187, 4.6296])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8939, -7.6939, -4.9574])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-7.2683, -2.4117, -1.9342])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.5783, 5.2466, 5.0922])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5389, 4.4556, 4.4913])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.0737, -4.6526, -0.8525])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.2324, 5.7076, 5.0672])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.8807, 4.5980, 5.3398])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.8209, -5.0585, -4.0059])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5293, -5.3096, -5.0909])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.7259, -2.1442, -5.9562])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3816, -5.7811, -6.9598])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.6713, -7.1881, -1.4076])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.7121, 4.7961, 5.6689])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.7161, -3.1262, -2.2107])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.1836, -2.8974, -6.2926])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3326, 5.3929, 5.0016])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.4427, 5.1740, 5.5718])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.8632, -1.6629,  1.6975])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.7384, 4.7044, 4.9903])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1517, -4.9970, -7.7257])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.2038, 5.0188, 4.7769])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-7.0541, -4.9467, -3.6552])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.0576,  0.8426,  1.8332])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.9715, -2.3641, -3.8799])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.1721, -0.6141,  3.5854])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.5163, 4.8551, 6.2847])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.1848,  1.1908,  1.8245])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.6938, -5.8098, -3.9962])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.5094, -5.3135, -8.0902])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.2030, 4.8602, 4.2550])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.8837, -5.5753, -3.8115])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.1492, -4.8108, -7.2582])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.6390, -4.8001, -6.8619])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.7221, -0.7168,  1.0090])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.7878, 5.9237, 6.4033])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.9275, -7.3622, -5.9003])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.2605, 4.4140, 5.7916])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.1232, -2.6140, -4.7194])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.9061, -0.1848,  0.9798])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.6514, 5.5658, 4.8855])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.2222, 6.3834, 5.9840])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([2.9514, 5.7007, 5.0831])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.1409, 4.8432, 5.1607])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([3.2003, 5.0217, 4.7294])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.5656,  0.7634,  3.5030])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.5362,  2.1182,  3.0071])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.9705,  1.0097,  1.9191])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.9806, 5.6030, 4.9999])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.6364, 4.2846, 4.2310])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.4394, 5.0291, 4.6265])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.2265, 5.3916, 4.4930])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.5445, 4.7982, 5.9080])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.9575, -5.3905, -7.7810])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8530, 5.6666, 5.2743])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.2151, 4.9958, 5.0063])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.0600, 4.9697, 4.6045])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.4535, -3.9510, -5.9455])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5939, -5.7660, -6.0307])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.0805, 5.3302, 5.3760])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.0068, -4.8930, -4.1840])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.2124, -1.0924,  2.6842])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.0733, 5.5839, 4.8917])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.0326,  1.1884,  2.8135])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.8970,  1.1874,  2.6437])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.8190, 5.0025, 4.7927])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.8843, -4.9374, -2.9232])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.6871, -1.5527,  1.6539])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.9348, -5.0509, -5.3267])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.7841,  2.0886,  1.8410])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.8349, -3.6165, -3.5314])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.1989, 4.8272, 6.2164])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.2604, 5.5360, 5.3180])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.5857, -5.1060, -2.9742])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.8524, 4.9140, 5.5906])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.9986, -6.1543, -4.7131])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.2768, -4.0467, -4.3745])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7356, -3.8504, -4.6704])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.2543, 4.9931, 5.2273])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.6610, -0.3848,  3.5090])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.3235, -3.3184, -6.2646])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4004, 4.4388, 4.0819])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.7663, -3.9794, -4.6961])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.8118, 4.7639, 5.0678])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.3088, -5.9682, -4.3274])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.0326, -5.5209, -6.0633])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.6463, 5.1366, 4.0397])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.7278, -3.2267,  1.6039])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.9380,  0.6311,  3.9958])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.0120, -5.4720, -6.4929])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.0549, -3.6784, -5.5742])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.6424, 5.5981, 5.4480])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.5804, 5.1417, 5.7619])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.2148,  2.5948,  1.2178])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.8620, 5.9048, 4.9617])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.2245, -4.2585, -7.0469])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.6160, 5.2223, 4.7601])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.1737, -4.7072, -1.3361])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3313, 4.8786, 5.2230])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.3027, -4.1156, -2.9137])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.9421, 5.0685, 4.8695])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.2094, -5.8367, -5.6756])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.5084,  2.5489,  1.3439])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([7.5705, 5.8427, 4.9856])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.3858, 4.0206, 5.2604])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.4064, 5.9330, 5.6282])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.4172, -5.2812, -4.2578])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([ -5.0932,  -4.6085, -10.5585])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.3567,  0.2245,  0.4279])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.2218,  1.7752, -0.3432])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.0770, -4.0321, -4.2032])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.7183, 5.3283, 5.6924])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.1872, -3.4630, -7.4990])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5479, 4.9457, 4.9456])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.4826, 5.0066, 4.4665])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.4324, -4.8435, -4.9859])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.0509, 4.9464, 5.3534])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.8434, 5.0410, 4.9217])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8657, -5.6065, -9.3668])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([2.4921, 5.6289, 4.2481])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.6973, -4.8815, -6.3248])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.9529, 4.5652, 4.0089])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.9112, -5.0654, -5.4996])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.2853, -8.1033, -5.2846])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.4374, -2.9146, -8.0377])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.2806, -2.5826, -7.4648])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0614, -4.2555, -2.8258])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.8558, -2.9860, -2.4872])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7958, -3.9552, -7.7612])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.0452,  0.5745,  0.7690])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([2.9292, 5.4389, 5.2696])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.2262, -5.8237, -6.2900])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3664, -3.3809, -6.2579])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.6236,  1.9550,  4.5113])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.2841, 4.1990, 4.5734])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8954, -6.3573, -5.6657])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4081, 5.1276, 5.4718])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.9182, 5.4725, 5.1384])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.6908, 4.5531, 4.4693])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.0165, 5.2148, 5.2767])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.9144, -5.9727, -4.8821])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.9208, 5.0461, 5.1481])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8772, -4.0465, -4.7604])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7826, -4.8366, -5.8480])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3121, 4.5883, 4.1202])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([2.3252, 4.3103, 5.2470])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.0251, -6.3652, -4.9036])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.6542, -0.3194,  2.8713])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.7481, -4.4460, -6.8978])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.2724, -4.5977, -4.6588])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.7677, 3.7817, 5.3949])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.3313, -3.7013, -6.2216])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.5878, -5.9299, -6.0226])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.1585, 5.0888, 4.8053])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.3770, -0.4212,  3.1038])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.7206, -1.4775,  0.0438])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.0767, -3.6660, -4.8177])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.9995, -6.2643, -5.5877])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.8676,  0.2845, -0.1451])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.5883, -3.1447, -5.4019])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.2636, 5.3871, 5.3298])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.0562, -4.3456, -3.5185])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.8033, -2.5693,  0.0289])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.7142, -5.2667, -4.3476])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5531, 5.5385, 4.8234])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.8522, -0.4502,  0.6884])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.9265, 5.3922, 5.8363])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.1962,  1.3618,  2.5553])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.1318, 5.9228, 6.8148])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.4014,  1.9143,  0.7783])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.7095, 4.9418, 6.0076])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8761, -4.9818, -5.9193])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5474, 5.0092, 5.3067])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.2801,  0.6988,  0.9045])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.6955, 4.2198, 4.0806])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([2.1355, 5.1674, 4.3196])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.2721, 5.1552, 4.7376])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.2214, -0.4516,  1.4401])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.8822, -4.7044, -2.4049])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.5464, 4.5676, 4.9219])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.8758,  2.5719,  2.0582])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.7392, 4.7560, 5.9897])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.3375, 5.4285, 5.6415])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1266, -3.8133, -2.9217])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.5686,  0.1405,  1.0514])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.9897, -5.1712, -5.8606])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3012, -6.8478, -4.4045])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.2450, 4.7831, 5.5383])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.6822, -7.1738, -4.6953])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.8943, 5.4704, 5.0597])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.0332, -3.3408, -6.8462])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.9209, 4.9513, 5.3253])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8333, -5.4944, -5.6652])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.5512, -1.5294,  1.8560])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.7224, 4.5859, 4.0107])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.5414, -4.2937, -3.3683])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9479, -4.3288, -6.3244])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.6673, -1.7697,  2.1999])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.7883, -1.0666,  0.8792])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-0.2460, -0.1357,  2.1956])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-0.0533, -2.1234,  1.5905])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.8599, -5.5752, -2.0276])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.2555, 4.9857, 5.0783])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.4398, 5.0642, 4.2380])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.9662, -5.5058, -4.0118])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.7852, 5.3009, 5.8679])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.3595,  0.1194,  2.7663])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.4091, -3.6427, -2.0891])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.0658, 5.2040, 4.6071])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.5656,  2.1682,  3.0708])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.0496, -4.0189, -7.9807])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5734, -4.3602, -5.6951])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.0038,  2.1354,  1.9176])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-7.2352, -4.2095, -3.5167])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([0.4020, 0.9526, 3.0710])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.6947, 4.5855, 4.7638])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.9987, 5.1551, 4.9114])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.7750, -3.4637, -6.3892])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-4.1360, -6.8128, -7.9044])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.5798, -3.6714, -4.3877])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3608, -4.1168, -3.0839])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.0479, 5.4260, 5.1849])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.5654, -4.1776, -3.7651])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9375, -4.5328, -2.7552])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.0001, 4.6986, 5.1121])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.7255, -0.6878,  2.8187])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.9755, -0.3462,  3.3728])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.8180, -4.8815, -7.1745])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8521, -6.0099, -5.7107])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.1970, -3.1132, -3.2623])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.4619, -4.7063, -3.9355])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.9188, -4.7182, -1.5406])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([2.8242, 4.8561, 5.6602])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.3452, -6.3732, -3.6315])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.7068, -0.0834,  0.8835])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.9292, -7.5269, -4.8452])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0907, -1.6899,  2.0003])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.8155, -1.7953,  3.1378])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.6572, -0.8460,  1.9189])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.1765,  0.3121,  2.1997])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-0.6291, -0.4633,  1.0747])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.9125, -4.2229, -2.1911])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.0764, -3.3283, -3.1066])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.2613,  1.9222,  4.0010])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([2.4487, 5.3947, 5.2209])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.1190,  1.9365,  1.7755])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.7548, -3.5864, -3.4800])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([1.9047, 4.7127, 4.9332])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.7469, -5.1523, -7.0533])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.1268, -5.0592, -5.4290])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8818, -6.4572, -3.6498])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.9122, 4.0719, 5.1968])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.6187, -5.0190, -4.5902])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0329, -6.9527, -7.4777])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3734, -6.1426, -5.5249])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.0769,  1.5547,  1.9429])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.9818, -5.1667, -3.9012])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.2257, -3.9956, -7.9118])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3969, -5.4841, -1.7692])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.8953, 5.1007, 4.5453])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.2327, 5.0705, 4.9957])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.5871, -1.1093,  2.2911])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.0372, -6.7930, -4.1857])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.8447, -2.1160,  0.9965])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.2094,  0.4030,  0.4995])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.0653, 4.5469, 5.6584])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1741, -4.6674, -4.7423])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.0766, -3.6104,  1.5295])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.0019, -5.0709, -1.6963])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.1363, 4.5167, 4.8109])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.5449, 5.2264, 4.5587])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.2759, -4.0215, -3.9388])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5678, 4.9067, 5.3567])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.7046, -0.5603,  0.7831])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.7113, 4.5186, 5.3099])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.0919, -4.7090, -2.7643])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.7203, 4.6024, 4.2630])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.8405, 5.1961, 4.2143])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.9854, 4.7859, 4.5470])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.8988, 6.0014, 5.5465])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.3360, -3.9399, -5.1084])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0986, -5.8033, -7.4601])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([6.1162, 5.5306, 5.7119])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.7250,  1.7510,  2.0923])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.9352, -5.2323, -8.6895])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8254, -4.2419, -6.9048])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.7209,  2.0703,  1.9948])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.8115, -4.8578, -5.9904])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.0202, -5.3597, -5.9203])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.9831, -0.4551,  0.6063])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.7967, 5.4069, 4.5828])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.3672, 4.5470, 5.0992])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.8026, 5.2879, 5.0119])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.3950, -5.0250, -4.3130])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.4297, -3.1898, -5.7277])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8487, 4.2074, 5.1395])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.4245, -1.8084,  2.1138])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.6753, 4.9517, 5.3484])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.0890, 4.1393, 5.1598])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.4924, -5.5414, -5.7157])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.6317, 5.7113, 5.6240])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.9706, -5.9838, -7.2629])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.8859, -4.9218, -3.6898])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.2780, -5.8751, -4.0991])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.7932, -4.7560, -4.1912])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.7637, 4.9576, 6.4731])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.1151, -6.9349, -5.2787])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.6630, -4.6626, -2.8459])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.2788, -1.3554,  2.5251])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.3236, 6.0290, 4.8055])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.0413, -5.0623, -4.9768])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.3143, 4.3232, 5.5973])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8162, -5.3631, -6.1193])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.9714, -3.0711, -5.8308])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.0274,  0.2589,  2.9144])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.8831, -2.1412,  0.4654])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.8588, 4.8856, 5.4124])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.2307, -3.4683, -3.9459])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.8135, 5.1562, 4.5988])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.6302, -1.7083,  2.0097])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.5376, -5.8889, -7.1345])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.8310, -4.6745, -2.8393])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.0866, 5.2985, 5.4309])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.9155, 4.5825, 5.4370])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5781, 5.8136, 5.6167])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.4458, -7.0991, -4.3314])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.1419, -0.7796,  4.2416])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.7469, -5.6701, -2.7982])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.7610, -0.4363,  1.3414])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([7.7233, 4.1670, 5.3766])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.4165, -5.7343, -6.2716])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.2262, -5.8263, -6.0775])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.5347, 4.8129, 5.5322])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.8572, -5.2083, -3.3818])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.4498, -0.7660,  1.5652])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.2372, -5.0795, -6.6956])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.4739, -0.8593,  2.4813])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.8863, -6.9687, -7.1392])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.0221, 4.8025, 4.5035])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.9621, -3.6991, -8.0711])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.8135, 4.8434, 4.9277])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1166, -5.9332, -3.2801])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.7183, 5.3607, 4.4558])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.8019,  0.6980,  0.8833])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.9039, 5.0604, 5.4090])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.6122, -6.2599, -3.9151])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.5719, 4.9931, 4.5254])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.4823, -2.2348, -0.0740])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.2440,  0.5017,  0.8126])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.9489, -0.4981, -0.4400])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([6.3980, 5.0714, 4.7039])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.0301, -5.0828, -5.4294])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6206, -4.0018, -3.0642])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.9905, -4.6527, -6.2259])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3337, 5.1263, 4.7188])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.2704, -6.6968, -3.4434])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.2955,  0.1343,  2.6581])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.9457, -6.3073, -4.0400])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.4096, -5.5515, -1.9090])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.4901, 3.8429, 5.2479])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.4206, 4.8391, 5.0809])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.1343, -0.9234,  2.0146])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.0810, -2.7632,  0.3798])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.8460, 4.9698, 4.7132])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.0134, 5.3261, 5.5474])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.6187, -3.4996, -6.4419])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.6714,  0.2913,  0.7837])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([8.1188, 5.3670, 5.0066])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.3065,  0.2792,  0.7660])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.2774, -5.2750, -6.3049])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5352, 4.9433, 5.0639])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.3274, -6.0667, -4.9882])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.7076, -3.4886, -5.5650])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-7.9432, -6.1726, -5.5945])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.1337, -5.7278, -5.6963])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9251, -4.7761, -1.5200])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.1583, -4.7781, -3.7994])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.3182, 5.0835, 5.4446])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.8202, -4.5467, -7.2330])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.6924, -8.4304, -7.4189])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8039, 5.8551, 4.6800])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.8108, -4.9036, -6.2637])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9338, -3.6762, -6.6756])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.8996, -5.1638, -5.9496])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.0315, -4.3515, -3.4128])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.0668, -4.0869,  0.5085])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.3237, -5.8738, -5.3438])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.8916, -4.8788, -6.2662])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.8414, -1.4987,  2.4236])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.8503, -2.0065,  3.0078])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-6.3221, -6.4287, -3.0178])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.7717, 5.4221, 4.9420])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.0510, -2.2400, -2.2029])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.1183, 4.8929, 4.8809])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.4352, -6.3487, -4.8135])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.0936, 5.2794, 5.0039])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.8170, -3.8623, -4.4357])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.6225, -5.5645, -4.8014])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.7231, 4.2091, 5.0357])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.4959, -0.8678,  2.3331])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.9678, -3.3791, -2.0736])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6349, -6.8845, -7.2372])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.8876, -1.7694, -7.3775])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-0.4634, -0.8738,  2.3653])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.3383, -5.6515, -3.8622])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.8454, -3.8720, -4.5015])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.8011, 5.1685, 5.1235])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1999, -5.2941, -5.0850])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.9865, 4.3187, 6.0970])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.5761, 4.9591, 4.3802])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.4583, -5.2681, -3.1834])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.1478, 4.2459, 5.0196])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.4676,  0.2629,  0.9651])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.0103,  3.0391,  0.3158])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.4239, -4.1222, -2.0868])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.4710, 5.6731, 5.3900])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.4646, 5.3567, 6.4986])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.8461, 4.7294, 4.6598])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.4194, 4.3522, 4.5856])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-5.7174, -4.7528, -3.2325])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8227, -6.6624, -4.7013])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([7.0624, 5.0626, 4.7623])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.7935, -5.5659, -2.8459])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-2.5388,  1.3607,  1.7102])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-3.2549, -7.7591, -4.9922])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6400, -3.2168, -3.6820])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([7.3958, 5.2171, 4.8900])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.4741, 4.0816, 5.5596])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.3286, 5.9499, 5.2402])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.6949, 4.8865, 4.3081])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.7649, -3.5308, -2.7464])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.2720, -5.8183, -6.7669])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9261, -3.8943, -2.8972])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.7216, -7.8965, -5.6531])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.7802, 5.4133, 4.6254])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.2837,  1.0228,  1.3468])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-5.8491, -6.1485, -6.0032])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.4761,  1.1169,  1.0898])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([3.9773, 5.3826, 5.0112])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.2413, 5.3382, 4.8192])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.2355, 4.8626, 4.4557])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.7108, -6.5129, -5.3581])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.7763, -4.5303, -4.8448])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.4128, 5.1349, 4.8348])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.9196, -6.5945, -5.0629])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0724, -5.4725, -3.2380])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.9147, -5.8160, -3.6662])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.5587, -2.5062, -4.3053])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-1.8679, -1.1454,  2.2726])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.7692, 4.6068, 5.3574])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.5752, -1.3414,  2.9081])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-1.9307, -5.0507, -7.8520])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.7635, -6.4318, -6.6649])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.1877, 3.5177, 5.4453])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.7752, 4.8613, 4.7842])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-7.2734, -3.7484, -6.4604])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.6932, 5.3442, 5.0188])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.1921, -7.6091, -5.8808])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.9798, -4.8030, -5.5120])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.0177, -3.4625, -6.3658])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.0025,  0.1914,  1.3115])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.5941, -5.6081, -4.3842])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.5430, 4.8772, 4.6803])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.0574, -0.8516, -0.6630])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.6531, -5.3638, -5.4280])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8217, -3.8520, -1.0787])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.6705, -4.5600, -4.3065])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.7561, 5.1664, 5.0973])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.8064, -4.5923, -2.8240])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.3129, -5.3127, -3.2000])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.2073, 5.3802, 4.7088])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.4945, -0.4730,  3.3931])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([4.2297, 5.1555, 5.0874])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([5.5250, 5.7275, 3.5784])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.1932, -6.5648, -2.7385])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.1516, -6.4241, -2.8844])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([3.7387, 4.8631, 5.0266])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([5.3016, 5.0439, 4.7012])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.0710, -4.1315, -1.8937])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-6.5516, -3.8203, -7.6694])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.9009, 4.6357, 5.9812])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.8766, 5.0392, 4.5516])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-5.2018, -4.1369, -4.1839])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-5.4848, -4.0727, -7.3485])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.6450, 4.3038, 4.9239])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-0.5851, -0.2328,  1.5045])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.6664, -3.8470, -5.7296])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([6.0516, 4.0848, 4.7424])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([3.6246, 5.2830, 4.8922])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-6.2078, -5.9995, -4.8959])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-3.5518, -4.6541, -6.0520])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([-4.8493, -2.8245, -8.4416])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.4425, 4.4484, 4.9331])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([4.1070, 4.7799, 5.8413])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([7.2929, 4.3334, 5.3298])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-1.6102, -0.1598, -0.0633])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.5217, 4.8428, 5.2575])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.2329,  0.5947,  3.8899])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([6.4373, 4.6759, 4.9939])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.0537,  1.4523,  2.5920])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-4.0810, -4.5235, -4.7310])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([4.7441, 5.1091, 4.9170])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-4.4146, -0.1660,  2.0270])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.1753, -1.6948,  3.0430])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([-2.1406, -1.6341,  2.3699])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n",
      "Sampled xyz:  tensor([5.5057, 4.1547, 4.2672])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([6.3614, 4.7894, 5.4988])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-3.5234, -2.4055, -4.8132])  and my params:  {'mean': tensor([-5., -5., -5.]), 'variance': tensor([1.0000, 1.5000, 3.5000])}\n",
      "Sampled xyz:  tensor([5.9891, 5.4929, 4.7338])  and my params:  {'mean': tensor([5., 5., 5.]), 'variance': tensor([1.2500, 0.2500, 0.2500])}\n",
      "Sampled xyz:  tensor([-2.6170,  0.5888,  2.7939])  and my params:  {'mean': tensor([-2.,  0.,  2.]), 'variance': tensor([1.0000, 2.0000, 1.5000])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2602e99a0f4ba7b25d43dc49c284e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([5.5023, 4.5805, 4.6092])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.7276, -2.3312,  1.8633])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.9520, 5.3698, 5.5542])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.7727, -5.7360, -4.4028])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.6949, 4.6843, 4.6877])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.3165, -3.8261, -3.4225])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.9577, -4.3847, -2.3556])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.6497, -6.3649, -7.0917])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-0.8457,  0.6083,  4.9037])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.8235, -5.1035, -2.4730])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([ -5.0126,  -4.6595, -11.1354])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.9801, -3.1931, -8.3037])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.1319, 4.2060, 4.8880])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6328, -5.6145, -6.9124])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.8108, -4.0747, -4.2372])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.3312, 4.9711, 5.8717])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4500, 5.0721, 4.9762])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.4393, 5.7291, 5.1491])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5827, 4.0727, 5.1646])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9676, 5.3051, 5.5019])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3551, 5.8657, 4.7731])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.2528, -0.1414,  2.3712])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.8474, -4.0003, -3.3969])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7694, 4.5562, 4.9233])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8418, -5.0923, -3.5037])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.5292, -3.3317, -6.0737])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.4641, 4.6483, 5.1819])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.9930, 4.3554, 4.5372])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6712, -6.6376, -9.3313])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.7280, -6.7364, -1.6486])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.1025, 5.0930, 5.4212])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3734, 5.3499, 5.1526])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.5779, -2.7164, -4.3148])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.1274, 4.5324, 4.9270])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5032, 5.0649, 5.5177])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7057, 5.0477, 5.2265])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.6543, 4.9515, 4.8915])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.4062, 5.8093, 4.8070])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.0825, -6.0233, -3.9764])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9893, 5.2208, 5.2626])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6712, 4.9957, 5.2611])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5662, -6.6164, -3.9014])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.9016, 4.9378, 5.0846])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.5633, 5.1628, 4.3143])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6021, -4.0445, -3.7158])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.5477, -4.1299, -5.3190])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.3645, 5.2255, 5.2609])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1858, 4.6749, 4.6006])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.1239, -1.1062,  0.2224])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.9146, 5.1816, 4.9897])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.3166, -2.2010,  1.7552])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.8975, -4.2702, -4.1882])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.1321, -2.0459,  2.4447])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.1678, 5.5640, 5.3321])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.1436, -1.5671,  2.4139])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.3482, 4.5188, 4.9361])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.3296, 5.6501, 4.9517])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.3895, 4.5632, 5.7076])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.6037, 5.8962, 5.0760])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.0523, -0.5372,  1.8549])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-1.7765,  1.3049,  1.4553])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.6812, -5.3999, -3.9725])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.2160, 5.2130, 5.4489])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8233, 4.4365, 5.1311])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.7710, -2.2930, -4.5750])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([4.5094, 5.0685, 4.9679])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7271, 3.9096, 5.1019])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5748, 4.8605, 5.0246])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.1042, -5.3392, -0.9197])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1361, -5.0095, -4.8444])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.6930, 4.3849, 5.6585])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5405, 4.7945, 5.0044])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5823, 5.4440, 4.8733])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8071, 5.2133, 5.6522])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.3528, 4.7711, 4.9970])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6919, -3.3189, -5.2840])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.5423, 4.7483, 5.5886])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.0834, 5.1080, 5.0740])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.0310, -1.3265,  1.7331])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.1063, 4.6486, 4.8290])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0555, 5.0366, 5.5679])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3697, 5.8765, 4.9556])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7423, 5.8184, 4.5605])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8249, 5.0465, 4.5808])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.5013, -3.8234, -6.1313])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.2697, 5.7721, 5.5178])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5388, -5.4401, -1.2095])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.0009, 5.7963, 4.2913])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7025, 4.7960, 5.0117])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7511, 5.0491, 4.6958])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.0268, -3.1674, -3.2738])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.9788, -5.1970, -8.5164])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.2701, -2.8807, -0.8854])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.3531, 4.3061, 4.4685])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.2555,  0.6861,  2.3861])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.5395,  0.2028,  1.3678])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.1193, -4.0581, -4.7347])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.7700, -6.6894, -3.3982])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.2940, -4.2967, -3.5898])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.8085, -3.7197, -5.9558])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.1123, 5.1262, 5.2300])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.8442, -5.8975, -7.1451])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.5743, -4.1566, -8.6466])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.5316, 4.9552, 5.1511])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5699, -6.5666, -5.7226])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.8508, -4.1845, -4.7207])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.2003, 5.2708, 4.5843])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.0077, 4.6819, 4.9108])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6221, 6.0080, 5.5014])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6880, -6.6302, -5.9229])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.4132, -4.8664, -5.9816])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.4600, 5.0331, 4.9086])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.4455, -4.3981, -5.8951])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.5446, -3.4792, -4.2187])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1699, -6.0267, -2.8880])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.8911, -6.0389, -6.7164])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.9867, -1.0550,  1.8536])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.7136, 4.9273, 4.9396])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.0799, 3.8349, 4.4798])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4095, 4.6706, 4.6688])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.1891, 4.9418, 5.0997])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3699, 4.5283, 4.9649])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.1231, -7.7195, -4.7805])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.4505, -4.0703, -1.8068])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.9884, -1.1405,  4.2407])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-1.9375, -0.0168,  2.0288])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.0527, 5.3457, 5.5108])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.3336, -4.5588, -2.1049])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.8329, 4.5908, 5.3882])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6994, 4.8199, 4.8316])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.7115,  2.2094,  2.6006])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.4342, 5.6963, 4.9178])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9132, 5.5172, 4.7433])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.2783, -3.7498, -4.3565])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.4245, -0.8293,  2.4110])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([7.1347, 5.0872, 5.3871])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([5.4456, 3.8030, 4.6984])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0257, 4.1038, 5.1937])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.6318, 4.6541, 5.7152])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0457, 4.8993, 5.2482])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.4082, -2.1347, -3.9440])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.2271, 5.7253, 4.6919])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.1240, 4.3469, 5.1958])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.9763, 5.4901, 4.7216])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5977, -3.2935, -3.4435])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.1469, -0.1501,  1.0571])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.4656, 5.0185, 5.7947])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7074, 5.0039, 5.2797])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8240, 5.1111, 6.3385])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.8799, 5.0933, 4.6109])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.8077, 5.6181, 5.3859])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.6941,  1.6202,  2.9786])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.6716, -6.3998, -9.6675])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.8039, -3.5085, -5.6442])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.9798, -0.0752,  1.8146])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.4331, -5.0396, -7.3046])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.5477, 5.1619, 5.4967])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6115, -4.9260, -3.4255])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.2449, 4.8929, 6.0678])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8305, 5.1101, 4.4643])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.4338, -3.9020, -5.3412])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.0488, 5.3596, 5.0834])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.0744, -0.8956,  1.1789])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.6005,  1.9361,  2.4084])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.7270, 3.9483, 4.6913])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8935, 5.6212, 4.6364])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.0955, -6.4606, -5.5389])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.4306, -3.9725, -2.3609])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.0083, -1.1515,  0.6385])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([7.9167, 5.5119, 4.7091])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.4969, -4.3103, -5.6578])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.4981, 4.8195, 5.4423])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.7011, -0.2423,  2.4090])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.8244, -0.3503,  1.1195])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.0862, 4.6982, 5.0587])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6093, 5.1644, 5.1724])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2058, 4.9132, 4.4057])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.8021, -1.5775,  2.3179])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.9112, -4.8027, -5.3508])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([2.8369, 5.5789, 5.2190])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.0517, -1.3118,  0.1011])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.2396, 4.8333, 5.7340])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6388, 4.6751, 4.4272])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.1997, -5.5297, -8.2721])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.3740, 4.1913, 5.1629])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8661, 4.8262, 5.1433])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.2293, 4.6962, 5.1428])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6281, -4.3908, -2.9017])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.5938, 4.4771, 5.3452])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.2902, -4.6577, -3.6469])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.9903,  0.0170,  2.0644])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.7218, 4.6698, 5.9634])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.3632, 4.5231, 4.6209])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.1388, -4.2259, -4.9776])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.4201, -0.8599,  3.5761])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.2485, -2.8828,  0.3392])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-1.3798, -0.5797,  1.7952])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-0.5330, -0.7737,  1.0014])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.3515, 4.7287, 5.4853])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6083, -4.3599, -1.2982])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.4423, -4.1072, -5.5072])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([7.3471, 5.5951, 5.3069])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0017, 5.4660, 5.0394])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.2493, 4.5354, 5.5736])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.0156, -7.8005, -3.4314])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.3554, 5.2862, 5.6384])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.3886, -4.0818, -5.8247])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.3936, 5.1862, 5.0687])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([4.7931, 4.8425, 4.4320])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.8355, 5.6285, 4.9468])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.0396, -0.2644,  3.0069])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.1843, -3.4719, -5.1586])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.9223, 4.8676, 4.7646])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1951, 4.0262, 4.5474])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8178, 4.3007, 5.0883])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.9512, -0.6826,  2.1800])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-1.8622, -0.4770,  1.6227])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.9773, -5.6868, -5.0657])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.7272, -4.1318, -3.3627])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.4921, -2.0995,  2.2132])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.0621, 4.9641, 5.6016])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.1794, 5.5301, 5.4184])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5030, -4.1090, -4.3329])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.4744, 4.9774, 5.1736])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8419, 4.7142, 5.3714])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8819, 5.5219, 4.1898])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.2713, 5.2543, 4.6422])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2379, -3.8048, -6.3351])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0221, 4.6890, 5.2548])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8806, 5.0762, 5.5696])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.2181,  1.1917,  2.4302])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.8975, 4.8426, 4.8929])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.4726, -4.8762, -3.0604])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.7707, -3.7353,  1.6935])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.1761, 5.7477, 4.8549])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([2.4864, 5.1400, 5.6591])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.3163, 5.1983, 5.1829])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8262, -6.2802, -6.0932])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1507, -3.7858, -9.8050])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7930, 4.9567, 4.8296])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.7209, -3.8830, -4.7857])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.6798, 4.6273, 5.6354])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.7567, -1.9482,  1.8799])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.4649, 5.4680, 5.0734])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.9545, -5.3002, -4.9887])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.3565, 5.2304, 4.9010])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.3496, -0.1582,  1.6242])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.4883, 5.2425, 4.5715])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.5840, -2.4954, -5.5104])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.1576, 4.4534, 5.1449])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-0.9250, -0.6089,  1.3536])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.4446, 4.7727, 5.3572])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.4837,  0.5391,  2.5641])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([2.8415, 4.8874, 4.7669])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8124, -6.3650, -4.7238])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.8154, -3.0359, -0.2980])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.6745, 4.9700, 5.5468])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.2431,  0.1699,  2.1788])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.3179, -3.8685, -9.3584])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.1710, 5.5948, 4.5902])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3665, 5.3027, 4.7785])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([2.8435, 5.6423, 5.2613])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.0806, -4.2338, -6.6189])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.5596, -1.7947,  1.6675])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.7261,  0.6128,  4.2667])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.9612, 4.8112, 4.3904])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.6495,  0.4117, -0.0193])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.9632, 4.9172, 5.1250])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.9382,  0.7814,  0.9477])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.0516, 5.0662, 5.0750])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.1786, -5.4083, -3.7722])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.0499, -3.7573, -5.5736])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.2501, -0.0191,  2.8104])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.2200, -4.9377, -1.3845])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.0084, 4.5969, 4.5874])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.0662, -0.0118,  2.2757])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.4308, 5.0302, 5.1328])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1423, 4.7397, 4.6011])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.0731, 5.3377, 4.7321])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.9105, 5.2767, 5.1799])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-3.0551,  0.2083,  1.0700])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.3317, 5.7576, 5.2010])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.4501, -0.5814,  4.2179])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.3365, 4.4612, 5.4603])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7750, 4.4254, 5.6985])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.3669, -6.1768, -6.0296])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.5383,  2.6517,  2.6713])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.4210, 4.7805, 4.7010])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.4626, -5.8141, -4.7463])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.4233, 4.9677, 5.4285])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.3005, -3.3916, -5.3265])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.0136, 4.5298, 5.1773])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9986, 4.3987, 5.3222])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.4520, -4.8185, -7.7483])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([2.8464, 4.6091, 5.4111])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.1626, 5.2838, 4.8450])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.7290, -3.3559, -5.9425])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.5971, 4.3765, 4.7693])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.1589,  0.9492,  1.7851])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.9370, 5.4937, 5.3449])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2212, -3.9690, -2.1640])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.0960, 5.8729, 5.2032])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.7772, -4.9140, -6.1403])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.6745, 4.6778, 4.9783])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.2878, -4.3396, -0.4310])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.2359, -1.9900, -7.6376])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9707, 4.8287, 4.5086])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.0123, 4.2391, 4.7465])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5356, 5.2455, 5.4988])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.7213, -3.7589, -5.1259])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1571, -2.7155, -6.4488])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.3217, -0.1426,  0.7773])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.6127,  0.8163,  1.0017])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.7787, 5.5556, 5.3173])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.3994, -4.7319, -6.3620])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.5752, 5.0979, 5.1660])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3434, 5.4378, 5.8093])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.8999, 4.9619, 5.4326])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.2565, -0.4832,  3.4528])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.4148, -4.2507, -2.4789])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.5882, -3.4568, -1.4798])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9291, 4.4696, 4.8514])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.3423, -3.4583, -3.7989])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.9920, -4.6867, -6.2700])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.0855, -0.4268,  2.8077])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.3531, -3.6416, -2.8845])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.8472, 5.4378, 4.5140])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.7703, -4.7440, -7.3604])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.7878, -6.0388, -3.1037])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.5103, -0.4235,  2.1088])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.1190, 5.3371, 5.8790])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.1513, 5.7050, 5.0697])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.5047, -4.3137, -7.2387])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.2190, 4.6534, 5.1728])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7314, 4.2381, 5.3370])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.2042,  1.7058,  0.3982])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.8208, -3.5026, -7.6424])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.2303, -3.4446, -4.4232])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.9852, -7.3922, -4.8278])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.7486, -5.0089, -6.3789])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.7846, -0.6124,  1.8575])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.7839, -4.0178, -5.2998])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9181, 5.4438, 4.8550])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-3.0332, -0.1378, -0.3103])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.6218,  0.5559,  1.8813])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.4196, -2.9286, -5.8322])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.6138, -5.7727, -4.7681])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9249, 4.5348, 4.7394])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.0848, 5.1070, 5.0785])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.2933, 5.7131, 5.6366])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5169, -3.6588, -8.7996])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9851, 4.6655, 5.4326])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8096, 5.7701, 4.8085])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.5399, -1.2533,  2.7805])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.1973, -5.9001, -7.4555])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.7272, -4.0601, -7.4959])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.3992, 5.4368, 4.7169])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2665, -5.0277, -6.3870])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.7395, -4.1716, -1.6206])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0329, 4.8118, 4.9870])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.2708, -0.1566,  0.6478])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.5591, 4.7313, 4.7557])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7811, 4.7374, 4.8480])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3113, 4.9680, 4.6143])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.5271, 4.8426, 4.6197])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8634, -2.5581, -5.7416])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.6316, 5.8247, 4.9395])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4456, 5.7679, 5.4557])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.4155, 5.0815, 6.0878])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.4362, -0.6600,  1.3054])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.9866, -3.2295,  0.0860])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.5369, -5.4394, -6.2298])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.4551, -5.1235, -4.7599])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.6312, -3.0358, -4.9401])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.4643, 4.8942, 5.0478])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.0940, 4.4757, 5.6890])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8659, 5.4995, 5.1769])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.6710, -5.8790, -5.4013])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.8739, 5.2087, 5.3666])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.3354, -6.7408, -2.2725])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.6320, 5.3223, 5.4838])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6752, 4.9018, 5.3354])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2418, 4.8436, 4.8654])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.8496, -2.8562, -2.3231])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.3355, -4.2278, -3.3976])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.0650, 4.7593, 5.7815])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7775, 5.5010, 5.1566])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6103, 4.6514, 5.5151])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.0148, -0.4258,  3.0537])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.9064, 4.6250, 4.9963])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.1042, -0.4663,  1.7288])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.5360, -3.1707, -4.4769])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.8322, -5.6740, -1.7667])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.2967, -3.4088, -4.9650])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.9998, -4.2816, -3.7054])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.9184, -0.2244,  0.9861])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.6850, -3.5725, -6.9400])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.4868, -0.9846,  2.3235])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.6227, 4.8368, 5.0224])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([ -5.3527,  -5.3453, -12.6411])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([2.9839, 5.7106, 4.8278])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8443, 4.6454, 4.9407])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.4305, -5.0242, -3.3019])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.7667, -4.6210, -6.6710])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.3615, 4.2915, 5.1247])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5820, -3.3242, -8.4780])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.2052, 4.8349, 4.9333])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2521, 5.2497, 4.9805])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.4365, 5.4240, 4.8206])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4480, 5.2512, 4.8741])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([4.5316, 4.8477, 4.6516])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.4557, -5.4820, -1.5518])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.2694, -0.1348,  1.1232])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.6509, 5.2084, 4.5965])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.2935, 4.9024, 4.7479])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8377, 4.9454, 5.8003])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.2593,  0.2841,  2.9841])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.5308, 6.1147, 5.2877])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.3856, 5.9216, 5.5066])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.7353, -6.7230, -2.8482])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.5870, -1.7507, -4.6913])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.9976, -2.8536,  0.8540])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.8283, 4.8673, 5.6868])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.8274, -6.5957, -8.6505])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.8979, 5.3130, 5.4668])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6823, 4.5320, 5.2559])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.2844, 5.1150, 5.3665])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3342, 4.1658, 5.3840])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7102, 4.1558, 4.7566])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.0250, 5.5738, 5.3104])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.8180, -5.0905, -2.9385])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.8988, 5.3705, 5.5056])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.3771, -3.0379,  1.2161])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.7530, -4.4206, -4.3138])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.3568, -1.5191,  2.7897])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.5932, 5.4782, 4.8887])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3031, 5.2587, 4.7175])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.0855, 5.2145, 5.0621])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7398, 4.1950, 4.8863])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.6291, -2.1981,  3.0730])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.2073, -6.9305, -5.1837])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.8065, 4.8068, 4.9637])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4468, 5.2923, 4.6211])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4250, 4.7490, 5.8378])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6236, 5.0273, 5.3167])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.0096, 4.4628, 5.3826])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7222, 4.6918, 4.9871])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.4682, -2.0611, -5.3502])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.0107, -2.9623, -1.9794])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.7525, -1.6374,  2.3905])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.9481, -3.9848, -4.3395])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.1334, 5.8804, 4.9497])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.4252, -6.0533, -5.6367])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.7027, -2.2628,  1.5634])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.6121, -4.2405, -4.6862])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7859, 4.3816, 5.1796])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9189, 4.3562, 5.0288])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6210, 5.2270, 5.3148])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.3648, 3.8528, 5.6446])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.6444, -2.0108,  0.8371])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.1896, 4.9054, 5.6470])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7553, 4.9606, 4.9140])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.7337, -6.1217, -4.9012])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.7116, -3.3344, -5.9225])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.6563, -6.3511, -3.2822])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.8702,  0.4406,  2.7609])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.0185, -1.7494,  3.1175])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.5152, -0.0533,  0.9665])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.9513, 4.8904, 4.6731])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.3880, 5.2888, 5.1085])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.1149, -4.4128, -5.7278])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.4329, 5.3476, 4.8777])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.7067, -1.8137,  3.2382])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.9996, 4.9633, 4.5905])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.6593, -1.3945,  1.7450])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.6118, -4.4625, -2.3330])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.0362, -5.6575, -6.6345])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.0932, -3.3583, -4.2545])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([5.0682, 5.5590, 5.4138])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6897, 4.8323, 5.1763])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2854, 4.4591, 4.3876])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1530, 5.2161, 5.4648])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.1287,  0.5879,  2.4030])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.0215, 4.8107, 4.8432])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.2620, -1.8052, -4.4998])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.1359, -3.7538, -8.5233])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.6955, 4.4929, 4.3497])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9294, 5.1331, 4.2736])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.9282, -5.3647, -5.6815])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.4263, -4.5272, -6.3058])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.3933, 5.0568, 4.4137])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.8478, -7.1397, -2.6823])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.6439,  1.0504,  1.4629])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.4863,  0.4895,  1.4308])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.6045, 5.6272, 5.2657])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.4912, 5.1396, 4.9562])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.3207, 5.0465, 4.8958])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2127, -3.6320, -7.2965])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.1955, -1.3617,  3.2960])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.2597, 4.4304, 5.4514])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2504, 4.4288, 5.2609])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.3865, -4.6913, -3.6279])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7572, 5.9947, 4.8195])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2968, 4.5403, 5.3336])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9572, 4.6187, 4.6983])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-0.6374,  0.7014,  2.3133])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.6092, -5.6834, -4.6311])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.5747, 6.1428, 4.7793])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6727, 4.2387, 5.3391])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.1604, -3.8129, -5.9447])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.8011, 5.0238, 5.5801])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.1380, -5.8058, -4.9704])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.9717, 5.8510, 5.2507])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.8429, -4.6383, -5.9005])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.2253, 5.1392, 4.5666])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5666, -5.2554, -5.2217])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1373, -0.6150, -3.9451])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.1439, -1.0009,  0.0448])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.1827, 5.5440, 5.8390])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6745, -5.2246, -4.3614])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.8619, 4.8727, 4.6876])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([7.5821, 5.0427, 5.5556])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.8639, -0.2064,  1.9150])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.5452, -6.7123, -7.1434])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.8248, 5.8090, 5.1212])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7416, 4.2797, 4.8731])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.1826, -0.0193,  1.2389])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.8756, -4.2308, -7.2849])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.5008, 4.8917, 4.4815])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8794, -5.7167, -7.4466])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.6211, 4.7363, 4.9448])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6584, 5.1152, 6.0226])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.7314, 4.3881, 4.7381])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.1783, -5.1180, -3.4209])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9162, 5.2255, 4.3940])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.3105, -1.8786,  3.1266])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.2088, 5.5518, 4.5853])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.0273,  0.1153, -1.0287])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.1012, 5.1975, 5.1583])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.5908, 4.2278, 4.8143])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.6949, -0.7694,  1.2604])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.3966, 5.1171, 5.1220])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([4.2573, 3.9978, 5.5533])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.7119,  0.5567,  2.9879])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.2145, 4.5432, 5.2528])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5261, -4.9866, -7.0019])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.0052, 5.0436, 4.2067])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.8890, -4.6730, -6.5684])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.9538, -2.2269,  2.3430])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.8084, -3.7266, -2.5720])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([2.2269, 5.1195, 4.9860])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.0864, -3.5558, -5.3940])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1820, -2.7343, -2.3922])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.0824, -4.6508, -4.8072])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.8617, 5.3778, 4.6509])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3853, 5.4223, 5.0115])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.0688, -4.5765, -8.7929])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.6945, 4.6553, 5.2500])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([2.7621, 5.4358, 5.5921])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5706, -3.1024, -2.9730])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9194, 5.4757, 5.7932])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5358, -5.9166, -4.6276])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([2.6561, 4.8312, 5.2665])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4567, 4.8708, 4.7888])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.5594, -5.9778, -4.7666])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.3781, 5.6378, 4.2101])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.3488, 4.8493, 5.2921])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7892, 5.3282, 5.3073])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6411, 5.7203, 4.6729])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5916, 4.6476, 4.5677])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5906, 5.2308, 5.1002])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5359, 4.9215, 4.7695])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.0582e+00,  9.5954e-05,  2.1351e+00])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.3359, 4.9052, 4.5844])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.9542, -1.1141,  1.5198])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.5605, -4.9375, -3.7029])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9967, 4.7214, 5.1395])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7923, 4.7346, 5.2604])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8638, 4.6674, 4.9582])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([1.8781, 4.9610, 4.7006])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4888, 5.7031, 5.5946])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.6241, -0.0213,  1.1095])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.9880, -4.4485, -4.2967])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.4979, -5.4345, -5.5979])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7898, 5.8624, 5.2894])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5772, -6.2191, -5.6553])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9750, 5.5756, 5.7890])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0921, 5.6906, 5.9477])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2082, -1.3465,  3.9805])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.3456, 5.5533, 4.6849])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.4952, -0.9463,  2.7404])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.2943, 4.7281, 4.5093])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9165, 4.7449, 5.3022])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.3461, 4.4389, 5.4302])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.6969,  1.9473,  4.0129])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.5288, -3.1033, -9.0016])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.0179, -4.0514, -2.2399])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.2207, 5.5512, 5.1905])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7603, 5.1870, 4.2034])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.7376, -4.4411, -4.4216])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.4727, 5.5489, 4.9446])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.9435, -4.5216, -3.8078])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.2119, -2.9090, -5.4774])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0511, 5.5282, 4.6255])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5575, -5.2483, -4.9866])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.7933, 4.9249, 5.4174])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4151, 5.1337, 5.3340])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.5944, 4.7030, 5.3902])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.4824, -5.3054, -5.1032])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([5.2980, 4.8390, 5.2083])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3187, 4.8556, 4.7154])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3843, 4.7440, 4.9806])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([2.4646, 5.5068, 4.6221])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.7690, -3.1671, -4.7198])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.4744, -4.8828, -7.4512])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([ -5.5232,  -6.0058, -10.1860])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.8946, 5.3191, 5.3972])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6126, -5.2852, -2.2526])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.8948, -0.9016,  2.4153])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.8955, -1.5718, -0.1748])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.5825, -0.2601,  2.5033])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.9046, 5.1744, 4.9970])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([2.8814, 5.5629, 5.6102])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8616, 3.6278, 4.2964])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7414, 4.6083, 5.9241])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.4947, -6.0624, -1.2234])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.2938, -3.5057, -3.9187])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.2280, -4.7962, -5.7628])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.2741, -1.8243, -6.1295])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-0.9921,  1.0668,  2.5258])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.6257, 5.7568, 5.1635])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8575, -3.6727, -4.7663])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0817, 5.3423, 5.0221])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.7711, -5.7515, -4.5749])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.6808, 4.4192, 5.5529])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.9445, -7.0027, -5.5813])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.1064, -0.5342,  0.7770])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.9061, 5.7981, 5.6611])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6996, 4.7228, 4.3724])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.4626, 5.2382, 5.0543])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.8848, -6.1349, -4.0161])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.0319, -5.6108, -1.9555])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.7312, -5.6589, -8.4072])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.9393, -7.1911, -1.9650])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.8702, 5.9364, 5.4674])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.1382, -6.6297, -4.1574])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.3738, 5.1942, 5.1743])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8339, 4.7727, 5.2015])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.5855,  1.2308,  2.1243])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.0040, 5.2954, 5.0834])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2984, -0.5503, -0.8048])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.2974, 5.2863, 5.2497])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.4499,  1.5988,  3.3546])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.4693, -5.5445, -7.3718])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.6419, -2.5607,  1.7863])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-1.8618, -1.1163,  3.4192])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.4766, -6.1604, -8.9733])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.5147,  0.2161,  0.7635])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.7659, -4.5600, -1.5911])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.2583, 4.8156, 5.6196])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7810, 5.4707, 4.7716])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.3077, -3.2287, -2.1209])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.3982, 5.6370, 5.5487])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.4648,  0.1006,  1.3838])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.5156, 5.3683, 4.8839])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8814, 4.8412, 4.9001])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.5761, -5.5224, -3.3867])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9169, 4.9990, 5.1392])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.2002, -6.9859, -3.5621])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.2654, -3.0793, -3.7307])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.5243, 4.8228, 5.2680])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-0.9736,  0.7444,  0.3232])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.5244, 4.4278, 4.3554])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7336, 4.3287, 5.4123])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.2325, -0.1999,  2.3524])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.3798, -5.2688, -4.3273])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.0291, 4.3847, 4.7608])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5617, 4.7521, 4.7152])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.1691, -0.3102, -0.2330])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.7212, -6.0932, -2.1330])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.4482, 4.3549, 4.5176])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.2740, -1.0645,  2.1770])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-2.7862,  1.5720,  1.8749])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.6395, 5.6644, 5.1084])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.1527, 5.5790, 5.3263])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.8284, 4.9620, 4.8747])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5822, 4.9888, 4.8871])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.0408, -4.6905, -2.8980])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1359, -4.3071, -3.3114])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.5209, -0.4253,  1.5600])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.7929, 5.7992, 5.2506])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8685, -4.7696, -6.5503])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.4232, -0.4839,  1.5139])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.5757, -0.0243,  1.4546])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.2199, 5.6572, 5.3825])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.8925,  2.1064,  2.1979])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.2433, 5.8151, 5.2281])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0289, 5.2949, 4.6872])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.4560, -3.2762, -5.0797])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7561, 4.8467, 4.9265])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5873, 4.5194, 5.3039])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0380, 4.8017, 4.9400])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8770, 5.2555, 5.1491])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6229, -8.8918, -8.7868])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9428, 4.8185, 5.1723])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6098, -3.9960, -2.9476])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.8699,  0.2488,  1.1835])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.8302, -4.4016, -5.9880])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.4924, 5.3036, 4.8670])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7412, 4.7363, 4.9248])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2598, -7.6070, -3.7519])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.6069, -2.9293, -2.4569])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.5078, -2.6186, -1.8286])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9893, 4.5763, 4.6736])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5356, 4.8639, 4.9340])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.6284,  1.1221,  0.9752])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.1069, 4.5232, 4.5993])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.2575, 4.7108, 5.4021])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.3526, -4.1674, -5.3960])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.4014, -5.5643, -5.9154])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.0909, -5.0611, -4.1843])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.6757, -2.6161, -6.7950])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.4679, -6.3400, -3.4380])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.1441, 5.1155, 5.5093])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8930, -3.7964, -6.8456])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.8517, 5.2519, 4.8143])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5354, 4.6448, 5.3478])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.8103, -2.7103,  2.8619])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-6.3121, -5.3151, -3.9195])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.6296, 5.0060, 4.6372])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6086, -6.4069, -1.7820])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.0161, -5.3208, -3.4487])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.2260,  0.9973,  1.3816])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.0471, 5.3258, 5.4018])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.7170, -4.3980, -6.5879])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.5300, -3.7532, -2.1982])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.9605, -1.1488,  0.8282])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.0038, 5.4982, 5.1641])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8196, -3.3000, -6.2384])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0152, 5.1149, 5.4575])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([2.7976, 4.7380, 5.3083])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.2056, -4.5908, -5.2304])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.2861, -4.9711, -6.6922])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.6725, -3.9630, -3.6734])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.0399, 4.8454, 5.0614])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.2706, -1.4641,  1.6818])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.9553, -0.3483,  1.3467])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.3352, 4.5328, 5.2360])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.0519, -5.3838, -6.1292])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.0007, -1.2624, -6.5068])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9876, 4.9006, 5.5692])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.6558, -3.4659, -0.6254])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.3549, 4.7596, 4.8665])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.0751, 4.8295, 4.2477])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([5.1720, 4.6948, 4.2095])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8730, 5.0521, 5.9562])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.6669, 5.3514, 4.6613])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.0669, 4.7285, 4.8707])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.9639, 4.5325, 4.6566])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5894, 4.6613, 5.4437])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.3688,  0.9972,  1.3059])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.0387, 4.8610, 5.3089])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8141, 4.9442, 5.1244])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1668, 4.9357, 5.1485])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.3961, -5.1181, -4.2922])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.8622, -2.8566,  1.0324])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.3588, 4.8017, 5.3764])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.2020, 4.7240, 5.1693])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6588, -5.1559, -1.5771])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.4023, 4.8122, 5.7136])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.9208, -6.1626, -5.7029])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.3315, 5.4485, 5.5455])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.4255, 5.1558, 5.0896])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.2268, 4.7397, 4.7877])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.7111, 6.1041, 5.0203])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.7546, 4.5320, 5.2933])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.6145, -1.0806,  1.9065])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.8403, 5.8789, 5.1100])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.9726, -5.3193, -2.2720])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.0728, 5.0734, 4.7660])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.0625, -0.0157,  2.7831])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-6.0272, -6.6908, -6.9549])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.8155, -5.1122, -1.1121])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0627, 3.9670, 5.0264])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6420, 5.3775, 4.5084])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.5894, -2.3206,  2.3051])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.2969, -3.2329, -2.8394])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.6606, 5.1076, 4.8006])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.6124,  0.6691,  0.2268])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.8509, 4.6170, 5.6183])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.0195, -0.3649,  0.7419])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.8367, 5.2428, 5.3370])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2685, 4.8709, 4.2776])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1583, 5.7142, 5.2134])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.1364, -2.9145, -1.1474])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.5522, 4.4310, 4.8555])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0229, 6.2055, 5.5241])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.6304, -5.9763, -2.0600])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9836, 4.6147, 5.5821])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8753, 4.3808, 5.1330])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.4209,  2.1311,  2.4872])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.7795, -0.5303,  0.7083])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.0048, -5.9084, -5.1332])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.7689, 5.2625, 4.6027])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.0971,  0.3006,  0.6079])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.8124,  0.6417,  4.6978])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.8285, -2.8814, -4.8654])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.5178, -1.6967,  2.4257])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.7856, -3.8632, -1.6549])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.3159, 5.2274, 4.7238])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.7087, 4.8769, 5.0704])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.4208, -1.4996,  2.6581])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.7631, -4.2906, -3.3932])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.6335, 5.3401, 5.0250])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2936, -5.1493, -8.5246])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.0591, 4.6939, 5.4727])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.0016, -4.1001, -5.2398])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.7151, 5.3936, 4.4998])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.2305, 5.2837, 4.7405])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.5395, -4.8406, -0.2864])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.7900, -4.4676, -5.2926])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.8060, -6.0342, -2.8431])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.6659, -4.1851, -5.5151])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.1245, 5.1692, 4.4503])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.0887,  1.3792,  2.1880])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([4.4907, 5.0831, 5.0069])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.1539, -6.3814, -7.1695])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.1261, 4.4198, 5.0852])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.8590, -2.6067, -1.3816])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.5111, -1.3360,  2.6056])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.4553, -5.1867, -8.1167])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.5979, -5.1681, -4.6984])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.1546, -3.5910, -5.6529])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-6.1027, -5.2907, -3.8774])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.9539, 5.9445, 5.3509])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8083, 4.6047, 5.6351])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.5431, 4.9170, 4.7265])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0727, 4.9432, 5.2478])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.9100, 5.1460, 5.1085])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.0962, 5.2913, 5.9516])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.1920, 4.7614, 4.7675])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.6103, 4.6361, 5.7321])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.3240, -4.3492, -2.6302])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.2551, 5.1199, 5.1854])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.9618,  0.0400,  1.9677])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.6761, -5.3988, -4.0759])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.7360, 4.6733, 4.9184])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.0133, -4.3806, -2.9456])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.6109, -3.5419, -4.7312])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.8482, 4.7056, 4.5520])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.5015, -2.7126, -8.9295])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7663, 6.4891, 5.1068])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.4824, -4.5346, -0.5242])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.9566, -5.3082, -4.0629])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.3379, -5.6925, -1.8135])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0952, 5.0600, 5.3247])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.3187, -0.2316,  3.4933])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.0873, -5.6815, -4.0519])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.7395, -5.6594, -7.0601])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.9334, -5.7692, -8.4217])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.1153, 5.6534, 4.8971])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.9009, -1.0320,  0.9705])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.6956, -0.5475,  3.7072])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.0256, -2.2775, -5.9255])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0894, 5.3045, 5.7258])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.4708, 5.2924, 4.8496])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.9423, 4.9759, 4.9002])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.2007, 4.5655, 4.9855])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.6661, 4.7490, 4.4902])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.0409, 5.6060, 4.3044])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.1349, 5.4174, 5.0491])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2860, -3.7865, -4.7388])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.0877, -1.3382,  3.3227])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.2422, -3.8281, -3.6889])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.6696, -2.1501,  0.2440])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.1324, 4.4309, 4.5856])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.0602, 4.4557, 4.7355])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.6390, -8.7636, -5.0990])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.8709, -1.0259,  2.1888])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.6903, 3.9065, 5.4098])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-0.5189,  1.2968,  3.3150])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.1539, -2.8717,  4.1832])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([2.9342, 4.0901, 4.0164])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.2640, 5.0885, 4.8958])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.9446, -3.9147, -5.8087])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.6420, 5.2327, 4.9825])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5413, 5.0900, 5.0130])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.4811, -3.7691, -4.6610])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.8603, -4.8742, -3.8488])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([7.0465, 5.3169, 4.8137])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5712, -4.5191, -4.7321])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-0.4571,  1.9185,  1.7235])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.9467, 5.0311, 4.4544])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.9065,  0.8152,  1.9005])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.2293, 4.6087, 5.5023])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.1269, 4.9591, 6.0802])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-3.7810,  0.4252,  1.5649])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.2731, -5.7361, -2.1064])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.5955, 4.0361, 4.8118])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.5199, -2.1974,  0.4727])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.1510, -0.6534,  1.7473])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.3715, 4.7330, 5.3173])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.9911, 5.4295, 5.1357])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-0.8290,  0.5009,  3.9030])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([6.5433, 5.0606, 5.1947])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.8666, 5.0024, 4.8865])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.2155, -3.8736, -8.2445])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.6275, 4.9934, 4.7613])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.6655, -2.9357, -3.7304])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.0456,  0.9609,  1.5005])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([5.1568, 5.8065, 5.0647])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.2421, 4.4458, 4.9663])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.4774, -4.1311, -7.0475])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.0023, 4.8758, 5.2143])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5405, 4.4692, 5.3029])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.6047, -5.9314, -4.1006])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.2417, -1.3809,  3.3015])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.7259, -5.1595, -3.5953])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.2097, -2.1991, -0.5135])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.0008, -4.3236, -3.9927])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.7560, 3.8796, 4.9563])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5207, 5.4237, 5.1641])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.5293, 4.4136, 4.8692])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.3228, 5.4573, 5.2823])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.5991,  0.5283,  3.0931])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([3.3032, 5.8958, 4.7653])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.1926, 4.8645, 5.1088])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-6.1081, -6.1530, -4.5137])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.7191, 4.5422, 4.6614])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.4157e+00,  2.1863e+00,  3.0159e-04])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-6.4081, -3.8667, -4.9988])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.4403, 4.4649, 4.3472])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.4228, -0.6786,  1.8602])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.3782, -6.6911, -5.7951])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.9727, 5.6851, 5.5137])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.0503, -2.4606, -4.7678])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.4553, 5.4868, 5.4979])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.2593, -5.4706, -4.6434])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.1463, -3.9527, -7.5747])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-3.7413, -5.9686, -4.5487])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.2257, 4.4461, 4.6268])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.8560, -4.3670, -4.9272])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.5202, 4.4761, 4.6303])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.3814, -5.0236, -1.2894])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.5439,  0.5996,  2.2689])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.3361, 4.9571, 5.3813])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.4673, 4.8077, 5.0247])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.2587, 5.0049, 4.5880])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.9572, -6.2592, -5.7962])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.1954,  0.5207,  2.4936])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-1.9320,  0.0896,  1.6594])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([2.7290, 4.7324, 6.1167])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.1036, -4.9702, -2.9795])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.6373, 5.2497, 3.6004])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.0359, -0.1274,  1.4475])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.5510, -7.7280, -1.5050])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.7406, 5.4591, 4.9764])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.2835, 5.1627, 5.2007])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.5683, -5.9997, -6.0732])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9264, 4.8481, 4.7862])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-2.8314,  0.7250,  2.6522])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-5.3238, -4.9657, -7.5732])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.2395, 4.9556, 5.0442])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.8630, -2.6884,  0.8024])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-4.6444, -1.2155, -6.3929])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.6045, -3.2498, -5.4336])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled xyz:  tensor([-4.9561, -3.3577, -1.7426])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.1706, 4.5878, 5.5301])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1045, 5.4575, 4.5652])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.8109, 5.2102, 5.2377])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.1346, 5.0157, 4.9955])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-4.0425, -2.8530, -7.4069])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-4.6155, -6.4444, -6.9430])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-5.0803, -4.2915, -7.2248])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([4.8378, 4.8575, 5.9649])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.5970, -3.7894, -5.9342])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([5.5708, 4.5790, 5.1826])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.6472, 4.7031, 5.5283])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([6.3660, 5.0205, 4.6591])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([5.3714, 4.6786, 5.0553])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.5966, 4.9537, 5.6053])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.5012, 5.2736, 4.6692])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5467, 4.6340, 4.9534])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.4418, 5.0240, 4.4674])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-1.0776,  0.2700,  2.5800])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-2.9711, -4.0776, -1.9281])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.2545, -3.0495,  1.4692])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-1.9810, -1.4677,  2.1149])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([4.8580, 4.6346, 4.9464])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.0593, -4.4159, -5.9335])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([6.7976, 4.4616, 5.3373])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-3.3494, -5.1186, -6.8511])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([3.9223, 4.5743, 4.5710])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.1628, 4.6702, 5.3660])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([4.5783, 5.0347, 4.6327])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([3.8246, 5.0610, 5.0941])  and my params:  {'mean': tensor([4.9814, 5.0070, 5.0496]), 'variance': tensor([0.9730, 0.2343, 0.1815])}\n",
      "Sampled xyz:  tensor([-5.4153, -3.6649, -2.5525])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-1.4812, -0.0389,  1.2814])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n",
      "Sampled xyz:  tensor([-3.2167, -2.8894, -3.2470])  and my params:  {'mean': tensor([-4.9046, -4.7184, -4.7043]), 'variance': tensor([0.7268, 1.8225, 4.4287])}\n",
      "Sampled xyz:  tensor([-2.8317, -0.1335,  3.9740])  and my params:  {'mean': tensor([-2.2439, -0.6126,  1.7560]), 'variance': tensor([0.8142, 1.5000, 1.1622])}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjTklEQVR4nO3df3Rc5X3n8fc3ErZTTBLHmFBGMrYQ+Mhaekw6ApOQ1JQQGcEKmgWhpNljjkO85IjCIUtS07QKq5BGTbqlpSIJTsMmaY+tpJAgdYuVmtY0bcGRResQrATLWGDPbEhcmRA4GITH3/1jruTRaGyNpPl55/M6R8f3Pve5M1/5GX316Ln3Po+5OyIiEl5vKXYAIiKSX0r0IiIhp0QvIhJySvQiIiGnRC8iEnJK9CIiIadELyISckr0IiIhp0QvIhJySvQ5YmbnmdkRM3t3sH+OmR02s3XFjUzmy8w+ZWYPp5XdZ2Z/UayYZP7M7EYzezXl6w0ze7zYceWDaQqE3DGzjwN3AFHge8CP3f3O4kYl82Vmvw7sByLu/kszqwb+H3CVuz9V3OgkF8zsbcAPgT939weKHU+uKdHnmJn1AysBB5rc/Y0ihyQ5YGbbge+6+9fM7Brgi+6+uthxyfyZ2VuAfuCQu3+i2PHkg4Zucu9rwH8B/lJJPlS+CXw02P4o8NdFjEVy6/PAGcBtxQ4kX9SjzyEzWwz8CNgJXAVc6O5HihuV5IKZLQJ+BrwP2AWsdveDxY1K5svM2oFukn99Hy52PPmiRJ9DZvZ1YLG732hmW4B3uHtbseOS3DCzrwGXAP/p7r9d7HhkfszsIuAfgCvdfU+Rw8krDd3kiJldC6wHJsb4Pgm828x+t3hRSY59E7gQDduExbXAEuBfU+682V7soPJBPXqRLJnZcuCnwNnu/qtixyOSLfXoRbIQ3JnxSaBXSV7KTXWxAxApdWZ2OvBz4AWSw3MiZUVDNyIiIaehGxGRkCu5oZszzzzTV6xYUewwBHjqqaf+092X5er11LalQe0aTqdq15JL9CtWrGBoaKjYYQhgZi/k8vXUtqVB7RpOp2pXDd2IiIScEr2ISMgp0YuIhFzJjdGLSPl78803icVivP7668UOpeAWLVpETU0Np512WrFDmaRELyI5F4vFOOOMM1ixYgVmVuxwCsbdGRsbIxaLsXLlymKHM0lDNyKSc6+//jpLly6tqCQPYGYsXbq05P6SUaIXkbyotCQ/oRS/byV6EZGQ0xi9iOTdvTv25fT17rjyghnrVFVVceGFF07ut7e3s3nzZtatW8eBAwd44YUXJnvf1113HY899hivvvrqtNe57777+MpXvsK73/1ubrzxRoaHh9m8eTOPPPIIF1xwAatXl/7SwUr05WrnF6buX35XceKQokhNnNkkvUr01re+lT179mQ89o53vIN/+7d/47LLLuOXv/wlP/vZz076Ol/+8pd57LHHqKmpAaC1tRWARx55hGuuuSaviT5X7ayhmwo2MDDAqlWrqK+vp7u7+6T1zOy/mZmbWTSl7C4z229mz5pZc0EClqyoXWfW3t5Ob28vAN/97nf50Ic+lLHeLbfcwoEDB7jqqqu49957+cY3vsGtt97KE088QX9/P5/61KdYs2YNzz33XCHDnzUl+gqVSCTo6Ohg+/btDA8Ps23bNoaHh6fVM7MzgNuBH6aUrQbagUaS87N/2cyqChS6nILa9YSjR4+yZs2aya9vf/vbk8euuOIKfvCDH5BIJOjt7eXGG2/M+Bpf/epXOeecc9i5cyd33HHHZPl73vMeWltb+dKXvsSePXs477zz8v79zIeGbirU4OAg9fX11NXVAckeTl9fX6Y/Qz8H/AnwqZSya0mutPQGMGpm+4GLgSfzH7mcitr1hFMN3VRVVXHZZZfR29vL0aNHCfvsm+rRV6h4PE5tbe3kfk1NDfF4PL3arwG17v73aeUR4FDKfiwokyIrVLua2SYzGzKzocOHD88/8CJob2/ntttuo62trdih5J0SvWR0/PhxgFrgf87ndcKQEMIkV+3q7lvcPeru0WXLcja1fUG9733v46677uLDH/7wnM4/44wzeOWVV3IcVX5o6KZCRSIRDh060XmLxWJEIic6b8EHeBHweHAL2tlAv5m1AnGSyWJCTVA2jbtvAbYARKNRrVuZZ4Vq19kqxp1BE2P0E9avXz/l4rSZceedd8759dvb2/n4xz/Offfdx0MPPZT7cfqdX2DtwTEAdi3fNK+XUqKvUE1NTYyMjDA6OkokEqG3t5etW7dOHn/7298O8CN3jwKY2ePAne4+ZGZHga1m9mfAOcD5wGDBvwmZRu16QiKRyFj++OOPZyzPdA89wPPPPz+5fdNNN3HTTTcB8N73vjfjhe5SpKGbClVdXU1PTw/Nzc00NDTQ1tZGY2MjnZ2d9Pf3n/Jcd98LfAcYBgaADnfP/FMlBaV2lUzUo69gLS0ttLS0TCnr6urKWNfd16Xtfx74fL5ik7lTu0o69ehFREJOiV5EJOSU6EVEQk6JXkQk5HQxVkTyL3221fmaYbbWsbExrrjiCgBefPFFqqqqmHiwa3BwkAULFpz03KGhIb71rW9x33335S7eIlOiF5HQWbp06eQ8N3fffTeLFy+e8nDUsWPHqK7OnP6i0SjRaDTjsXKloRsRqQg33XQTt9xyC5dccgmf/vSnGRwc5NJLL+Wiiy7iPe95D88++yyQfKDqmmuuAZK/JDZu3Mi6deuoq6sr216+evQiUjFisRhPPPEEVVVV/OpXv+Jf/uVfqK6u5rHHHuMP/uAPePjhh6ed89Of/pSdO3fyyiuvsGrVKj7xiU9w2mmnFSH6uVOiF5GKccMNN1BVlZxi/+WXX2bDhg2MjIxgZrz55psZz7n66qtZuHAhCxcu5KyzzuLnP//55GpT5UJDNyJSMU4//fTJ7T/6oz/i8ssv55lnnuHv/u7veP311zOes3Dhwsntqqoqjh07lvc4c02JXkQq0ssvvzw5s+c3vvGN4gaTZxq6EZH8K8HF6z/96U+zYcMG7rnnHq6++upih5NXSvQiEmp33313xvJLL72Uffv2Te7fc889AKxbt45169ZlPPeZZ57JR4h5p6EbEZGQU6IXEQk5JXoRyQv3ylw5shS/byV6kZAZGBhg1apV1NfXT1kjNcUyM/uxme0xs381s9UAZrbCzI4G5XvM7KtzjWHRokWMjY2VZNLLJ3dnbGyMRYsWFTuUKXQxtoINDAxw++23k0gkuPnmm9m8eXN6lWVm9mMgAbwKbHL3YTNbAfwEeDaot8vdbylY4HJSiUSCjo4OduzYQU1NDU1NTbS2trJ69erUamPu/m6AYFHwPwPWB8eec/c1842jpqaGWCzG4cOH5/tSZWfRokUl90BVVonezNYDfwFUAX/l7t1pxz8J3AwcAw4DG939heDYBuAPg6r3uPs3cxS7zEOpJATJrcHBQerr66mrqwOgvb2dvr6+9HY9nrJ9OpDzbvdpp53GypUrc/2yMkczDt2YWRVwP3AVsBr48MSfein+A4i6+28ADwFfDM59J/BZ4BLgYuCzZrYkd+FXpnt37OPJA2OTX3ORmhAWLFgwmRDS5D0hSG7F43Fqa2sn92tqaojH49PqmVmHmT1H8mf1tpRDK83sP8zsn83sfSd7HzPbZGZDZjZUib32cpPNGP3FwH53P+Du40AvcG1qBXff6e6vBbu7gIm/W5qBHe5+xN1fAnZwokcoRaSEUNnc/X53Pw/4fU78xf0zYLm7XwR8EthqZm87yflb3D3q7tGJed6ldGWT6CPAoZT9WFB2Mh8Dts/xXCkxSgjlJRKJcOjQiR+5WCw2+Zj/SfQC1wG4+xvuPhZsPwU8B1yQt2ClYHJ6MdbMPgpEgd+a5XmbgE0Ay5cvz2VI4RKs0rP24NyGa1LNMSF8BZIJAXgj2H4q6PFfAAzNOzCZl6amJkZGRhgdHSUSidDb28vWrVvTqy1M2b4aGAEws2XAEXdPmFkdcD5woCCBS15l06OPA7Up+zVB2RRm9gHgM0BrkAiyPle9vsJLTQjj4+P09vbS2tqaXu2kCSG4doMSQmmprq6mp6eH5uZmGhoaaGtro7Gxkc7OTvr7+yeqnWVme81sD8m/yDYE5e8Hng7KHwJucfcjhf4eJPey6dHvBs43s5Ukk3Q78JHUCmZ2EfAAsN7df5Fy6PvAH6dcgP0gUHqzG1Wg1ISQSCTYuHHjZEKIRqMTSf8sM9sLvAm8xNSE0GVmb5K8YKuEUEJaWlpoaWmZUtbV1ZW6e8jdp62V5+4PA9NX3pCyN2Oid/djZnYryaRdBTzo7nvNrAsYcvd+4EvAYuBvzQzgoLu3uvsRM/scyV8WAF1KCKVDCUGkMmQ1Ru/ujwKPppV1pmx/4BTnPgg8ONcARURkfvRkbAg8eWCMXceS063ecaVukhCRqTTXjYhIyCnRi4iEnBK9iEjIKdGLiIScEr2ISMgp0YuIhJxurxQpU2sPbklu7FwKl+uBczk59ehFREJOiV5EJOSU6EVEQi68Y/TB3O2Axi9FpKKpRy8iEnJK9CIiIadELxIyAwMDrFq1ivr6erq7uzNVWWZmPzazPWb2r2a2euKAmd1lZvvN7Fkzay5c1JJPSvQVTAkhfBKJBB0dHWzfvp3h4WG2bdvG8PBwerUxd7/Q3dcAXwT+DCBo33agEVgPfHliyUgpb0r0FUoJIZwGBwepr6+nrq6OBQsW0N7eTl9fX3q14ynbpwMebF8L9Lr7G+4+CuwHLs5/1JJvSvQVSgkhnOLxOLW1tZP7NTU1xOPxafXMrMPMniP5C/y2oDgCHEqpFgvKpMwp0VeoQiUEM9tkZkNmNnT48OFchS/z5O73u/t5wO8Dfzjb89Wu5UWJXk5pvgnB3be4e9Tdo8uWLct9gDJFJBLh0KETv4NjsRiRyCk75b3AdcF2HKhNOVYTlE2jdi0vSvQVqlAJQQqrqamJkZERRkdHGR8fp7e3l9bW1vRqC1O2rwZGgu1+oN3MFprZSuB8YDD/UUu+KdFXKCWEcKqurqanp4fm5mYaGhpoa2ujsbGRzs5O+vv7J6qdZWZ7zWwP8ElgA4C77wW+AwwDA0CHuyeK8G1IjoV3CgQ5pdSEkEgk2Lhx42RCiEajE0n/LDPbC7wJvERKQjCziYRwDCWEktLS0kJLS8uUsq6urtTdQ+4ezXSuu38e+Hz+opNiUKKvYEoIIpVBQzciIiGnRC8iEnJK9CIiIadELyISckr0IiIhp0QvIhJySvQiIiGnRC8iEnJK9CIiIadELyISckr0IiIhl1WiN7P1wdqg+81sc4bj7zezfzezY2Z2fdqxRLDm6B4z608/V0RE8mvGSc2CtUDvB64kuZLQbjPrd/fUBUYPAjcBd2Z4iaPBmqMFce+OfQCsPTjGpXVLC/W2IoWx8wtA8vMtkq1sZq+8GNjv7gcAzKyX5Jqhk4ne3Z8Pjh3P9AIiIlI82QzdzHfB4EXB2pK7zOy6TBW0/qSISP4U4mLsucGc5h8B/tzMzkuvoPUnRUTyJ5tEP6/1Qd09Hvx7AHgcuGgW8UkeDQwMsGrVKurr6+nu7s5U5V1mNmxmT5vZP5rZuRMHdJG9dKldJV02iX43cL6ZrTSzBUA7yTVDZ2RmS8xsYbB9JvBeUsb2pXgSiQQdHR1s376d4eFhtm3bxvDwtKZ5DYi6+28ADwFfTDl21N3XBF/TFpuV4lC7SiYzJnp3PwbcCnwf+AnwnWDN0C4zawUwsyYziwE3AA8E64wCNABDZvYjYCfQnXa3jhTJ4OAg9fX11NXVsWDBAtrb2+nr60uv9oq7vxZs7yL515yUMLWrZJLVmrHu/ijwaFpZZ8r2bjJ8WNz9CeDCecYoeRCPx6mtPTEiV1NTww9/+MNTnfIxYHvK/iIzGyK5OHi3uz+S6SQz2wRsAli+fPk8o5aZqF0lEy0OLjMys48CUeC3UorPdfe4mdUB/2RmP3b359LPdfctwBaAaDTqBQlYsqJ2rRyaAqFCRSIRDh06cddsLBYjEpl+16yZfQD4DNDq7m9MlOsie2lSu0omSvQVqqmpiZGREUZHRxkfH6e3t5fW1mnX3t4KPEAyGfxiolAX2UuX2lUyUaKvUNXV1fT09NDc3ExDQwNtbW00NjbS2dlJf//kTVW1wGLgb9Nut9NF9hKldpVMNEZfwVpaWmhpaZlS1tXVlbq7L3jYbQpdZC9taldJpx69iEjIKdGLiIScEr2ISMhpjD5kJubjn3DHlRcUKRIRKRVK9CIiJW7twS2wM1hI6fK7Zn2+hm5EREJOiV5EJOSU6EVEQk6JXkQk5Mr7YuzOL0zdn8NFirBYe3DL5Pau5ZuKGImIlJryTvTAkwfGJrd3Hdt3ipoiIpVJQzciIiGnRC8iEnJK9CIiIadELyIScmV/MVak0j15YGzKjQia30jSqUcvEgJrD26Z/BoYGGDVqlXU19fT3d2dqfq7zGzYzJ42s380s3MnDpjZBjMbCb42FO47kHxSoq9gSgjhkzh+nI6ODrZv387w8DDbtm1jeHjaaoCvAVF3/w3gIeCLAGb2TuCzwCXAxcBnzWxJAcOXPFGiLwP37tjHvTv28eSBsSnPDcxHIpFQQgih4dEXqa+vp66ujgULFtDe3k5fX196tVfc/bVgexdQE2w3Azvc/Yi7vwTsANYXJnLJJyX6CjU4OKiEEEKHX3qV2trayf2amhri8fipTvkYsD3YjgCHUo7FgrJpzGyTmQ2Z2dDhw4fnF7TknRJ9hYrH40oIFc7MPgpEgS/N9lx33+LuUXePLlu2LPfBSU4p0cuMlBDKx7Ilizl06MTv4FgsRiQy/XewmX0A+AzQ6u5vBMVxoDalWk1QJmVOib5CRSIRJYQQalhxNiMjI4yOjjI+Pk5vby+tra3p1d4KPECyTX+RUv594INmtiS45vLBoEzKnBJ9hWpqalJCCKHqqrfQ09NDc3MzDQ0NtLW10djYSGdnJ/39/RPVaoHFwN+a2R4z6wdw9yPA54DdwVdXUCZlLtQPTE3coTLxMIkeJDmhurp6MiEkEgk2btw4mRCi0ehE0q8FjpJMCAAH3b3V3Y+Y2URCACWEktLS0kJLS8uUsq6urtTdfe4ezXSuuz8IPJi/6KQYQpXoU+dkz1ieaXHd1DntQzKf/dT/hz89aT0lBJHScu+OE084rz2Ym1upQUM3IiKhp0QvIhJySvQiIiGnRC8iEnJZJXozW29mz5rZfjPbnOH4+83s383smJldn3ZMk1+JiBTRjInezKqA+4GrgNXAh81sdVq1g8BNwNa0czX5lYhIkWXTo78Y2O/uB9x9HOgFrk2t4O7Pu/vTwPG0czX5lYhIkWWT6LOewGqu52riKxGR/CmJi7Ga+EpEJH+ySfTzmcBKk1+JiBRZNol+N3C+ma00swVAO9A/wzkTNPmViEiRzTjXjbsfM7NbSSboKuBBd99rZl3AkLv3m1kT8D1gCfBfzex/uXujJr8SEcneyebrmq+sJjVz90eBR9PKOlO2d3Nimbn0czX5lYhIEZXExVgREckfJXoRkZAL1Xz085Y6Nz2Eft56EakM6tFXsIGBAVatWkV9fT3d3d2Zqiw+xRxGiWAZusml6KQ0qF0lnXr0FSqRSNDR0cGOHTuoqamhqamJ1tZWVq+eMo3ROMk5jO7M8BJH3X1NAUKVWUgcP652lWmU6CvU4OAg9fX11NXVAdDe3k5fX9+0hODuT5tZ+hxGUmATS8zNtLzc8OiLaleZRkM3FSoej1Nbe+Kh5ZqaGuLxWT20vCiYn2iXmV13skqax6iwDr/0qtpVplGil7k6N1g4/CPAn5vZeZkqaR6jsqN2DSEl+goViUQ4dOjExKKxWIxIJNtJScHd48G/B4DHgYtyHKLMwbIli9WuMo0SfYVqampiZGSE0dFRxsfH6e3tpbW1Natzg7mLFgbbZwLvBYbzGK5kqWHF2WpXmUaJvkJVV1fT09NDc3MzDQ0NtLW10djYSGdnJ/39k3fV/ZqZxYAbgAfMbG9Q3gAMmdmPgJ1At7srIZSA6qq3qF1lmoq96yb9LoZL65YWM5yiaGlpoaWlZUpZV1dX6u5r7p6+bCTu/gRwYX6jk7lSu0o69ehFREJOiV5EJOQqaujmyQPJYZpdx/ad9NiEShzKEZFwUo9eRCTklOhFREKuooZuZuPJA2OTQzx3XHlBkaMREZm78kv06XPGy6lpHn2RiqehGxGRkFOiFxEJufIbuqkQE0/uiojMl3r0IiIhp0QvIhJyGrqRyqE7kKRCqUcvIhJySvQiIiGnoZuQS52s7dLLixiIiBSNevQVbGBggFWrVlFfX093d3emKovN7N/N7JiZXZ96wMw2mNlI8LWhMBFLNtSukk6JvkIlEgk6OjrYvn07w8PDbNu2jeHhaavGjQM3AVtTC83sncBngUuAi4HPmtmSAoQtM0gcP652lWnKcugmfe54mb3BwUHq6+upq6sDoL29nb6+PlavnrLC3Li7P21mx9NObwZ2uPsRADPbAawHthUg9FlJffBs7cGx0K8zMDz6YkW0q8yOevQVKh6PU1tbO7lfU1NDPB7P9vQIcChlPxaUTWNmm8xsyMyGDh8+PNdwJUuHX3pV7SrTlGWPXsqHu28BtgBEo1EvcjiSI2rXGZTYMxvq0VeoSCTCoUMnOm+xWIxIJGPnLZM4UJuyXxOUSZEtW7JY7SrTqEdf4tYe3JKX121qamJkZITR0VEikQi9vb1s3bp15hOTvg/8ccqFug8Cxe+2ZDDr/78S64kBsPMLrD2Y3XWphhVnM9K7K/TtKrOTVY/ezNab2bNmtt/MNmc4vtDMvh0c/6GZrQjKV5jZUTPbE3x9NcfxyxxVV1fT09NDc3MzDQ0NtLW10djYSGdnJ/39/RPVfs3MYsANwANmthcguFj3OWB38NU1cQFPiqu66i1qV5lmxh69mVUB9wNXkrw4s9vM+t099Z6tjwEvuXu9mbUDfwLcGBx7zt3X5DZsyYWWlhZaWlqmlHV1daXuvubuU27XmODuDwIP5i86mSu1q6TLpkd/MbDf3Q+4+zjQC1ybVuda4JvB9kPAFWZmuQtTRETmKptEn80tV5N13P0Y8DIwccPySjP7DzP7ZzN7X6Y30K1aIiL5k++7bn4GLHf3i4BPAlvN7G3pldx9i7tH3T26bNmyPIckIlJZsrnrJptbribqxMysGng7MObuDrwB4O5PmdlzwAXA0HwDF5mLiaeqdx3bxx1XXlDkaCRUUu/YKjHZJPrdwPlmtpJkQm8HPpJWpx/YADwJXA/8k7u7mS0Djrh7wszqgPOBAzmLXiSDKdMeFDEOkVIxY6J392NmdivJe2yrgAfdfa+ZdQFD7t4PfB34azPbDxwh+csA4P1Al5m9CRwHbtHtWiIihZXVA1Pu/ijwaFpZZ8r26yTvyU0/72Hg4XnGKCIi86AnY7Nw7459U55M1AIeBTbD06qpQzVFcbL4SvEpW6lImutGRCTk1KMXkVBL/4uv0HdbFfv9QT16EZHQU49eRMrDbK55pNSdNvPnzqXZvUaJSX0GBGb3l4ESvcg8pS5tqQexpBQp0Z9CvuaCFxEpJCV6qVilcJFMpBCU6EUkVNKfexEl+oo2MDDA7bffTiKR4Oabb2bz5kyLh9m3gd8ExoAb3f35YAWxnwDPBvV2ufstBQl65xdOXJRavmmyeLbDbBnrT1ykS3mvSWV04a4s2zVkUq/bsLx4cUxQoi8RhX66M5FI0NHRwY4dO6ipqaGpqYnW1lZWr56y8NCZwG6tHFY+EsePq11lGt1HX6EGBwepr6+nrq6OBQsW0N7eTl9fX3q1d6CVw8rK8OiLaleZRom+QsXjcWprTywzUFNTQzyevswAC5jHymFSeIdferUg7apV4cqLhm5kLiZWDhszs98EHjGzRnf/VXpFM9sEbAJYvrwEBivn6FRDayGa8z7rdnX3LcAWgGg06gWOc14mx88P3MmldUtPXjFH12WmXQ/aubTg13yU6CtUJBLh0KETSwHHYjEikfSlgBlnniuHlXNCKEfLlizmB0/lv11LTdFnMC1xGrqpUE1NTYyMjDA6Osr4+Di9vb20tramV/slyZXDIG3lMDOrAtDKYaWlYcXZaleZRj36ClVdXU1PTw/Nzc0kEgk2btxIY2MjnZ2dRKPRieTwn8BSrRxWPqqr3qJ2nYUpt0HCqYdyylhZJPopa4DqQYicaWlpoaWlZUpZV1dX6q67e8WsHJb6Q1/OP/BqV0lXFolepJxMdEzWHhwr618YEh5K9FK2CjnpXOp7pT6RK1IOlOhFpOyU8102Tx4Ym9Oc8vOhRC8iZUtTiWenIhN9Tj8cqRNfQfYPQpxkwqy8fnDnGmsFSr8bQyrDlAvyl2d/XqnPmFmRib5STbuVbBYf5GJT4pVCC9N6BXpgSkQk5NSjn4PU3/R36H9QSkyYeqKSG+rRi4iEnBK9iEjIaeBBZJZOdWfUSY+V6bKExTRtCKrEslUu7uVPf418TXldYv91IuEyn0mzUqdSqCjBL8W1B8dO+hRyoe+fX3twy4k1hXNwO3Sh41eiFymg1KciQRdKZ6PYt9hOLkp/rPyeytUYvYhIyCnRi4iEnIZuiqjYfwpOeR5AQwgioaVELyIlo9TnjClXWSV6M1sP/AVQBfyVu3enHV8IfAv4TWAMuNHdnw+O3QV8DEgAt7n793MWvczLT3b/gEe+8nmOHz/OG7/3CTZv3pxexczs2xSoXU92u1qYf/Dz8VdVaruuXX8Dd1z5p+lVCtquUnwzJvpgseD7gSuBGLDbzPrdfTil2seAl9y93szagT8BbjSz1STXo2wEzgEeM7ML3D2R62+kHJTSkoiJ48f5bk8Xt3T/H95+5rv4m7t+l9bWVlavXp1a7Uxgd77atZznFC9V6e167+9dz/DwxoK262zoM1AY2fToLwb2u/sBADPrBa4FUhP9tcDdwfZDQI+ZWVDe6+5vAKPBYsQXA0/mJnyZq+HRFznznHNZ+uu1ALS3t9PX15eeEN4BfDPYVruWgfR2vei3ri54u54qeetaUHGYu5+6gtn1wHp3vznY/+/AJe5+a0qdZ4I6sWD/OeASksl/l7v/TVD+dWC7uz+U9h6bgIknI1YBz87z+zqT5Er3hVZO77sEeBvwQrD/TmAxcDClzhpgxVzbNTiW67bNVjHaohTes1zbtVg/O7lQKrGf6+7LMh0oiYux7r4FyNmjYmY25O7RXL1eGN93Fr/A5yXXbZutYrRFKbxnubZrsX52cqEcYs/mPvo4UJuyXxOUZaxjZtXA20le5MnmXCkOtWs4qV1lmmwS/W7gfDNbaWYLSF6s6U+r0w9sCLavB/7Jk2NC/UC7mS00s5XA+cBgbkKXeVK7hpPaVaaZcejG3Y+Z2a3A90neXvmgu+81sy5gyN37ga8Dfx1cvDlC8sNFUO87JC/cHgM6CnTHTbFWDC6b9y3Tdp2NYrRF0d+zjNu1nFf5LvnYZ7wYKyIi5U1z3YiIhJwSvYhIyIUy0ZvZ3WYWN7M9wVdLnt9vvZk9a2b7zWzaPAJ5fu/nzezHwfc5VMj3LmWF/AwUq/3Lve3N7AYz22tmx80smnbsruD/81kzay5WjKdSzJ/72SqJ++jz5F53nzbJR65lOUVEvl3u7qXwwEapyftnoATav5zb/hngQ8ADqYXlMHVKCbT7rISyR19gk1NEuPs4MDFFhFQGtf8cuftP3D3TE7WTUzG4+ygwMRVDKSmrdg9zor/VzJ42swfNbEke3ycCHErZjwVlheLAP5jZU8Fj6XJCIT4DxWz/sLZ9sX+mslEOMU4q26EbM3sMODvDoc8AXwE+R/IH4XPA/wY2Fi66grrM3eNmdhaww8x+6u4/KHZQhaDPQOm3/anayN37Ch1PpSrbRO/uH8imnpl9Dfi/eQylqI+Nu3s8+PcXZvY9kn9SltQPe76UyGegaO1fDm2fbRulKYepGMohxkmhHLoxs19P2f0dkhd98iWbR87zwsxON7MzJraBD5Lf77VsFPAzUJT2D3nbl8NUDEX7uZ+Lsu3Rz+CLZraG5J/tzwP/I19vdLJHzvP1fmneBXzPzCDZllvdfaBA713qCvIZKGL7l33bm9nvAH8JLAP+3sz2uHtzOUyxUeSf+1nTFAgiIiEXyqEbERE5QYleRCTklOhFREJOiV5EJOSU6EVEQk6JXkQk5JToRURC7v8DbC3j42b9kZ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hand-written EM baseline for GMM: estimate cluster\n",
    "# association weights, and then apply a closed form update\n",
    "# to get new best cluster mean and vars. (Like a \"soft\"\n",
    "# k-mean.)\n",
    "    \n",
    "# Initialize param guesses from pre-fit grammar\n",
    "weights_init = pre_fit_grammar.params_by_node_type[\"Root\"]().detach()\n",
    "means_init = []\n",
    "vars_init = []\n",
    "for rule_params in pre_fit_grammar.rule_params_by_node_type[\"Root\"]:\n",
    "    mean = rule_params[0][\"mean\"]().detach()\n",
    "    var = rule_params[0][\"variance\"]().detach()\n",
    "    means_init.append(mean)\n",
    "    vars_init.append(var)\n",
    "means_init = np.stack(means_init)\n",
    "vars_init = np.stack(vars_init)\n",
    "print(weights_init, means_init, vars_init)\n",
    "\n",
    "gmm = GaussianMixture(\n",
    "    n_components=3,\n",
    "    covariance_type=\"diag\",\n",
    "    weights_init=pre_fit_grammar.params_by_node_type[\"Root\"]().detach(),\n",
    "    means_init=means_init,\n",
    "    precisions_init=1./vars_init\n",
    ")\n",
    "\n",
    "X = points = torch.stack([sample[1][0].translation for sample in samples])\n",
    "gmm.fit(X)\n",
    "\n",
    "# Make an EM-fit grammar with those params\n",
    "em_fit_grammar = deepcopy(pre_fit_grammar)\n",
    "rule_probs_param = em_fit_grammar.params_by_node_type[Root.__name__]\n",
    "rule_probs_param.set(torch.tensor(gmm.weights_))\n",
    "print(\"EM fit rule probs: \", rule_probs_param())\n",
    "for k, rule_params in enumerate(em_fit_grammar.rule_params_by_node_type[\"Root\"]):\n",
    "    mean_param = rule_params[0][\"mean\"]\n",
    "    var_param = rule_params[0][\"variance\"]\n",
    "    mean_param.set(torch.tensor(gmm.means_[k, :]))\n",
    "    var_param.set(torch.tensor(1./gmm.precisions_[k, :]))\n",
    "    print(\"EM-fit Mode %d: %s +/- %s\" % (k, mean_param(), var_param()))\n",
    "    \n",
    "# Draw its empirical fit\n",
    "gt_samples = get_draws_from_grammar(gt_grammar, 1000)\n",
    "em_fit_samples = get_draws_from_grammar(em_fit_grammar, 1000)\n",
    "l_gt = get_all_node_xyzs([sample[0] for sample in gt_samples], Point)\n",
    "l_em_fit = get_all_node_xyzs([sample[0] for sample in em_fit_samples], Point)\n",
    "l_train = get_all_node_xyzs([sample[0] for sample in samples], Point)\n",
    "for k, label in enumerate(\"xyz\"):\n",
    "    plt.subplot(1, 3, k+1)\n",
    "    #plt.hist(l_gt[:, k], bins=100, label=\"GT\", alpha=0.5, density=True)\n",
    "    plt.hist(l_em_fit[:, k], bins=25, label=\"EM fit\", alpha=0.5, density=True)\n",
    "    plt.hist(l_train[:, k], bins=25, label=\"Train\", alpha=0.5, density=True)\n",
    "    plt.title(label)\n",
    "    if k == 2:\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot parsing with MAP point latent estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6b2e0861dc490e9db6d651a94dd4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EM Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7c9c208b1b40e3a7eae13857ceecab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da748fcc9f3a4858967e4e78d776dfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2eeb3275d6433d804b6b26cccedde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b2338438004bccae004b425bb0584b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c8bb0f2f93415c9e26b1d37c2b33b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee58fd04895d4de7ab6961f0d0b2976c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3d435ff55b432e91b2372b5d9810f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb83df141dd4a678515b08efb16b8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba339f603b94af0818b5de0c77f044a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcbc63159944aed871feb6d9c6f7901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do single-shot fitting of grammar params based on just the optimal parses\n",
    "one_shot_fit_grammar = deepcopy(pre_fit_grammar)\n",
    "em = EMWrapper(one_shot_fit_grammar, [sample[1] for sample in samples],\n",
    "               parsing_strategy=\"ip_noproposals\", do_nlp_refinement=False\n",
    ")\n",
    "em.do_iterated_em_fitting(em_iterations=10, tqdm=tqdm, N_solutions=3, num_workers=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final params:  tensor([0.1999, 0.3301, 0.4700])\n",
      "mean tensor([[-0.6332, -0.1633,  1.5277],\n",
      "        [-2.2261, -0.3763,  1.7992],\n",
      "        [-2.3253, -0.5585,  1.6169],\n",
      "        [-2.2879, -0.6882,  1.6340],\n",
      "        [-2.2438, -0.6126,  1.7560],\n",
      "        [-2.2439, -0.6126,  1.7560],\n",
      "        [-2.2439, -0.6126,  1.7560],\n",
      "        [-2.2439, -0.6126,  1.7560],\n",
      "        [-2.2439, -0.6126,  1.7560],\n",
      "        [-2.2439, -0.6126,  1.7560],\n",
      "        [-2.2439, -0.6126,  1.7560]])\n",
      "0:xyz:mean final: tensor([-2.2439, -0.6126,  1.7560])\n",
      "variance tensor([[4.6226, 0.8209, 6.8300],\n",
      "        [0.6847, 1.1285, 1.5196],\n",
      "        [0.4811, 1.2508, 0.8837],\n",
      "        [0.7866, 1.4193, 0.9127],\n",
      "        [0.8142, 1.5000, 1.1621],\n",
      "        [0.8142, 1.5000, 1.1622],\n",
      "        [0.8142, 1.5000, 1.1622],\n",
      "        [0.8142, 1.5000, 1.1622],\n",
      "        [0.8142, 1.5000, 1.1622],\n",
      "        [0.8142, 1.5000, 1.1622],\n",
      "        [0.8142, 1.5000, 1.1622]])\n",
      "0:xyz:variance final: tensor([0.8142, 1.5000, 1.1622])\n",
      "mean tensor([[-1.3265, -1.2413, -0.1028],\n",
      "        [-4.3494, -3.4524, -3.5955],\n",
      "        [-4.8704, -4.6499, -4.5666],\n",
      "        [-4.9025, -4.7112, -4.6874],\n",
      "        [-4.9046, -4.7184, -4.7042],\n",
      "        [-4.9046, -4.7184, -4.7043],\n",
      "        [-4.9046, -4.7184, -4.7043],\n",
      "        [-4.9046, -4.7184, -4.7043],\n",
      "        [-4.9046, -4.7184, -4.7043],\n",
      "        [-4.9046, -4.7184, -4.7043],\n",
      "        [-4.9046, -4.7184, -4.7043]])\n",
      "1:xyz:mean final: tensor([-4.9046, -4.7184, -4.7043])\n",
      "variance tensor([[ 9.4140,  1.9705,  7.5793],\n",
      "        [ 1.9697,  2.1412, 10.0000],\n",
      "        [ 0.7814,  2.0017,  5.2307],\n",
      "        [ 0.7268,  1.8387,  4.5274],\n",
      "        [ 0.7268,  1.8226,  4.4290],\n",
      "        [ 0.7268,  1.8225,  4.4287],\n",
      "        [ 0.7268,  1.8225,  4.4287],\n",
      "        [ 0.7268,  1.8225,  4.4287],\n",
      "        [ 0.7268,  1.8225,  4.4287],\n",
      "        [ 0.7268,  1.8225,  4.4287],\n",
      "        [ 0.7268,  1.8225,  4.4287]])\n",
      "1:xyz:variance final: tensor([0.7268, 1.8225, 4.4287])\n",
      "mean tensor([[-0.9498,  1.2456,  1.0833],\n",
      "        [ 1.6175,  1.7462,  2.2144],\n",
      "        [ 4.0882,  4.2812,  4.6479],\n",
      "        [ 4.8573,  4.9266,  5.0317],\n",
      "        [ 4.9814,  5.0070,  5.0496],\n",
      "        [ 4.9814,  5.0070,  5.0496],\n",
      "        [ 4.9814,  5.0070,  5.0496],\n",
      "        [ 4.9814,  5.0070,  5.0496],\n",
      "        [ 4.9814,  5.0070,  5.0496],\n",
      "        [ 4.9814,  5.0070,  5.0496],\n",
      "        [ 4.9814,  5.0070,  5.0496]])\n",
      "2:xyz:mean final: tensor([4.9814, 5.0070, 5.0496])\n",
      "variance tensor([[ 7.0676,  7.9453,  6.9533],\n",
      "        [10.0000, 10.0000, 10.0000],\n",
      "        [ 6.4918,  4.1091,  1.5727],\n",
      "        [ 1.7074,  0.5526,  0.1957],\n",
      "        [ 0.9730,  0.2343,  0.1815],\n",
      "        [ 0.9730,  0.2343,  0.1815],\n",
      "        [ 0.9730,  0.2343,  0.1815],\n",
      "        [ 0.9730,  0.2343,  0.1815],\n",
      "        [ 0.9730,  0.2343,  0.1815],\n",
      "        [ 0.9730,  0.2343,  0.1815],\n",
      "        [ 0.9730,  0.2343,  0.1815]])\n",
      "2:xyz:variance final: tensor([0.9730, 0.2343, 0.1815])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "em.plot_grammar_parameter_history(Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc606562c4594fd4a4458047515f19b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'one_shot_fit_grammar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a6b7e2fefc07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Randomly initialized model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mone_shot_fit_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mmake_figure_for_grammar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_shot_fit_grammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_shot_fit_grammar' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "gt_samples = get_draws_from_grammar(gt_grammar, 1000)\n",
    "def make_figure_for_grammar(one_shot_fit_grammar, axs, N=1000):\n",
    "    rule_probs_param = one_shot_fit_grammar.params_by_node_type[Root.__name__]\n",
    "    print(\"One shot fit rule probs: \", rule_probs_param())\n",
    "    modes = []\n",
    "    for k, rule_params in enumerate(one_shot_fit_grammar.rule_params_by_node_type[\"Root\"]):\n",
    "        mean_param = rule_params[0][\"mean\"]\n",
    "        var_param = rule_params[0][\"variance\"]\n",
    "        modes.append((mean_param(), var_param()))\n",
    "        print(\"One shot-fit Mode %d: %s +/- %s\" % (k, mean_param(), var_param()))\n",
    "\n",
    "    #fit_samples = get_draws_from_grammar(one_shot_fit_grammar, N)\n",
    "    l_gt = get_all_node_xyzs([sample[0] for sample in gt_samples], Point)\n",
    "    #l_fit = get_all_node_xyzs([sample[0] for sample in fit_samples], Point)\n",
    "    l_train = get_all_node_xyzs([sample[0] for sample in samples], Point)\n",
    "    xs = np.linspace(-8, 8, 1000)\n",
    "    for k, label in enumerate(\"xyz\"):\n",
    "        ax = axs[k]\n",
    "        ax.hist(l_train[:, k], bins=50, label=\"Training data\", alpha=0.5, density=True)\n",
    "        #ax.hist(l_gt[:, k], bins=50, label=\"Test data\", alpha=0.5, density=True)\n",
    "        #plt.hist(l_fit[:, k], bins=50, label=\"One-shot fit\", alpha=0.5, density=True)\n",
    "        # Plot the mode density\n",
    "        for mode_k, (prob, mode) in enumerate(zip(rule_probs_param().detach().numpy(), modes)):\n",
    "            mode = torch.exp(dist.Normal(mode[0][k], mode[1][k]).log_prob(torch.tensor(xs))).detach().numpy() * prob\n",
    "            ax.plot(xs, mode, label=\"Mode %d\" % mode_k)\n",
    "        ax.set_title(label)\n",
    "        if k == 2:\n",
    "            plt.legend()\n",
    "            \n",
    "fig, axs = plt.subplots(1, 3)\n",
    "fig.set_size_inches(12, 6)\n",
    "plt.suptitle(\"Randomly initialized model\")\n",
    "\n",
    "one_shot_fit_grammar.load_state_dict(em.grammar_iters[1])\n",
    "make_figure_for_grammar(one_shot_fit_grammar, axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One shot fit rule probs:  tensor([0.2995, 0.1439, 0.5566], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-0.6332, -0.1633,  1.5277], requires_grad=True) +/- tensor([4.6226, 0.8209, 6.8300], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-1.3265, -1.2413, -0.1028], requires_grad=True) +/- tensor([9.4140, 1.9705, 7.5793], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-0.9498,  1.2456,  1.0833], requires_grad=True) +/- tensor([7.0676, 7.9453, 6.9533], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.2995, 0.1439, 0.5566], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-0.6332, -0.1633,  1.5277], requires_grad=True) +/- tensor([4.6226, 0.8209, 6.8300], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-1.3265, -1.2413, -0.1028], requires_grad=True) +/- tensor([9.4140, 1.9705, 7.5793], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-0.9498,  1.2456,  1.0833], requires_grad=True) +/- tensor([7.0676, 7.9453, 6.9533], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.0798, 0.1738, 0.7464], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2261, -0.3763,  1.7992], requires_grad=True) +/- tensor([0.6847, 1.1285, 1.5196], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.3494, -3.4524, -3.5955], requires_grad=True) +/- tensor([ 1.9697,  2.1412, 10.0000], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([1.6175, 1.7462, 2.2144], requires_grad=True) +/- tensor([10.0000, 10.0000, 10.0000], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1254, 0.3360, 0.5386], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.3253, -0.5585,  1.6169], requires_grad=True) +/- tensor([0.4811, 1.2508, 0.8837], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.8704, -4.6499, -4.5666], requires_grad=True) +/- tensor([0.7814, 2.0017, 5.2307], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.0882, 4.2812, 4.6479], requires_grad=True) +/- tensor([6.4918, 4.1091, 1.5727], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1895, 0.3309, 0.4796], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2879, -0.6882,  1.6340], requires_grad=True) +/- tensor([0.7866, 1.4193, 0.9127], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9025, -4.7112, -4.6874], requires_grad=True) +/- tensor([0.7268, 1.8387, 4.5274], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.8573, 4.9266, 5.0317], requires_grad=True) +/- tensor([1.7074, 0.5526, 0.1957], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2438, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1621], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7042], requires_grad=True) +/- tensor([0.7268, 1.8226, 4.4290], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2439, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1622], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7043], requires_grad=True) +/- tensor([0.7268, 1.8225, 4.4287], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2439, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1622], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7043], requires_grad=True) +/- tensor([0.7268, 1.8225, 4.4287], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2439, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1622], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7043], requires_grad=True) +/- tensor([0.7268, 1.8225, 4.4287], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2439, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1622], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7043], requires_grad=True) +/- tensor([0.7268, 1.8225, 4.4287], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2439, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1622], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7043], requires_grad=True) +/- tensor([0.7268, 1.8225, 4.4287], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.1999, 0.3301, 0.4700], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-2.2439, -0.6126,  1.7560], requires_grad=True) +/- tensor([0.8142, 1.5000, 1.1622], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([-4.9046, -4.7184, -4.7043], requires_grad=True) +/- tensor([0.7268, 1.8225, 4.4287], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([4.9814, 5.0070, 5.0496], requires_grad=True) +/- tensor([0.9730, 0.2343, 0.1815], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1296\" height=\"432\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAC3VG1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MTMgbG9v\n",
       "a2FoZWFkX3RocmVhZHM9MiBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxh\n",
       "Y2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHly\n",
       "YW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3\n",
       "ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAEpZZYiE\n",
       "ABb//vfTP8yy6/c5teOo96KeJl9DdSUBm5bE7TqAAAADAAADABLN/5saZW/iAGnsSlfydLjGxx9o\n",
       "4mId8vL/iB+Hn6fP0rh8Z9gM1bTx0Q5E67dJdeBkOEWFeiLJYdODw3gmXwVtF34nLL1SRNJOk5ZX\n",
       "MK0J6Vju+C4rREU+93uQgsUBG122dT5OXRfYGS2oy90DY8YQcv5sixJVMkgbk/0m2+hPk/HS8jfX\n",
       "1kEA4pOWIw8V4jxR0A2mjXVSAhSaXQOHCy6o93SpBNsmm0I24PlDkso5TsiqxapUAyK5MsNg1mvq\n",
       "2rY1eF6Be1GRlhQcrJU4tULKEBjMOSbRpxH/EuYgCPS/WCJtGTtX8Sa/JLNqmPYIgx4/NtkxoKXJ\n",
       "44lWUyO4d0+0GWKArZ9W6QtkXbdnkwwT8IZRyiu/zij2fU5XqDNju9fdoqvl4qVg6Csla4p4oOZA\n",
       "dYNO47fzy+CniePTIiChNrpkRQobM+GWpVqm0qWcdLlMTkP15aAUB8Jzwr2eyZpkQNYvc8IC5rON\n",
       "7/NGYl1PNEdL1583lHoeiKiCJI2+UPbzBFtDpCUW/IqK05ACK4h2Wv4uvwQ9np0IOoJLtvFf5PzU\n",
       "Zu1RWGaoVNIufO8Ej7rPUHYYxC2IOCT4VJmZhUP8+EVA4N1THj9VT4o8mKcvmylfc4dHCLZbO8m3\n",
       "s2QKxSGDv6YdadKOYhU3S1ijx1kIx7gOPOpZt04yz3XxhLUfUri9DG6Sth8s/m4X/j/8A1VYGf02\n",
       "1BGQXzVG5lQ+GbAEEqk1nE+25+JrtqLK6GW5rmVHA/kXfHP98W0ZH8GWvPgDwyXPiMaA+Mu+ARi0\n",
       "1mDDwksBCODyPd8XdFZqJKs87Z2CRoPmbavzOV8oWK+FhCcc1O//ASSwf76wwGChQBVmWPTy4Vlf\n",
       "Z0ek4OBVwsk1epZU3g7+6joug8X3jfzJ3V7gJaIeuItBAPAFOv/9EJ/PCsoEz0thyLdZduwvY5y8\n",
       "ADM/ai65GNI/wAAAF8XpPvUf/Dh/oPAAAKqINLdv/D3wkV8csDi56jErrDUrID/gCW8LTIpiM1m4\n",
       "dRtyoLN1iCniJlbQC47+D1X3352NQclv9mTCB+j9foI3vgKq8ad4BvJcs2NgCP1uZ5ib4G/MD0p1\n",
       "iQPLZRpTPdakxsr/75XFG44KaRpxnvHeQkLaRL9L9s9/giU9+R3FYJChigB1uvQIq1WEFODUZ8Jk\n",
       "14cwj40grJqovULZzBA0bi+exzhG846H9QggyIr/50jSB2IN1l8XY3HxhBB/0a2Qq3QJQSkDVUIq\n",
       "gUv8zWW/d/y4SR8Uz+mnR3EbLHO2v6C78/PJEhLWWq9lXLjKD+yAjWZBfEBRJV4ug7briOTJk9S+\n",
       "fWbm/mEFG2b5z0jKuY0CL0JqFf9YYtcvaVrtOxEGQEzKj5JZdIQioBc04YbY1rusS3DTNWFJ5zEd\n",
       "ciL0uWG9LhZXeQ0UtzDlWlOQ8gtlPjXNmHwIimvIdW5WBFS7EbRS49Fv7OHvSBhjjK5f1wgBpcu7\n",
       "3S3FXXqoFjoxLWxNncXe5b0vjXVWDagPlmW8liCegSHpUBgXbAxXZVyZP/Si5yp0WDbYdY10HWjH\n",
       "AAeUFmeLPsG6D2IF8ONnYIiO/QIDq7oeALkToV2GWHUUtqc06Vk3PLrCJwceL1++IFmIWO6OxIuf\n",
       "AMbyv8KB1lZFaf3mNhusFwdo9DDgAAyUUA2uBX2EBciZpBP2SHgxLgK0D2oceB8gqpTBmrW2hook\n",
       "ac4LfLr4A4vBdHDsSABvR3KoGYWF6bg+a/8FNGMcwVCejYxLpnnQ6g+dx/QxY6xUyjrU/PMcuecd\n",
       "5SOZUURg6SwjnLIZb2rZiaUwUue1i3rnj/C7kaX9MC7AkT4QlRGwDksqmDYPNSr29aC0kKqJgVHr\n",
       "lK6iyYiDiZjpRl03vtLEjmsEqQPLCYRM5bI7N5/44G0rdtOOqfOfXu9QO9LKTYpBR9Hf7SqEYbkF\n",
       "Pi/8P0ef9Ie6aMPjcoG8/OU+Vq+jsRecJ/t/PVOh1p7uxHgbFO+AHhdK80frVt5UdaVfGSnU58zP\n",
       "HUuvyB1BFFuQxr21PY9j5fpTJDU6M7YdEsgS1jdbNQCIT55g9mRUqEEwPDoJhwA/zUtmZvZGeVr+\n",
       "TBxxUAAHw5C9ZwAs0nBgqWWYh7XoMjmyX7QQ8wSSHvcg3TYu38lWmN3BKy+k/VuLM3p3M3jxpXMM\n",
       "DPnXfjJvIdVMK0xotqmBNvFqAfV4RnyXY60KpxuXaZgKjpDqHhk1Kn0+UDxviG9K7NbF/mbolCZr\n",
       "XmFsdn/qfwj4hMqzhJ2ajC/4RJ6EgrziAUgzMd+ZRS2jb8oziaZZiRG8qQmOv4WXtFI/Z8W6ekFH\n",
       "FiXcLrIUHEEN7CaDSbtkMAZHJX7bgTfBOdUKB94psgZRtHcZ/u1cN1pbca+2YXs2mNissGTw751f\n",
       "Q907pZ76jWPgluBqAWBmbwsLlzfqgTssq8+WRHyp8NMTZNRndjoJ1lBO58MIteFeNghLSCC/0v/3\n",
       "3P1X6UdlgNajB9QIPy4RrBbsyIzie59jjC/gUkrxIlGqCHeHCc6c/c9zvO3RtrOBrVH5mlyZM8fP\n",
       "PFwTEsrnaMrCLBfpqYwzES7IEkIXhbbXxXY6BCov2h/l+G3AKHiDQoyJj5kYdpoUV30qDGy0uSHE\n",
       "RImC2XzQ4yiXu/KT0HsEHbBKfiBbQpcv9XKskpL3Ax7/MlliUtacZBr4wz3OokoD+GN3Llwrwqg0\n",
       "Ad3/XtBp6pJ7+lazdCXFmt89q+uR2eh1RA9GIfYskNzI5Gej0ncxFFQ4YPb8rwGxQH9NCu+QFF5S\n",
       "aXBmIM1w4O8+gVLzFwmlU9khxnsy0MUqE1e1BVS8x2QBWvvR8njVxpaBYyL6TwU4qnHwDToA7Bmg\n",
       "fKLPz2wznHN1CRy6kktDFHCeMLgqyPiLSzsVjvKPtM4MLwZqGt4Srh9zdktLO0N6bpNNjk6gCE1F\n",
       "vpci1KJ+zjDOHhkQMXF3mhwIk4EKlhOrkAAAK7k6ebh5lw2AC2MfQ5AiPxJuIdUrChsQ7o/meSkB\n",
       "/8M2P8IM/b30Lv//WL7wCoFshwST6K0mhuJLlrvKnodGCwyEOiMnmakjNIcF3kURF+M02H29G7Hc\n",
       "EHdNFji4mkGfHFdTUUrwplRhytHJlWwp4CXsURpC+xHfeZf7W7v8LPNDXf6GQ5l6M9ZhETmQVpFx\n",
       "Un3D2BLShrdilUIjjkdAaMvBo+UJShgZKBeLwFYqlchTmy9DJLIY7CrcaySTGgmEyn/SQhyHCV5z\n",
       "CTCUBqI4RMAI0zdmdWYV2n0Je9eJM4HanQ7W2IJrajeopysBklmRmxm4DbNsFLCwH5+mWpt2bU9h\n",
       "fkUhXAJKZjgu4gJcb4krhzOIs2cKp2dQC9YkBqc3TbLfbO8JUpstonTFlfVP2Fzy6xbHNob888+U\n",
       "do80kKJpca77ng8HrRISEO8CB74As6PdpW/ry2GDs3CAkuKQGbHVyE+gcce3LLh1jEShK1+Y7nDg\n",
       "oCpYcl7xJqiMM9R3husgcETIpcYBK/KjLpb/VNytNHZdQFnvYQnQML04TTVkxqFuuJna2ekOgCqN\n",
       "6jK/cGpE1p3Oqo8QONNiG7eO9siDZ6dVPm7mj6hndEaneQC/4hSQIKWf6smRHyXf3DkbiIECjAhI\n",
       "zaTxc5JSxtxErxD1P1mZziVz1MGPpY4kMlVnVFUsRu/w/t4MfzdfGjCG3zZAxSQFV6lvh/16ANXc\n",
       "O6P2+nc7444iReLQlUQOYXnfY+X0m7+yU24QZmLAQSMEGcdDaMSdrl56zls+xYajBCFpFwRoM8cB\n",
       "CJ36jGnVkjny/CJG980rb/0zLAom/jy0nK5JQqR4f/xgBNISsakKpV9QWxBGa6UHthfGRs8LZQ4A\n",
       "gHGjxD+rd58xAgrb3H2Jhr4f04XI5QPKquqgYL9OfjH2CA50936vESgdEV7fptevbsMoVCpyyLt9\n",
       "061nAS8z8FOAgm1ddGC93M7vZR1fKlhlCNf5YIf4xRWEiPmqD6Bu91Hi2htySWtA/DmaJAMJKsuL\n",
       "LwUWSJdLBZJ0QCXJKfxABZW1R5NTleFvRB54eFMalF+eRZqiWq+LPgC+3uCbTUtDJz3lXRaSrK9O\n",
       "ICsZLlxQR40MtT+D2Ili/DC9C3JdZfV0vY2tt4BNh9G4z6IsvO308/Ov0G73ea2XEKRlux1uM1iM\n",
       "3mRDWPDBJR4bk8IIMYojhytVj+66wPAUilbyfwe7UuFrCld9SdFnGvCJHBY2O9ReTO1f6u7DbN69\n",
       "N7z7JDw0+HdMcIDBYbaX/wxxzexcQKZ0GJDXVUSubCFLtgf8/kFOsAnuO9ZsFp+wGc0Ep1NWeMbu\n",
       "P8K3rlZbSEc9rrumIIHd5tDIMedwSm+F4kP0ONtDfkSzFTOb9vmYPNu56NRmMU7/bueN9ppiY5Eq\n",
       "OKsR2+OCyjof8aJ7DJNtw1gGeiqxnDNu2VxZB07rOIIUnwmtcTr0QsSJV162GYmehjmdH+/YV1XC\n",
       "CjpK8N9rx7D5YZRYWcM6oVWCYRwsb0HG+cfw5xwpDHX2MNKLvw/alA99qGTU7Zmh+VskqPwGTqfc\n",
       "op6UAJFKviVsoJnmbdfFv279mnaKkBhqYq6UqjfKWegJHu6tjiBA5hbBxy5qZBYzqx/vgCEIL7T5\n",
       "eA9rSEp8KhtSNep2Xb9AKp5pc68ar4eqB6/vIf7IiCfeoKpwH2se0KmKj80NG76Takc05ilBiI4Y\n",
       "w4BVHe7Y1SEyi+Gc0My1E1420HMeqA82qpdXIXWkDOKc5ikY8V//IpN0euv28vbJCWmTU72UwqEM\n",
       "4DOZfeAVF2LTHXZYn1CKbNgwGBDAG3FaxY/O3FsL0exuhe6ndhVn+EreO9UUIJ/ub5g3Dg2jrmdG\n",
       "g/bSJURFrZ2g+vKrT7h4oAwreiRFynV3hKRevBCXARkcT/86VKUDwxRUy0ppnmTs2Z1+MHmt98Rd\n",
       "GLXebHn1TvZCcaCtLtNFfZo774sjJsWk3M9WQ+kzj4ysaHkzRKb1V1f7kndKyW+iYIN37p+glDyM\n",
       "v2ISnFcCWFN6gCQScUG3PH7jk1nENNII9xUIMi+Ug0W3SZGqfgqe1PmjnvJ6zegUWkUnqIYG08Eq\n",
       "SSsZ7CC0dF3J6oUPcADXbmMxO3uxXAuO4AtMASsqOFl6oAQqVCiv3lvFNsZxr7hi/GxPFoYyiwLa\n",
       "cJ41TdRWdAUeIvwgoafxj+od+K+8P++79Dut3z2YPwE82Mlm7Nsbe0l/QoZxBTh76sSSKjbEzrHl\n",
       "fyZ187w+Igc7Q8D7pmFRoWjUMmwcjEX3udXQiatG4FyPyuE+PQYzoYqhdDhf2SpxAMKdM9dw7IiC\n",
       "TI1j2RMpF5VX+VPx3v5hf/8di+BedwymZjNES8vIUGD2QlWR+Qshtogs6mF9WSz/Oh0ruVAOmY1a\n",
       "zflB9yKkFlgwm5IfXPWkFZ3//mPAWoZ5a9BEXb8n77S6aBJKXFICodR9A6fFcFwilz+klhDMOXfj\n",
       "UxjlUJYGususqPP08mxP8j/BIxxFov3igBoYJC8PJyG9NMvn7GoaYtFFIedLot2uUJp3ueollTy9\n",
       "KoRGy2854HiztLnxNSO+Oc0fuyndLbwU1cpj5YVIBml+TOhHRJ/kFcMMpKcX82JQncwGKw8waA+Z\n",
       "Bdm1wHh9p4OxxO0D5P/E+ojD/MrMvtOrUMmsBEiyl36K85xMKXJGuWmbKz4APkpgkvAfpfwY8lnZ\n",
       "qz/JgERjo4ZgQNVUJJUIiSP4s0lD9XomkUTzHkUuBCjtv8AnepLWy0Uj20mHaXsaf8ab2XBcShaZ\n",
       "N25tyYVmqEgQea3sOQEinT6xqtKppB9qkNKDG5lB69DBG+CfYy+sBdiJVDKpHgDPLc3FrmXEyncN\n",
       "D3zOHfHZcazS8B9skrHVqhRY70QT7uTKpF+PbF8d3SrTj591DW7p3L3z7WL2AmNd5gsEdNCFbtHu\n",
       "djKSsJOW5nsvQXPUzSHzanMhEO6rlrsWJIYwQGSRbNqrWFT661RLXkDes+LDC8tjAJCxQQeL166R\n",
       "Bb0VQxdWQJhlttkZLjD/WVFS75ww3k/zZH1WOInSkLwNaL0JeRZ0B9idhyWe3USwtNq5PwM6l6wV\n",
       "7ihuLHlGWTm9liE/wpCF5IXrcL2DeczCwMe6kD8BDc4zOltD6ZomTHk01S5PqppjTi9n75SJCoR1\n",
       "N5B2uSjqMUs6exhW4kcAhRWF+Ib2m+AGW9NPzlj2Osb6x7XCWyU4jyoPaBRwjPrqx67Fllemjeez\n",
       "tQW8I6TDVXk6mm2FgawcOHE9fUFyaYv+o+BXpKh4Hi1T7JIeygWTUXeuDgaaBreX0JCmAsVv1TK2\n",
       "bBHk/k5hwRK1vf3RB6uLbBerNRcyAlWEC/Gb5ILhhyHAYk+cejgOsJHhvZWtwzMnZR+O9t83i2AY\n",
       "FIGbEKk0s4E4M30sqmTGGN2d1OB0xTh8FgNEChN91AigQnOijyOlIQFrPC0mpyXqY+yAzFLL8bRu\n",
       "G2vEvmmqeGE1/0w3wrN1s2HjzbDV5jc0qXUcS9n//f6ZVetOIuhCnaiJlzayoj0V40Lp6j0FKyDB\n",
       "jEWdViWPa4iovv7ewHpK5dwLnPMgAstW0denCLcAJrZSiDYOOdg+V/OcCZiAvj+GZM6rrn2d1WR5\n",
       "r0Os3mznIEWW6I9F4YEKc2l4WbSs5v2dqGMD9HdZfCYQ3WztUH5AI0CAh2vbYkTbKhYPp03+YGP1\n",
       "xIVTF0Mro6UG5W81EW0IjJ8z+fVu1YuayaAPfzZbSusQEd7w0JCPq//5WrEHtH/1lAFiH06ayqD+\n",
       "aw3FUnLZPTfZYU3sVqah39lhtKa7HVUyuRHVtkz4b/oHB6ih2U3QmXamkcq4IpIgIpnYbLkoXIfN\n",
       "dStCPpPGgHrBdPsoJLKaEJAVIGJxmUQ25deU2MyOlq8M0nPrrJ2hDAcyBxCtFhGLpbntVpcd/auH\n",
       "/z7/EfKeTZspAf9zQIAcDWvFPtDIuuhPABytvB7QxzS/rxpQbjZWTCFM8YvqpxHvWGVAn4PLrtyC\n",
       "b7iCjdKXU+jqrTXsszdigWoxePGtiBArOgefqphU7BYdqixdI8PWy7b/Qg4Vm3z0fYUhQz76EFT1\n",
       "X6iDRVNd651fwt8zWuAeQOr3Oqj4JeJT8D7bzvtwpEbzMiHkkiYcmOd+qZYAMvE+mNikCeOUDfDP\n",
       "lsvM+GtSQ3P6+AhnZyaP2XD3M5Y7brguLn7RSwtMOZyLOzsZ6J1YA5aY6YFZdkGakgz0AY1mJhVu\n",
       "DboGX9QZXbwwuanqLxLGD7njt0+iyHTPObe30n9NEuVQLWG79ywKDm0srvboGOyh9+MbDujsCgha\n",
       "piCiyWGgRTy8buCF9G2w9HosVau3cSINq8PlFjl2iSyGLqWcII9QoMpFT1PAyx7ySOj6YU1vA6Xe\n",
       "zU+zjzBvHe94Gk8lYFBwNhfVLz+lP9e0LrSo96pnFWqI20wReTNylPq3il5lJYWgP/umX3T4oqfv\n",
       "fcH/mjHdqZXUEMSMhbL7uU4nP9dmAF9EZzJHdXc146960RIlTHgbJvRToWlJxbdi+WlZXbBEsL6m\n",
       "yXXVxupi4DKfmgyHkGXmELgFOwyuFbj8IRNUhew7Gbtci1Vwg+UWoXUte1PvTJQCfeYswVq3fmIB\n",
       "9IRvQbTrG8wfr07VXBc0ZWoFBW/J7/aIDHCMPOEixe0/Cc3zou1sbAD+hZSC5rqJ3AaW/HYOcktf\n",
       "ploY7KYYYorj9qr26edb4vm3riDksYukVSHONLuVN+8/3HdEWKz+pJA0dVHgV28OVegGalMB8mCO\n",
       "tFjlPFYkxdc98PRuxTb8PIHt5tGt1jgb8+zoFYJHWKdeqPeGhP1ll/G6lakpfiy8g69x+bns4EH6\n",
       "0BTmfMpnoo/+bLUucs/mTct+9VEnZXC+Dw0V2Vqx8niwtChf2VJuU/HRyh/omthsejl9H2kSRLNi\n",
       "Ity+JKIsBgP8e4niMMHMZeMZWMcRGafMx+Afa2GiM8BGhzH37o40okTBlOV0BwUgrnyEyREhmGhd\n",
       "62p7EZElkEIk13PNf2dn1w8Tnwg045CxK6q3yzd5lWRi2c9uJNKXiycMustbjPfAPdJ+PnJ/PEeV\n",
       "f5AotOm/HbnH0R4qakA0fRgH3GHN/qeccyYciF1dZmPdrsEq721he4qiBxYwPCwcF6o5qpbksnGt\n",
       "M4cUNCvJ1c3S0dXC/u3m9dPZlwsOj6Mpwieo2s5fTBvAtWyX04o1zk15Rd2OWG1pBYECP7ISp6Xk\n",
       "Pl1BicgPXmD6ysGK9b1omXHr6p9THzyo8uidjpP0ZLTUyWATqwNvhQCW1cYRZDjocbMvSkWNXHh+\n",
       "8+HcuoQfovdHpbhwjVedn092YOodkIgEsdN/sdDsybP/zG33ze1SDZqbUqgkWlXlXpSpxvw52LNG\n",
       "zfWTJBWFucDkLhQ4bAJV36cr6X3oW1n8Foi0naBainL9Hv7kU+C3++34c17YZi9XfhJt5v623xpw\n",
       "b6+a0QYnlObrODDBdOT84XdMbZeNVlfsxD6QL2ia1CsqV8UKp4AhVRarYOXFGzwgkKuml4gly+h7\n",
       "bDdV4EHEmCljnk2Pok8mZ8zMWqcSVAo1aTwn0WXuv72zIGNRn1CXEMUlEMJaYDESJiSN06O5Gd5x\n",
       "cF/VfwZnMiQuXXr4SrCZ3GC52OlrmG67sO7nPuFen3zH/Q7bKxV5cQ4lHFLku4gvAdeabgMLVdC/\n",
       "u9F4kit5dLFJKft/sIfx77HlyrWqSRMnZVfAJmDfkgeOxXlkt3hAXtYOPvyc0QgOx681BN/05iGc\n",
       "lV9wXosNFhdKeELbr4Su2PjUCUvmdwXW7jNFAppY2qysgjo1UyJ3ba2FahJQ3G64rdL8dTFn6AeR\n",
       "x0NP4PQCJVCCwumXbRTXIMmVJmIhqMcS4/OfEh8BKGb+bygs4lDaKyo+L0gFXZTpuDpV19g3/y8l\n",
       "9mfwyCbNpelhHwTq/c73O45m+TybDP7wcwIMZayMasqpowaw/DC0aIfidPyysQTYSc4AETC6VoBV\n",
       "xdkpUZESDDCYDzYPSwCRyJJZ2P4CWRQGmAHG+NdLVuTn8SAFc0XAGB+UcihGLgwEujlFy+z19aau\n",
       "PZcColnh/W0fcqRPSLiut/9nlzf0qyc2foOv8oTg6mqXcQGJ7gEmQ6u97s7NQEOpavN7wHxb+WYg\n",
       "+UinTDMmUvZkDBjqQUMuymxE0g2XdbUXt3mMpY/f5pA8NAdR6CzoZNW246DjgzIfNfEPK/O/SWZt\n",
       "/4mV6XqAuVNJ2OPjw3T3T0WMMRGuHfJMpECf21UKJIxC0eHTi46KpBqEAkzICC4/qZimyY59NI0l\n",
       "f/Y4cRDH9RX6TAEBKs+2OWRW+osxrLf9lowyhD+46xQPhDtq3+VGIwnRkj4DcRee277oUVSYoDQ/\n",
       "+4BgR+0glYuPUMquEeVcn0XWiSxUi05XRIK7j1OGTJEvS0gAqb3B13SdJXAysZYZN4BEVrzIsjVe\n",
       "hkUg+D/yQsLE3H0TXodnpxEjvwiSYnWa5Tn6Lm+wue7KXpJAv4r6l4FjEpAxZjInWi9oOzwXVWcL\n",
       "diSNbrxpBW8LJCDqpf7j1FFTn+LW5kNE9yUeq3h6VdZ2ETh1LoJQ5zysZW8YGasKH/a3X/n7tWLz\n",
       "R9vSvsXnQZqhwdUw/S2+CXOUT75g3dFbU6c8kw2gP3e/zSPFSxLIO3FLVs8L0IGj0RVnsydY0f+3\n",
       "SBfCR0TmGeuVfeirU+AXF51dHngkD9LleqXbRMTJzBQ5cc1pB4/t2T1HzLdTmRJO5Odq72LfZokO\n",
       "fQFy1BVpZCeyNYSqTOFkZzGYgCe70hmPlQl34y4PvJMzkCqnIwzx6/Dp5rpIfzcTgLp1SlmZu+Uh\n",
       "OeXZfJw730gHUpf/jTaXFFQEaYoQo+RaJa0pUOXpRC5XLCEQobvwN1q/oW7XvXcIyldewSMjAdc5\n",
       "be+3tS1Fwq2mu/BGHf53zvqkpX9NXwDadstQ30Vyokb0WNtBxqK/Pzq0AtHQJ241vUFqEtUeFsg8\n",
       "uYjGoY873tb9lGb35QtRii1S2ex8tbozdTtMe1gTRNDuqPxfRpHlPtqneofklaYydrKoMfLUsSD7\n",
       "pOgkus+5PEnkcnnKZXODb2Gfyq/x/XbA2c0zISTnK9Bhelw2je5yK92S8D+QWLnwqAcIf3+V9vNF\n",
       "C9Zsl2IG5Jrd678NAK/VgL9hExuQpIHrpZrRuMO7HVxzCrFgtVsvMECQzxGZhzeDheEILCvri52L\n",
       "RlXtpbgb82Hhl0T5DFvLLKu+7ijS56gbPXPQ9K3CydljK4DOVMAEDqn4wwaw+bBFUVk+LGqODc4i\n",
       "ew0wr92MNkarpU+S0rF4DghKiuTa+SvnCVHfnFN8EHixqc21NbrpuyDt71UzPdr9i2Hqz1xIB8Ql\n",
       "2xIp4GOduKu0Oeh3beS3mNDvHwrAzlJBQe8K3MQjZTMsplwJJY1qtvkkvYLrJvdpl5kQ5oDOev1j\n",
       "36Nr/4YWsj8fE94dKrgE2mYoP84WLAjwKcTkQSjc4sEM8I4CaSgK1twwQzFXGn0EEqfdcPMtZ8HL\n",
       "MVgz6QtP/1phwNomwgIpqp8lTDllCT7CtAcUcN/ArpK1mkzaojuFOWut+C1tGjEA+7U5jxfafPPO\n",
       "N13hWU74JmvWUNkU7G40rFQ3kUkJ2cgMO3gbnpRHbfYOmNGX+Z0rJ/w21/9LzFqAkdUX8aqsNNVE\n",
       "qO6iQidCv196CQne+ymf/4i8JEtHWRKUgT/t8OZc9JFe5u/jl93ap6R6J2JjLjWXhcCJc002+Uh+\n",
       "Mu4iQi+VooUZ8I9kY9auVVwc9coPzJwFuEdYEjuevjsmD3rF+E95v7GVIfaYs8FLFi+3Cab/ML7K\n",
       "ehJ//XNn7ap9VSBLSOlaqyE2a/Nk6NPww5jaKXGNOJQ+35gsYxUJ/vB21ktPYwMvc1E0elii+aVQ\n",
       "68QJ2U92uw7TyVPUkTZAbh8mZA5qwF9fBPAcxqjfSCaBYJCEna6l33vaDAAyEZBlC0DglXlASHEk\n",
       "uaAdX0eSrQEbgAmH+JeVlC5Osm7OwAP63ZkyB9VvguYZT2M8D0csKohXdb4Pr7mpTvF/ZfE4/nO2\n",
       "yglJ+OLyj0Z62vKxJe/Xp9K/iwhGaP6DpIGGpjYc0XS/7VBjFfiy/2pFmeoc+6NJtcH/sOo41RHu\n",
       "P7hNlgmPyzq/JdoKtjShaifP88XoEHTDtnWIH638naMbG5ix+vptCQFBYm3k9wQhIla2oWVUHMwn\n",
       "0WnAhf5uye/ZvP2bCWwwpuXiHCJw5RWYAVurdnbXcw8pKUFhJhTsVeK33OahodXraeMc2b5jERHs\n",
       "TL/4rIEEt831LU2Co/c9n/HnioEaqx5gPMQe/YV53S2p7rfLl38o5LJD59zBa7LvsnliUDzjFWKr\n",
       "dbXlNHrwfZx++IuHUmHzfcpAyY2nGDGguDnz5+A2i2p5t5Z2XG+3LT4EeCLeyHhqfhyZbw7g7tui\n",
       "Wb66gzyv/5ZaRAoBR6aqIJMqNzkynEp5TS2Gz3ucAa3BoXOeR02U7e1PO40GqgFo5le3DtkAgHrW\n",
       "3AtqAZt0vXPfqxVsNzDvV562wNk+r+6mhuI4+Lj4FVgfPyk8Gxqd6DwKvjyqAztgy1+WC5HL+uzt\n",
       "45+KjitjiSSq9PW2wamsne76wUvTn4QRa8gr/e07zsmutrWvF5aYydZUpTGj+rsrGhOJVDAZp0aV\n",
       "Zxmd2f3li0iV9aZKQodvvhpQADVT5f3qUfBoz5cmE+uDezf1zj+9xnvPExwjZaxCi3YmEPhOQSkx\n",
       "Pl/J6ZGacnjgtxDtOFq2ML2ulMSJK/iEhv2NQyxj0mnKlbthRE+hBuek7LM1z9xntY4dA35P3dpw\n",
       "c9NnSBfFzyFypZo2dTDC70FmTcJzR6IIvcx8y3nsoEk9anHMiQucd+ADp+UuZARJUT9nJioYHryH\n",
       "oGnFbESTl+0r9l096FHqHilrefrvzIq22AMFd0MRjIJgknlaDVywf/Gg84eJkzFTTioaafzxCn0t\n",
       "Uv5ilKGIyKQaRPuXWUrD971hQHYSI42qfOT81MQhUaS5uN3UXwwk/y8/6gm1wOJ4Jxs6p4tNN3TS\n",
       "kh6RDDl9FJgZmmGUlZm+x/mGOxAJfEB2saWOXi9y2h73xzlGH2Fd0BTQdt20WMrKc532Xyx2sM4A\n",
       "90+x6cpN5AW5OxaVmging+DQZ99ZeJvzD8k75boxJrnl2wpaCntriGewN1PQwbXgUUzYO3lVUzNJ\n",
       "CQVgLZVLBSzBAndU5R/0cA0Wh/opMPSJBy01j5nY022LAfiF79CMzZD9kO5eygAUv8kONtJvnKwp\n",
       "zadJzjl6p0aEe+gmMCYFhtVysIYXaGvUABUhqZAAZkS10h6cZ6irI+0DoD3AI00lCvYbA+tC6ES4\n",
       "AU4V7gXDfCEibb/y8lyVfxAW2qy5MwoLFecg3hFbbaiQaC75yDr+4Po8v3brr93PYj3b9SUsyilv\n",
       "qO8n/H7cdUADEK0n3zZYfF3sM2GF2kgBh+q8yYzJ/+xmd9txIM0axjMQIfc2BeIY33Geeaphxu6R\n",
       "THSgqBGAFqnhdLqc5+iGLZ1PsIv0TdWVeDbHYdjMOW9T/7rVLJw37Q2j4ZlKeoD2TvFy4uOqsMNH\n",
       "2Q79laWmy4uGEYVv2og3VPvm9AfqwQ3J+LYwSsAK8ZdO+Suol9mYyw+ZUISdUEw39NUTTEkUCsMA\n",
       "GlAgjXRra44wfYf6SGBPQkh0BOS5JZnKSym+8goVEo00gXxYsMondlh7eouMp2j7d94i4Zc5hXYS\n",
       "oM7lL8Yvna8qbBSfbuRfomP9Db/fPrZNAUWrgA40PoWucyShcjcur3pV+OZw683FMRvtis3sZp6X\n",
       "3Kvj5jPRjtdPmfiEVyCBeMfErMubpuAZti3vtCo2c4mWTJvvy3z1gZR+XGzzBhGT6/nOmxOPC3Gq\n",
       "57zTk/oAksPZCA4IjaRH14S/3bzkcpg1tyN3ND2GgRi6Kgv0rVXUaWd9+qy9bvE/5nAqjze6uRB/\n",
       "klHrckIo4HBkOhla9iFh/MrOdqIhPKMbh+nUa0IAc9j0NtcK//tkZqsjN/Q2GFLMHOf8/b0+5XH9\n",
       "XRF/OaI6o/mEBLde4t1qI3U0Dlof80y0fxn86OVHICd7+0g6MSEueIAnd6cx21GsJkjALdAGnICD\n",
       "sHO3J1Y1JlkW/lu5/FUirTx1lgCVoVujyb/Z14pfenJNa+G0uv4ZnLNs65vVZKU4/tUewfFEVSSh\n",
       "eH7P639a9VGQ4IUdz5Z8adWbae3RBAx0xPGH5E8sz21/07jsUFAGdlf34Rm2BXVQnLUU4gV1MVno\n",
       "3WVMpLfAO99Te51WyAhf8VVL9sWk5chP/vdORLfy2eSiGwBqD1BVD2E7jqM5QS2p8wLr9L9sllr7\n",
       "L6EutCJCrhJkKG199zSvyzAoExFUxkLuCJkjAUR97spuj/WQlgecy4nMmYK/wkRxp+VjkpVlJ3bl\n",
       "PLZa6LFSOCF5C8iVwnNbKV6bovWYZPyWoaH/bJKbCDltC4GwvgaOOBCSxlKe6xecg40MQQ9UHj/i\n",
       "WjpR/GQoZit4fK6NFwMhzL8K1cis5VAfWjLFl33NbthB6hXkc7KdhSka17oKfWedEDwHdcOutv2Y\n",
       "9geECzHydY7VaV6VGpa2Nbs4EiJFb7zgAADHYE62U3ETsVH+3CEPT9TM9EwlBUEsWoJ+w5noer7E\n",
       "qbI5vxSd2AVME4Sefecu4mnk3BLZLpfT8d8zemmMm6o62ZOwyh6rGSQzUGQsZKDdMy4RacPvR3Xa\n",
       "s4iQUiCzhYKuKrjbTH6LvWhnD9B/lvkr8lpF6REdsLonVRJrKt8Q3liqmZPznx02Rwa2tm2ZufSp\n",
       "Hm7LagigUU3lC7/JQlfPSbf4dt9vwExGF7VEcbAj304P1FC7iGxpp7ry0P++M0xV6B69TX0ZthiS\n",
       "ViFys7lAQJ0PnGm2xoafNfn91rmE4Q55qw5Itf/jBoT9DjgNYf8JL+9E0WRwppoMCEVQm9C6NU9E\n",
       "etk7iJE4A7sDcLScC3SPXBOsaX+cbjijT4Hmti2z6eNJKDfStSWt68Sse1368wKoTYB38VqaTvVC\n",
       "S6BNrn0ex+N0K6w3vj6gYK9qBicmBGoJA8YRCa8Hdw0IXeRb6vlTeuQToOTo0Avbjpweoo+WIVAI\n",
       "+GfwTS6TG0AE7WWJca+ZgUob44H5FGU4eWjOKZGuDl5O3Lf61GYwr+TAT9WqfB9PeQ8yE87eG9OD\n",
       "O/5n191SdvzJ2XM8liS4RlY1jffDwvd2+BH2+f965frGPuQJtg8eelJxEZ0n4AsGWe/gDW46SfJj\n",
       "mNbx4q+BUNaOwXqRpLg4EMkoDjpFse96bs0iKfBfq5ws3SW84Wlpx9em8WVCgj61dkwYaBw6+geS\n",
       "sjF3gOxvG8zCReuHHQGPB/LOde0fBtVh+FUdgvVySvfEGZ+o4peW9haDuR9U+2yPffGV2RUlLqHt\n",
       "Tic19b213nCLjlKHEkTZeAi0AQ/4lLXig+EM5bWdzlxynHhqVeP3pf+yNKHnA2vmsvtyFTy3lXMw\n",
       "v0bxuO0ZaxWD/xzg0iyf4Q1KShSw4QKbx75vSNc1+CY1QeJ9qLKujpKLyB/OCS1CzYfi/bXw1rY+\n",
       "Y5cEvnzD5IR5DrIMZcmBSaj+amEwpc8iDmKalN+7BWti8pGt/YobsYZaAPx49NSI+pm8D8YX9aGj\n",
       "ug7KnIdeh9T51rux+FNyidwvqRsXTLtWsFGowAqeisQA9uABNx5YhVnrltktJEJLwtIw+55tQmEL\n",
       "O3v0yLnvZLjbq5hhhHvsP4ol+Bm3aFIZqfpIy0OSE12K121KUM2J2ANEq/ZfenKl7wl/anBI1/0s\n",
       "KygRtSPxfkOypQTeSo2M1yIAhRASJBsjsm5tyGynx0moaxcWNFhX+1k4Yj/vEsmRVE1js7qk68ya\n",
       "Ljh5D0CTv+EIvYEjN7vZhC/BTn9mcOaQTEmNGP/qt/b6gxBGg1gcs2HY2Q+e33C4esKKMGSUxFaL\n",
       "g/Eru0kUWQgVnAmm2z6edQeUQjxNr94kzHyDs9Yk+zphJ4vwZVyYImjm2PtSnxer2Ht+I5S2/KW0\n",
       "ZecdT6G6SEF6FcU0uRrE0FW60R1ADoPtKs0KR6gbXoU1D8drgD7jgMZ8rGz9C+0RU7yE/Of6EsbA\n",
       "8KJOyl2E1pj+ORekRk1Gk6EXdbPnsxVy/ssC5RHly083PNjR6ZKenxoML6liVAjcK+9im8nD3S5z\n",
       "AOUlkARnWRixRcSq9ksn89ff53cvxVgzQ3nr4k+b/F9hXwWq4mkYOa2j35MVMrsWuQltXiJ4MwLx\n",
       "IOSPUdeCBHcJqMLMTo06QexOvEE5yx0U/p1qGzOVSfIBr36A2GevhiK5ycBNZa7GLll90XTkyJty\n",
       "byKrxEFlq+n6XRONAkt/jZktpr+d/0FmDIYbLdhRTohi2s+z0J35/5NptiiX4teIFrVVO++EbVg5\n",
       "Bpb6TyaQgGvSrSvxYWqMcxD24MoVBHSMLl6qeqo5aFpdVKSFkH0QTXJgKLaBgbBz/IdGuci+D7TQ\n",
       "o2YZ+YBLfAp6FPAP/ixzUFdikH3guGii9zgj7CAT4lJ70hoibt3rb2sH3Y0d8cmnVtm0UQAMOiOy\n",
       "K3qOAdEVvKnnVLbo0Zt7Nu7grtSWOvaZS59Sdif6feqBOTJaUHa8Tyh9SfG7VP0u7PtCxJX7Bc5T\n",
       "152tkyD+gV+8yVth+zjcwC9SAdy3n+UHN/vyRDQkH8zk4QJ26MVgzCyHIcaza1WYCkujw8n1HoDX\n",
       "m/fXIiXTyL4oxrs5xyclZAlL/j/rOy6l803nv8riBT5FEZ+/Qt0vf+AOBW9bVkReEkB0remqH9Yr\n",
       "AM5iYt/A/0S2564CYP6Jw9rfEJ/C6mJQ4cQg974Nf76yoYEk6JkOftxfpNTo5g+0uKiP7qTfvvc9\n",
       "jFNEThQbo532nGemLq2gp/q6z8pmnmbB9utywzcgLfgFPvdnHIV8AxY5cjo9xu6IxNPpc70JYhlT\n",
       "UJp3lAeYqOayA+eIE+cSiZhzi1UUKNgFXBrlM91qFFc8gmZU2sO6Uo27tgx1BH3MayYrQ/N1AraH\n",
       "hGIgE3fQJAg1YvPZ5YuPlFbtLYw+voraNR9yVL8mFfjHOvdcxFCED45nEfjB4HBkijAzSwCVDO7c\n",
       "xsUtn+31msFGOHpXme6dz/y/3Rl4hDA3QzoXPO6+gy0yP4Hd1qHae6AYlmuyOO5JjFM3BZGTlVl9\n",
       "96kyDMgTt/EUg70tUWDo6itnMALBKDnMuTMUOwk/+f2d+ZtcKAkNyHw4t3Weedd/Cpa/I9EdsvOp\n",
       "+D2YGN3k3vexPCp6AqaKc6aQtOlYCOvZmTbOK8x8HYVNKYnVji71pxvEhBJQCpX153c1PuEJWPsd\n",
       "vtPk/Xvxty3vJIMQKVxgmUyTeS+Ir1Qpnq9I+7qqpQ+MiqrbnMFqr0/u0awACaheam+bdBKgxL/5\n",
       "qy2g7znFH+XzYBnBPuS41Kfwy30uZcR4dquCv/fWbHFtu/ZkGHltjSP5Zm0ECa7l+YDGclFL7EEs\n",
       "DQOwufKD1jzrfyQkkexdqBjob6sbGZTGcYXr7yDwO5AGl0zr5B+JUpnGA/1E3TJpJJa+WAh6Jime\n",
       "D0pwTCpnuB3tEQxQXUba9+5HO3CwNKbPdh6ujj5xs3q5X+92lU1jPB3KSjOdZnTKr69xHeVOrtS4\n",
       "AZnYik8CBpdUbDzt2x36iwvfRMt4OpcV06ibKZ9p3XslFpBb0Av8mznzZcMq/A0YXQG1+wynV0HS\n",
       "p9heoF70smnGv38IaY/MarMZbp/brg8h4nHBcxoz9jF1h44g5Z1CIAkbc2Lz17WxiC5RDK6G3Ktg\n",
       "D8GI5Zylvg9vl/VxiJAEa+4UWA5X4kFQNWGSPH4DHSWa1qFvTvtN1twnG7MjXTM7M5fprM0mkAE1\n",
       "MIY2999zQ5y9JSemwJO5NWojun3EDSbMyn0MrmlrIAMH4k6XV/Ux62+YP/jW5J3GSCoLzc0WcVdW\n",
       "HCJtrtTx0WuP0Nb6JCheNgd+gF4585q2nvdjsI23g9dVdByZ9s3dOZBOKO2c0FIlS/K+dSrARBya\n",
       "9jAkUgiujxoS9uxH7VJJj29KATKzE0sH3aWmFaPYdYbmOB/c+QOzE2Oc1W2SNQzN+FTdpHvjDf/e\n",
       "Y+mNArOA8+DtZxZdUQAzVin/tKTE2BA9GIZ8kRapVCSGTAya+ewGEjnIXWwOphw/RbZtzcr9JotI\n",
       "uT+qKh6zKmanJEtj1ghBMhNLYOm4LTfRf2YY6bztvKXFS2CSCqbB41zGSfKS2CCgRfS7GMrDeGhq\n",
       "DqYeXM9/Y5A9cuWzb/e8fY6Um4yzJRWgObATCOUqMbbUL5MqskTZV4+V0sE1zSX8tw0CfTCeZdxC\n",
       "OO5fuj9puY+BHdpeqBX8qXOZy+FenziArRB9ybCZpY6vElY9FZtRWFrbKnbd7ltYZQD+eG3PJ7hA\n",
       "+B/Xh8/kHRHi0fGYakZ3fGt67lsEWLrTM1HxnPob+wKfgenCtQlI74AjFvwYh4yQjKafroTLravP\n",
       "AOW2/kNnXNX9XrJhFIJIn8WDCe1jSx/zLhRILVbv65idE+NShzJRrJs5f0a86Ralz8acbvV/oooQ\n",
       "ez5oxjre3YXAqvG5sTP9lovQSZnsWNtUlfp92aYBiIbAeEeq4oiU4qfuBQHXyyPIitL8qmEceRWj\n",
       "vpMAtOtRUeqZtrSiIXXHfk9On+UzeGazdUhmPpZhOGyQOZGX3j8hTf2+BJJGSqPfQ66HbpxILAOZ\n",
       "F1OxZwuUof///+MXy2jhdL2inVrHVZrhMfrCKNkl7B6tLvztot2go42jJ0lD4/rF7G3r525WyLNr\n",
       "c/UeqR9CaCbJ8eW5AdlvQ4RP4tC8Z7U9Knc4l+ISC4lKi5+eAxuTFICCjzwAj97tfSdZh6I7Q26g\n",
       "zqM7hctm5bkYaXFt1YhvBP9+mXb7OWU2NravhMhMBr43t37e8tnk6idK0miko5WRRftqWTR0SvsR\n",
       "vWgCHxb9xbi4HNYnDMiFhhBPLSeL2J2JSu0iWp/maL9Yhf7wlpG/OCX3rT51jKhML4oOFR2oa7dT\n",
       "0dVTOq1ADZOWTUAlWpDkSsORfnIl1kHCq2kI6ccUWo7KcLB3JoFNtbNBfwChDwH6A8EmyNtL8wNt\n",
       "qAuU6Gz64hRcZVKU10z2zHRrC647wvbB2nEJ0CfBWoIFQBbUg6dvub4y/3h1LvO428c3lNoc/DpR\n",
       "Ni5Fi12rbMimjI4EVwcVSGQpZAx5do/wex1ixyluBlt+PAhSxjEqoF+KUAKzVfoSF+vxZJn5nRo5\n",
       "3A0/wu1oRyJ2DLcFZfkE7Ljo7SqABhLIgvudV1KXMl+cIAovSnk3E0VwZSPehjHAfCcG25lCY+fp\n",
       "1Bnag092uV1FnApj5V4uuMxku8871Iw53z4DYg95HdJg7X+PBf4t5w2MWiJo6W7mDkxEyuL5gvRH\n",
       "/Xbu22x9sdIwTIv7jRKTas6QKQ8cLnPyrRdWd/FWcNYhBP0J1vZ9V1zCZPdSTx/HmMlbdvJNf0zA\n",
       "kboSCpzEzyBTrYRVxADvMS+CzSN2Y5quNjNb3ivFoQGH3TG7zyCZs1B43qP/FGXxQiIGY1e5bPp3\n",
       "CNREAodPni7UZFk/kJ9DmllC6IzNqM1Y/FBs6NgK+qJ1toPZkCCD64/NklvizsyEEK+CNAqViW34\n",
       "xRF8hAOTdPArcjQqPxaEcXBM5qAvrtFhtuGLAhNcrIz0agSB60LFScK3Lx7Lsihf/bd+laEjmc6a\n",
       "JeIROiQ5Ri7m12AI7yGKKWpGWyXEFjRbZqmK7SYtQW2Tfd4Fc1LApkDcZNrfn6bKnmkmTz6mrauD\n",
       "uPQ0R22TW5Qfe0fls3tyrj+Okdkel+/8BbFBZearcbTOkSSPtpJA7sN2MFDnqK4l4Ld2FFldrKZS\n",
       "QNbhAVNO2MNxOGBBbyXpN35cVhWjZvx8dJFSMNqHyNv2p1bmJNqCj07mvp3OHOSwKhq4Ici7kaA4\n",
       "SjAPTy0jL53RaxEY36d4Pxill1UzSfcFpoRGEqM+B6lTEgBUqIcHAbCTpgmJAagHvvA3BE9/sFyc\n",
       "4KhD8t92jADZ4JlJvaehVgxXYicADuDvoxsHiA+PMjQSeN8Elj6WIhHG9LJSH1PfUWwXXMOKJzFB\n",
       "q6+u92rK8fJpoccnTlKwhtTsfvpdIHVdR4osUvdHx1Vt3wPqlr+lhyX+wQTTp9yYxLCnnR12+VB8\n",
       "nF2JNVVxzYhWal7NP/nGB20gGIlm70oUFUrxkyAioQ+m0YWX3w9VGx0zDhrg1hdYSa2GLSmjIGB1\n",
       "xs1RNIY8aN/dfZDhiNjTcGTKYq8wvVn9jI5duIrywprWFch2meCge16nWUmjad6W2a96uVTa4cNm\n",
       "xenUjEBn53ggd7C2lQBj4tNy0+10krPgqdAsImheFFNUnANDKOnXFrVMx5Lv8Az+o0NhDtMLERJD\n",
       "YfyDfgJCinrKvBHiWEz+PrHx7DNeT4W77gIxGpHYoYdegEOaODCJhYoRgy+G14mpW4v33LATNU0Y\n",
       "rk5O5eXGo7YGq1e01VRkYq6fV/bUQNEHy57MnILfKKpM4Iauf+ODPqSNa7wkb5DaBf1VexXT2Qj1\n",
       "Lz3+ajYyzcXgwz+uA/BDkD5nBUJESqr2HSE4dCLh5elRdrIhorGa7Inpu3gxZut48KhW1dxlrphC\n",
       "CSkqD8lr7QJVsILLL8814ITDviA+14JhjVGhtD4s38mCdfkSD88NXrViqFRQjh4nkBpB4yub9Lib\n",
       "Vg1f++GcuULganG6U2Vmb4PJiyGVTpKZtqonnU/wlTECATYTPdu5gyBjVF335C4dqTELpvQGGlJV\n",
       "ypPvLsyiah1l67uFqkUxZwwh6fJDL7gdWxK/hRNHnB0ngZ1ruIPg2OPiHr0xf/XXVz5oNw/Chyud\n",
       "d0vcmriT3x6OnwLmG1//w0v/qLyFppJbguFcWaJ5CiYaVwZp4gpkRMCMz6hDEdqRqp4SV5kI6dyl\n",
       "pqGA2wbNZjQE0QRpP96ohKw/sQmVuEIDvU8gWVii7pZFJF/66Ku2g0PGLeApB2jNGwcImpblYnjT\n",
       "F2qZb2wsuiE4b9BKWmO6WFxYz9daq1ZRL5zjlYD8AFNzSNG9t18lOg/KU/eJ/0BnSd/VKm35RJDm\n",
       "AaqxdWuRF3QH9f5euwZD2LJdrpE3M6xue0PFSjVdf6gE+QiO9OFY74M/B4t2MpUSwfFPma0p99lK\n",
       "kEQ+ecCLPl1rsbwLptp4OR76ANd5JNpGhKuSj6hitgI9lM4CqC3OReYD4nfa7zse9TDGuFhGabBq\n",
       "EMVjO8T8Gxdn7UiTOcKnq1U9GBiQEdo4lHeRxEB2mfxysnzzQQsVqAID6QYpMNzOdAlfn6ZXTt1o\n",
       "WJfMW+4oX+Utn9IYK2Qb46c2Zyw2m85z6WxfutMX7dgOB+QBmOjIFIqOpRzlx8+axFjRgjWxnTi2\n",
       "bZrng7+6YkObOZqGrToyXGxV25WHnv4S/B5oj6G9Ssma85q4NRR4RlKd/GOopB9QKwpx762KNWy7\n",
       "LLFttZ53mqX82LqyppxqBdHsVO7r2X1wepgaKziOWm2wGz2vICXA9c9h7alrnxbF5gOozxRr49m+\n",
       "ei2c1YjYiQSIEPpfzq3NRNAjWFvDfRkG+8/TZzTm3ipPzb08k0czBij6Dc4+yIkc6VhoWBpdEvVl\n",
       "/9G5rIA/0HXUk+6HJbG5VXDd6050IbpUaFwQdSeaftgilVVMCeDMzVdL6k0F9jbMeu2oxCb26qXY\n",
       "/N9q0wJFGysepOX7G6jjFhJZcJxAXoBLfx1xZJKlQKanUAx/0UGS3rfAlZhL9xySWkqwoLdiuGpS\n",
       "NoJYHe2FlnIiq7DhCaDY+wwAEDoDihPVmBDopZj8wZ+Mw3aZQDm9cyoYSDVT4Jql+g6HK9qVlktL\n",
       "CV9IDX1+Qg7iz8lepi6ikoTF/hXvWRbtSIduabiPldOqoJORrL6lIU9hTR+71sOt5Uq56BFCcwFq\n",
       "qYRAKtgGmnk9ZA7PjYHsxC9Q97kPsw/RrEkWDX2GNqGgQHjog2BF0uzKNw/mB/gQLLOEw+oePFzv\n",
       "JZkO2mptgCcfJnJNS39jYLYghRGtiIqykLKwtBpQfQFYo+hsu7EYAizfdI8IOm/ZldKaadXwqllu\n",
       "KPQiMoy8K1KDiqc7Yd7BMykNaV3Z9iJeChwZI+oKjkEgL2fyIDK7cyn2Oq0tjjIJ6nBMNYGqL9UC\n",
       "NPd6JFGZQv8Mz2tlBTQJLa4uIxzNKudeheKPS6ARrEhxSFEG5S/i6b+fT/F0R3zCZlVvXWyrc9Az\n",
       "v5u1Jd5Fi7Vpr0ZTNtpO259ZhpwssSHto4GRm3yltV8hpUgMqDT9Er7FdBfJNgmiwABsjPocyD7U\n",
       "R4vC5G64OF95N3aRlLHnPHfqi1bWdk/2ZiDetRu0p8aOrfRt+mtQ5NmVCkWolP+fwZL6ICp67vTB\n",
       "ed9uS4MmakGt2xlKYL/IRrj0H4AdCH0OZEE6Ljdbh5FKOgc9DC435dH153DkGDuJtdTGpsgqadV1\n",
       "d8MUTic/61Tt6rW7TO1DB54j0NH3YkYcToC8dntHw1SNclKHrn0KiYrmc3MRM2SBxXKMnDZAO6Gz\n",
       "goD8VvmUB0tpgvZySTswU+saD/HVe1sIpFFRy8/tAb2wW109CNL7ru+IhlEmPRRV7VPPU/G4uPx8\n",
       "M1CWkJgAH9LWfOQ7oNNJ9Jg2kU3z1W3LZmBPhx9DblZonILXMAfBWpgM+VEmI2GXwsmNGnvRDMQ+\n",
       "kp5ln8WsOz1msZtlqd7LniERufP5PQs3k4G2EJPjKIrLxCdBkJ+TZ1e8aAJl42L/eVVTk7jI/UjR\n",
       "/XPDrifRFZvKyiEx3yDSbPuzLtpaxDr6CKuTdma7RzkYCwEQUygkSOvRFKBTEx+B5wPWcqWg6YKE\n",
       "4mU+JIW72yzXVSL1tuuYMOdCKbs4qdrtilbRqLFXQDaiQKr8v71MCAQsvv5WnUYMDt4cJ8K+N+Dd\n",
       "N7nT9NH7KvMIO+Pyem4Y16u+yFOLw3U+hMx5E3Pojg0qFsivJljztHiFPz444J178SNGhYVdfstT\n",
       "LgL9wCSKDHwo956ZAUln7SbNvPSk7xJuzCR2hL8+wlDKaiAALqcKMt99Fclbf1OPRB3dxPHpQfi+\n",
       "/XZE2qA1MQf6FBMHlDsQDvKwky4K4DrNpkmeXdBiB1W3gqJZ+CHROpehGRV1dT0qSoHXLwNOQQmD\n",
       "zp/S/9GFH3lQ1OtPJec+uBZvYIDeoawkvbiRZvNJBCq/HdNiJ5pFh9AERCM0DhvCEtjMRiKp0hLG\n",
       "9mIUXRO/xVf/N1B2kkNqbAdwmgGUmU4mMYAoybbRXgUgGrkuGoS9hLAAjErfNV58+A/un0qhwTvD\n",
       "Vbz5+gdmyX5oRmMxqlTcY9+u7BFNeSqy7GSEE5V5yyZEKoMXNFqWJ1aIKG0B+Cf8zynpLyQuO0PQ\n",
       "i3h3mpcjP45ZtY7xc/zd23udF7th2mFKkcA1dgMBgMSPC4W5gmsZfccPG0qkS7U5w+CzMK5i5+oD\n",
       "AVUx+gZ/HI5ryZgBFtDK/JxnaDPsXdgISd1b+NFv9h+OSei4RiSRdTuU36Y3VUVyJRWGRkUAEcnq\n",
       "Eto2sQ/UoOxzES76A36CogXWi6Xuy4OFoyW2hS2toYvnN+R16onBf2pL3dYfuNyNBzMhNTltGKP7\n",
       "BZrGF5Ih9Z61o29vUUsoXMJFftMdhH3pNiKOfKzayINWUwfQn3fk8714gphDZv6/9OHJNt02Fa1V\n",
       "tu1P83QOXMr93eCYRz0TOKmfJIh4O3cqp6ZY/QwMcH66CyCFY0OdNWH5lFjEPOkFAM01OMNWhyi+\n",
       "e4Fr7rliZg6qhiPXoX9RC04efFxEo06HkfPplQYMt9v8tM+9HMYFkpDwee7DotIq/uecsA8U1bjO\n",
       "O9dFzvW16F3y2DXlw9WJzMf1G2QLz4W5D2spWynksEIZf+q4IkHG5eRGLsTmQ6ECUwBM7AIaFF92\n",
       "U4gE2EM2w8+e/sLDFOTzFda+S7aRzIBaC/+bJIABgf+AJrVVHDV/4uzGlh895KOGLRKj+Sygl0I1\n",
       "CvPWn9rNtUXs5eGqtwBTqUlyUaVi6VsAftTlC4yjE/r6XP7jKgls3VVvJYNOVB/Bg8pYofrHgDhQ\n",
       "JOXOh2pkBZqalZ3tIiCJfOw1OrVSpmrveWiDZ34i0DcZkKSEiFs0FB7sKOdEHXb8+9s6K4Yqmsvw\n",
       "dPy+OotktIZcRZ3un63ovJezFYS4ezX51/pnr/fduz6kDvStohVdT1plk88NzT1CGOAIxcd6KVCg\n",
       "PUGLIF8ygkN+EQsdOcWxuFJoA6wD77LCWJMTgpw+VTh4ybhAf2e9973/qCTaJ+WO1G0HbsbfZu/u\n",
       "ZRVI/UIAESetfSc1pCUnY7ZuhEEC0CS5Oo+6ZE1gA0C/f9BWUJtNCknVj7JtSVDyvKoBu6PwK6As\n",
       "x0hYU7tK1BpbEyzTfrYqdB4cgpwyX3+wIMcdl3nthR9MchDP+LSat1CRtu7/7nG1sJez7jGAXfFu\n",
       "mgH7QUh09eTfF6aCVbtfkqL1k8Uy4TbbaGujn28y3td1u7TyJ/JP+EhCIj7d9uBQ2/cDL/Ao62wb\n",
       "WMso8+rHMBiKJmZtKXZt7qVATfdNNYpYOV8qbvSka5AAThrdfjxso0MrI6z6b7kYa+3V9gkX5hWl\n",
       "fre+RTtI/iNMpB/5JcI7ge52CQdaHTtjHWFctJqobCpXj1FFW1lh8ChMvl823XBytSUSnFid12+I\n",
       "4aPT9JG0t0ajgo384kou7uvg64IgiI6ldJt55r4i/6a1ZfOtbZeRvrWbVNCHcnZfNv2l/mq3qOBt\n",
       "a7R/xK0X+ipPK/UfVx0zd2qLSj/BdigKsb909/ezWP4hYJG6ES/rbcGJVMGlIjhq7VBcOve2zZu/\n",
       "+PLmHNnm/wSHUwlnNnB/SFRTM7JJN6myMUHZKqPSv/d4h74yRNCscivCUeAgoWepOC4+krDfOXQ0\n",
       "xg3v7emukzhDO/kWGlFwPAulwRWORALjnZ1gNAB+PLsG9zAkgrMW9LqQ7n0YtMpCCUvTqRTabmq0\n",
       "YpT2LtR+GhCzw364NGZEZDx+2fO0EkyWy/lOKQW64yC3RZl1Apsf2JvjSxOu2rRjVpXg6xe33y5p\n",
       "AcMOL41pvd0AyYsv/HsLMC1BUuqWyvj/mhHMRnDd7CTYmkzdBo9/BWDThF6vYQJZhN2+JJd0w+uF\n",
       "b1tgTzEA2y7tSdeilHNQDTZhmwc4EIR+u1L8VJUQRFmV0YcEPNfFsN/PZNk94A/HAu+dL2Z/qVWJ\n",
       "blVVYMgMKO8mptA3QnE7k05Qi50fpOpFwTNT0nRU4qkU+nhO4ZnsHCszOqzIoe+PxKKJSwKG7M2U\n",
       "aGVkdZ+TQ4+JRWUuuzOyj8ZW/GqbX4V+ErCl0t+Tl505DRjr/NKdKT8GArMrRSg4+5/JOEj1YMEd\n",
       "DwidufL0xWr9xhc4rND504SegsMkVnIPMzmH4f4a5RpFu2DHxqPBfd2KxTnExsWsUh4VCeV7jTWd\n",
       "sPGyU6kg0rezu+Tq7GPhLUaOqy6MfyrstI1WJa672SQJfmbc50mzJsDzPQfbFvhar72eIH37HhBR\n",
       "//Xr4sEWaEhllgeuyftHqGQ5vNqS+W/lxTKpB2cNI7ytHuqKd0ZlR5k5Eh/32OrFjjdCZCiXqlP7\n",
       "XR401KK0tZeFgThm3FkELZT+HUNn0o/jh7MBPE5+HSyRdccKnpvA4kbZRw3U8dy0+lvBuYWtyXwm\n",
       "JVQhZZICumB0Vcpyt7uW3CV9O1Rlr6G6X/eNYD/7//9kCiftQcf/zf0LmNJVvATKLyMq/ExaOqPo\n",
       "wb1LwZFhHcx8U8MjE7eu+HGTet8av9NDfyIvsDLHdkEWd+y1g7fhP9YxhqOeKrvq04DzTLz0nhn8\n",
       "NAIsCYWKD9KbBj9juS+tagpfUi7OLJBs0EZJlQbsb+vglVuTBRzQJe8YHiTnNe9vGgy0speISa/O\n",
       "j/CRFpJrOJBVBt+IpEFsXIc0xRqT4zxo5HszAl3I4LJ1rChmfVzS9DdR9zg2pSXuv0jj5cqTHNR6\n",
       "ozeuPdCkD3bTEd2uhEmEHwTNnLg+Won1LjnNccsFOUsYmwn+NINnMsDasUVQmv4p4esBInDPp7MS\n",
       "bm7htdNlBNQ+mpQTc+nYafk0l8J76Ag8js7nVGj3y5dam2USCHe05BEwOzZ4cjkBUjR8c+NX1zE3\n",
       "YiCmiQR6Bmwvn8IiOjEucItDqqw0/Y/39oH2/FucwQel5s5/UUJptRYe3tIRZLpCO38NDyy4L3dL\n",
       "tAA1h6mL+E0pGkWNVmhcQwoH5Sm/tOGhid7B/LjwWSxc4Rbc7eeOx3vn1/wPiGDKxLmTjyz695Ni\n",
       "/gXXZvQ1MhUpA5gc63EZcDKOP6v0EkQiimRdtseq9vbNOoG2IBeRX+qbovroQPC/ZzfK2bmLqj93\n",
       "fwSlf22A01mpYK6lmtNzdNf8w74HTRkLb+7xv0+ArKafqJAH7Abe4AyGp5MmNdsnoEj4w6N72huN\n",
       "u3bPGyv1rmEfJYCRPyykI87IMYVznF6AJXW90i5BWH5omawAA07MTFUufjgAAAMBrwAANVlBmiRs\n",
       "QW/+1qVQJZon/ABNP9mk7Mc4y/pzrMU5OsGLeIjf6KfsB3FZXW7RRbEzPxSxG9nmq388UQsPTUet\n",
       "5Pf7qqYEakCZw+Sy8lb+m3SxnXSYdtYVQkV0sGwWhowjODsenESYsDb/uQrPMkcN5v4MkPSxLXhy\n",
       "IKk34sa7WbKMPFRUiyBrv709CBx7bZbAhI2gQI41sSrYuqV3po1BiaTL+Mpx1jO/RptN3icQaWUk\n",
       "7RHFAOb9u6VEg30Dpa7i6dYb93WX1AUUCGQk6g683zDpTgJ9v2a/7NNqDfNAk9QrUA5FW36M1sZf\n",
       "PA7eT0xQwlhrwD1i+qDGqwbtYVFHfZ83W7XaIj9Vw8713BqT7E2agnhpZDnz8vfWctMUPjFs9K3u\n",
       "/TaY6ADuwKeoqqrYgcXBJXuFjQ9KVZpHcJlfrKL97GuiO9lOGkzMDexY8CgG2unVhSSfItGfCh44\n",
       "8HTxWlW7zeEkvuqe5oM1cn6GI4tAGjVD2GU/4ksHDkOZA8Y3f9jxmM0G5G+CCyrZFyN6XP4IWBKX\n",
       "2hIrElZgMl3ZYdxPP7Y62BFRrNZS42Aqvu1NgLNgOnsEOf5gkAwKtULqBXCYmIeuMdq5xGbTSR5k\n",
       "S3TPvgDNoRX9GZ37olca3P4XMr1ETucGAq+NG18jMAmjSSWJa4Lfkn8HeILpgi02z3MMiyGFnCSX\n",
       "Q82xw+yvWJu5oh/gJQamJYKnJp3gWpxeVfbFfajRbDA1HLyF6EF8zLRnmUht/hzJhkCvWwOuskTc\n",
       "xKp7FaKrlxdKU6XgGBdGeAgXHEx+ds1zuNqJGCu439EJn0fSe4ny53Kd71ZFlnaK7VXdeKL93gMe\n",
       "ObAT+go6ft7XsWDkrJGQAzuSabUdGO+KqbnJ9fu/fkvsIGGl8oWdA/GseMCOVjGkZq+lPYHDvE2U\n",
       "yUDsSod71G68vLB5F9wqcKzBBFUzFShaI4mS05X0cv6nAF5FpFfXhilcEm7maLH8MUY8V2WPXU7F\n",
       "cxA4/Adkib9j0G4rMCbNc9O6MdNBRRq3KEgr2P37moqDReTBzIAF2/mMt3zSTIHc3FzbkxyGVL75\n",
       "6nRqOOH84Uk8QwdaSqo7fuflKtpMyVnSr+R2He4uGHwz3PZ2DvciscCO4eGCxBejGKb485JO8X4H\n",
       "snKBvkymbHkueWaIVkHAtjtwHiSIe5OqTJcLZdWkYRUeQmjZoz/zg677nzwKt8ppjuK0haF+v3ek\n",
       "0VT1mFh7XZ24MVnl2UBcIAlE/A/b2wEUpP4ciB2gZmzeaXXV7wIy7hqo8Al1hXvJ7W35RNEY9AtQ\n",
       "ziF3G6aXAVBZDCS9CQKv/5GkcOS2XXQ0TI3LzuEYmVAYs0Z+CFUBGu2XE/4gv3hltXCbHDDeOMT/\n",
       "b3Ab7SCnBvoKCxm8mMvSJK0Cv5gUH1jUXgQDxOpi3YXqRTCu9PeLZ+HZXDr1VE3aKUUhCMcG9x5a\n",
       "o7KUjafD/8Kf+ui4Zt4XAaFuN8AXuOWvr7z3/mFiEN5+67nly59gLXvIG8GhAvsqmKJReWl6ZEDb\n",
       "MPHpQNnUHcYR4xVpx5IBU7UunH/Veurr8iKm41N7KxTtMqj4TAae8g3+kk5ycovoq+/J2PqJexpa\n",
       "SQejSn3ycP9yrpEI4fYRthnGnI/23BKA1FKSHMdUugx6b2xEFd1OWvOxci4f+HuN4fpfiBPsoQf5\n",
       "UBfq6IBMW5pOYpZoxBA+jfuvbVRR5ZAiCtn+Oq286Iu+HgLaoXZKsA1gZn826FKJEmzsgif3+VD/\n",
       "QMR90Ax+KqCUrI+iM88m6OXG/2J3D/W2ul6w76JntwCud63sQUFBh7KntjPvHONjO6pjTyFUr0QU\n",
       "mtSk+fEX6ZxxtxtQ58n1RDtKUqjua5TEfgoUojqZV5vELGhlrbg5y5Gxj4y3sRQT5TlTBfSCuirY\n",
       "eioGq7+uy5d0ziaksZCHB19JcBuIJqdjOqgIDXyc1MGcilG9bc55LUd+myfenmDPq7z8Dug0G0QA\n",
       "y0onl9+4FewOEThqA8TvZiLdq7br89RWFRUX/LbJwaecy/jQd3U+PiRIjg9JA03kgjpcO3ALrkJd\n",
       "s3h2qMgYsj/lJs4ZJfDM5uximWkAWz+6PT2KWQzjo0OPe3aQOSVJPQ9moubZfMgdVgHbm0w7TZNn\n",
       "x3vsWkl//2Tbr5OM81Uyb8UhWO2zNu6aGyh+jhqo9PZy+0kqY/+r72J+iCofP1OP7g2iKNt0xY19\n",
       "qrKuYIxBopJnVdXdnyYFIKQVmW07WoPzizG/a7sVJNwbUvsmmcoArRJkda54xfQPfc1a58ZkuWOp\n",
       "rgkXyGs2/FHgYLCQA5YRK+vJ9lyMJhIIhXXU7FN+VhHcI50G9Kda7WTqoBrFi0iDI+URk/isjz9R\n",
       "ro+6DZrQD2Iit+8zFMWefnyoOb+HGFQ8flF5/f0nK7psZW0y+/o9pgOJWEXu+sh5DFkYM5kzlhYQ\n",
       "fiIi54hzEymNNgI66cr75ipPBCoKgmO+dyrjtf/aI9jhwapQEbiZg/81ar2TO/71VQ+RWhM/OS1O\n",
       "TfkRBBa0HSzTm1VpoYp+wf5nyi5smuMQcHlS28kO8sWNVQmU1pt+e99BWl8SJKuz+8srOsNmBesd\n",
       "NdKzmBMGpsst5e3frmuR/3EGHLk1eRsU4CYw0cq227oc9KgRxKfeZDI5ZApUgzCie5y+8OrNW4Bt\n",
       "n9FxLnTMCRRwo9V3GsssieCmKwsCzraWuzfZxCJk5H3KsSp2CPXUb16I6AwOGbANBKa7B8ULSxZv\n",
       "0uL0qhp3tDlSL0Fd7QKXhHAgltwTPWPZcNSkMQ4hdBYjD9lX9dlcGJ9spSkDAUT1oVy5ttdvOevi\n",
       "hiXyDX4HsfyIMq2o11M7wqf4iVxjz1wdpLslpAA0stwez4SUEuJmBQSKMfZ+WxunlT2JXmM66Hew\n",
       "jG3MHNvZaBJskJosV85VsGILsRoVQ2ZbIXeARcfRXDDYeFwZjRtc6spOmpvArnDvcXxdVCHH+XbF\n",
       "QZs3soLBMLS5dkjbuh4495NBgrwUuOoeunzmudsU8CNFDcZOPi+4UImsl1N07/XhkFXqSnkou4zB\n",
       "56Fytdv3tAQKgbKv50IQWEfU0aLIXox5bPH/m99eVVjGSe9RgmbB4wLpmEGUWKqEu6cJsUV5AbMm\n",
       "se78bSqhFTqtjrndFfNBIcK0GkwfpEm1q1YBSdek4UVRQbO1hpn/PWW/YWxHTcSuBsK4dv50/g/3\n",
       "WD0xkMg9eCkE7Chb4qnEZlgu7DLdm92FtM5ZhZe9d7YYBntvHvKi6y+LbIgMRojE+CDmcNDn/wQ9\n",
       "hSO+Z21tZf4p4RJHasJ61fq6HCw+61hsD5TK8mX99YmXcMsxisDOxKfuEUTBjmLel0IKkz7x/gaW\n",
       "SzBDbLbp6ZJdJlGGpRXDfxdA+LRCIfxzexxomk7tU/l+Tk5dr1VgX3MR1uYBCdAWp5sYoAyAlib7\n",
       "qQJ8kfhRkgy2pUIAD06gpxxjnlIZh4g0PnVuY6KWQrcKWadVDUGG2PBFtYT6xSAxhgs0iPoZ2OZ/\n",
       "FTRNP/znci4NWdfrY/pNTjX6DpDR64G/5k2B8SoR30XetzcYQhIFIiyBAsNTB6YQaRNZAeBN/TXY\n",
       "3jfT4bD5eOuTyzYYFthg2W3yjvf3yPRgN9eoI/xpaGn/BNi5+H2UmhTxL1ItPOKFuH+H/8akR1nE\n",
       "ym4K9w6YjfB9QwDPAuVwMEyg+z4I6T0SmoWQFyHeerwmfXLl/QMpVde9wyqGC0AZSUafYAzCoInW\n",
       "lwYYCHfcqB5CezRQxMm7JHG0QV0nfKNc6ilvxsv/o3466a496r89xJj/IWuakymx/qEHwTWo4dEi\n",
       "8VMN33KqL+MJ4T/BU0Ud4+nvpdN1Ryrhu73WnKRqBW3DKJR96Cpv1yX6pf+Xm9iDl56ybV6hGOgy\n",
       "1APhZo805oHfXHhTKEporOoTBeF36xE19nVSkOSNK2HloIvd5H10AmE5Adajxxh0nxXCYxHDN/UU\n",
       "4ETNv+4nvSEbDgs9ai+hKYWy5PZDx9D05Qe/O/5c7W6zdBc41D0SOXd9smlM5Oq81xa1H0ejB425\n",
       "DeSwWkX4AnFmBuy8X6o+h/VKT3H5wWpWfm+MczGJ0psnDcNk+3sqzjeHCfY70eHi49ASRA21lESt\n",
       "WhffFZEqr1Qjz5tTsUAZ+rUZmnLEMhfjzR7KFfUXKEc1hKpPks4uG29bhQsFTtAfzpPmL2kL1HXY\n",
       "jyoGlRozpUyi4TonQnUTair/T6HiRA4WSckWAXJLaj7s2Udlnz8+ShESFpf0qVr76X6cmJ3oJM4T\n",
       "JWxexU8UiRKaFezQhhGye06KF9oYQguMnnV5mzjpHUVgr0aISFC+97HxkdKCLaJugVPIYZRFL2fW\n",
       "hr5Lvr5FHft3huIo0o5t7W3GvvlMh3qQme48EBxmAwcQT5Ypza8MlyEWNCeLRtaqgay2ez41pZgF\n",
       "//gC7dYON/rj44CAWwEvsf9Zrh8UWf+akMbZiujg3Yi54jIbYfikmIdiOG2Y49/JvxEEd7jFdb1d\n",
       "19s7Pns2W5IaEErSHrbjPav7sVwpo/ZTzdgO60oDhVEYgryFi4IwdK891GDluqIfSWqUQrtdQOkw\n",
       "YdZv667yJewhUdORmsM8gQ5qw7gsGbzzcnViApZ1FmEHG1Jlh0pKI1BXzMQAsYy3mYM9jzTKMZbo\n",
       "E1rI0cgyMd4DxM7kI5Z5Osd5vWeQ9hw+9EXEjHOgonWwOJ7nxWW+lV6kl3XNrEyGpNgZA4PO/8PO\n",
       "sYt21IR2Cx51Jf6bfTP9+gXF4LMepwjiuMVd0/arPvAQhb/E/6JdfZLcWc8fQwitY92ery02qHP5\n",
       "KT47zAk4Pq6YZGxj03uP1pkMA5010jZGywaHJ9Yt6MKi7EjFA+bCZmWvoWlEUJuP/iKIrSuxDs2v\n",
       "lEOMlyldH8YPyB46onEMZx2BPpsIVTqI11jI5DrnEYS8447UJOM3682RFo+8TT/6+mqf+dQnn9Rz\n",
       "fQxwsQmdnIhKVv1lVNh/Ut8L37ZOU+PYPC2bPkNEDTBz/vevTrA4QwjuKZl2q2j9b0vVH9v+G6FA\n",
       "eSHMRK0IQCiPb0Tbd56eiX4+4tU90KckioEYOLgsIpTntS4+O/PJe6deiCwTBScY43ESZF3fuFYf\n",
       "FtOxRi/hk3L6P0I4R4EYzF0bW0cNpx80rDXGydi97ZQgNhB5Z2nJ3GKlhWDwNgJpbjpIR9+q1cLu\n",
       "zyV0jSlc5ulUcpUhhYKxYuGvUTo9enT9imBnTuX+fCcf6nvYHe8bE8zpXtZvy5sd4eb25sE6EP7F\n",
       "7u5Swf8M0P1/CZHIvT5X4QCu6cxU1Hvi2hJyoJa6shu+ra43brXyAKkY89THWVMiIW8D5VSg0xRT\n",
       "lWMDBH78fjTi3TlfmTcIVasYGjbvVNmoEe2iSMCpWKLxNOkYKtTYBt3MNDkXrEhIdbd951uxJ7nk\n",
       "jWuC2LTSsHpGihRcbuyzkqrW+oWuzdxuxomRrmXazGu4yY3iC2j5dB5qHgHBMb7U15hb0M6q9KEj\n",
       "XSp/oXKcrhOWQ3aeO6W3BURZD4o95Ffmuip2hyeN9bMhTPGJuuWxK+W6VaUyF4IF0IdBolf5YA+2\n",
       "mwJH3ipRP/WPtzoMhD9MyxgVZJHEknYOrs0JvQxEAEm7aFnmj3gozIQjTISfxWaF5gAIe/6aILQF\n",
       "KF6kwxaZdCyG57sgAN24tazs0CAYu+E4Rmg4opmv7qZ2DGGv6vsO7d6Xs0chFQvzlVUsOHx5VZKd\n",
       "DyjxxAGre788FiuGrLwlsuuawzkEtLeIB6zoHssEaJ6Hso+bIGxy+tdWmKJIkiQn0Hy21vAwr4GZ\n",
       "GdeBN4ZQui8UAD3xrhxks03SqhiQwk6un3nPVQ40OfBBhtCBTyOXcN3JgLOmVrs0kMBNErcMzLk8\n",
       "QQB8bTH1MsgilTjxUKrz9A4QNckTni8vfY31VsorJii0Qiy4u29OnBY7E3w5INisb7Fx1eHlIQKt\n",
       "9lYaHaOtPeYG04LhiLy2Cm0w6n55P3FUQK2iFo64BQp15yjfZYDb5rjvcWpr+mpKzPLRTD03AVvZ\n",
       "QCwvX/5V0sj9JzpHzglWZGIBfXqz0oAsgfZ8I7LMnB6XKRtK11fc39kOIclwhH4WsRiQUAY2q+RC\n",
       "+//ryBS4O//+0/yX2f4CbMJGT0ZcA5ojJFAmRMeDnJn1cvZVD7i7U1D3Ifookt8ONKvXm7tCliW1\n",
       "G570s6/2pJm8pzl9jKid4wkXchayiXEhIb9HwlorpE33IWbiCdMrsivIT6DIO4+XZvZydJiwE/Iq\n",
       "dbIGfP8KnK4Eb+jVqH5Vn7VdQgkk0XnWm0HVGqEmnp8eIBKMqvizNPCF/LN6erbNJrS/JR1vRpkm\n",
       "dejdn0DHdz3vwmiBRjXNRcfyL/K1TaY0u4gSlaazSqbJRX8vjleC1zg1eUkGaLNRQ08wN0TurjiF\n",
       "sPg9jRY3kVlE2C939hJijZj0rVmNlu+5E/ku6XZBTwFrM/epFWQYeDFgCOOBRujJH37ekJOWNMwo\n",
       "W3M/ClV/U4A5Jv2nKM86GeP7spBJu3438BHG7CG8L9fAxWPgEpUlCoNPgXq6pDdLj8ERzHBmMmE1\n",
       "M6r8xjI5DN/7hRzB8UjaxmlAKfHZbzCzZrnlH//yObPzsjmvgGocY0U7U5DlcOSkhkm7v6nPrUx7\n",
       "S1DfLRjSyJ8/ZXI+qOv2D6lLrzwnHJkE7pFiEpnJmhlKTDP71iR/m+3Puo2DOjkDFJjpppMyS0Mb\n",
       "/x1BHzo3BmVWLCuF/6CwiULSR37Euj+H3gsmVRA7Ae78K2K2/wUXaqvEtCXE6zjiHslFEh5qIeJJ\n",
       "ISMBtHlMZ/HQb+FyG8hFFv1vQatyPeyXdiiRgap3rxDGDNBgB2Sa4BeWZ3Z7Kn4CkfKhYyzxxdwL\n",
       "W9UJJDbXVS6L93C3cxu1AH+Te5LYOckVdaJt3M/TtfyEWt22kDbKskl2yHkulJtq2u6/9SeV13rV\n",
       "UpPLzo41o7jZ7LBwoIn9js+hTcnHvTjD1PXiutrTdAtmKKNXt9rxvNNvP1WP4ccwzD2fotywx/WS\n",
       "8bksKfbdzLXpJBsEOU+7vH3Op++WgabZOduarIOTqTCe5lM2xF/G8yhcDOltbSecnnnKNUtQxE22\n",
       "+YeefHXh0iWD1zScC520H77chR7uk+amtu2/j/1SkE8Z0boZOyy+eltNEGUQte/lYOFc2DGFQf49\n",
       "cfZmkwimDgAF+21aCZiWEyHLhSSSkCjZUeCmGLcr7vE2fD4T7QLto0GW5f7BULbRaUzjOOE1F3Yi\n",
       "CKYZ+lyRBvJ62lwDy9L7Rfe7WTBb2qXii1WSgqLylV6+0NvcaT946uoSMLVVhY5sw4Dfu0xysuMr\n",
       "Mo1CwX3tPmysGqQq4nVgOhj9dTOdyZYjX+HGA0esLFJlrPjtq81+4fRks5e0hAs0/nIt4sgDB5dK\n",
       "IXnjAIpPERfflHzVRXe2H60sRBYwkKbukf7XV7R7BDFL2aDtUYDLsy5CCgp+uJmW1PAE4Gtah0sv\n",
       "q2HNYRBH24crZlcq58a/jYflc+en+S4bn7EuyW86CTT5tl7fSu673rlxTz7Vxi7qGBOh3TkGsZZA\n",
       "NvfStl05g/TA4hNncFQ8UpI5WMfZA2QsaoCtghc1qXVpV076/zSTNOyPqgZnTpDugnhpJaL3qY9b\n",
       "smwfPetZlLU0VXXWT98YvEtK3No2cJedHzUGFfIH9GelcUvjKEtYIsdPf9khcg+jywjHf3tpQ3vm\n",
       "8ARPyOv35/O1LjUuEhnDv8ZXrUQClJE9yrfV9Gac9mFcUQGGLdl8CQnwWT7TqWj2OpfyVT52JHg0\n",
       "HSNTsWShCoHY4szWdW2om7QRAT5Ji3VHQQFpPIVBKV6vdXw4r9ul/bSWKdk5/ND3GPHBqEgb7CPH\n",
       "cL2X6kVsChFjpgKduXTFF43k/ZFyqzcpA6IkxL/Yap9oAtt2zIottTaWtzUMR9CsfEdzxDlUg9yy\n",
       "X1/X7S35qAkpUThVBHKAHW8LdsDbfe4BAgs4aeSykUd//KugJ193oQXfl6EeGfC0dHv52C24XbLI\n",
       "gnbSzNGAPMPbrmgJ7iM98uiybHiZeGRBRk3REUTVE47osLg6gSUx61JFW78LcWsOzVEV/fy14QWM\n",
       "NLzWAJBEE9DoUXQEXG+lQ2Rx2orALezGWMCj1T9zdT6g+Ga5gDE+Z48E4uW9LOwe9UC4LwejSp9w\n",
       "xNan4Up/rwMtv2poRejqBchWVdERiztuOxnjGFx155t8XNgW6+eFwi3LhJnVYzOPeGSMynYZecvW\n",
       "sImTLoBYuEHCMcEm9EcuWIbn/KHE701gg4k87b8cUgoCTnk/RpaLp5zXA6Xt8bpVmJSf+iZLORhy\n",
       "wEbXGs3wZ/M5PEu8nb3Qt9VFlKSEyzmi93ZGDUla28DN2lLR8VlLpn6XKPS0Rv0HQ5KoSwC4c/MO\n",
       "6lB7/S1BrfF92Ip9OqME3UiR3zzayarwWJfG2NtQqY/MRfRsEIZNAOmyixF38WXDWa7VPF9sgMkT\n",
       "DozNvs5Vz6PIyHzz12rSWg3ljfJNks4O2JXPLdhrqSoqykE/HJ47x8eHKiAHBrOLSeluy/N89O/M\n",
       "GK99YDLaND/VnfD4ruQh/tza0g7nKGmf7+GKHoCdWKM/M1z41LOttgWzJaMQ95J6/UzKPAuvS2o/\n",
       "wkz+zJKG2YhaEupa9UQwnkLNYSpkF5AiCKHApqXpB3+YPcDLd6HPJyXce1Tfk+3m5rBaTlQI0wMu\n",
       "HN4afR9SkKAmPUIBsDiQsFv6xJm5nuaJaYYYuxfZIu2hEl/3t3lxWWJ/2t0TVx4nfDnuc2ZMDQMT\n",
       "0ZmsJ2810NTm1rBTuLjH+E60k/aQpu//VzBlPxYaEq3v5P6oaVMAIUDhOa68Vo0WKvrRgu0UIhyx\n",
       "msr3e2yFRkJ7GtOddhKOclyNCO2rbkSkLDOyX3SxqoLvK+yrqGqwupeajEiFz1ljmvqYR9fPliRX\n",
       "tGbkdcTicXnuPlH7fV23DXusznuTTJfkDnGY+q3tO3BnfgmB0UwDEeeIF0gUXt/SaEamrjOff8NZ\n",
       "CCO5DdhIWPUfYp/+iRDkDqORPgEDDBXozTg/YOfNjjFGBN1TTgTUiyz7witfylpGHmh7pMQQMzrk\n",
       "6Vxh26ov1hG6dF8XWRRzOsDuzMEQQFvM/gMhOgUm9EA71jXKX7+hp5sgxzQetrqBZfQJDDYQsv5c\n",
       "frncLXcqfNfSj25OowZ0Qaz+CO4Ybm5fVDs5CuD1m+KnW2O8uaYTX9Yjl8oaYAHLhcjXo1CfISbJ\n",
       "ifxaoCpr+55+xjTK6rJaae+IApyDpp6f9jCqPr+4dPpKDf3lUZVxyu3A7+3OoJMGKfDJCnNZvZLN\n",
       "yx3dh4+jjiqoSTi+4SR7uLKZpgpfR6aeQrVdwzicY1idl5uE2ftNj/rGK/kUNwP1PWJz9muhb5z+\n",
       "j34YV9BhHua5AisolbISRu59BolMFP3VNFow3vQDiptjRX7f+yY7QWkSVazdHCdbWXqwRJf5/Zu7\n",
       "CG5XnUaYDd4Hm+A6eUIiAc36YJiIUOOZdin51XrEh+gEP0YQWgRIj6f+rW6lczrXBP8VNg5Lbv1B\n",
       "WsfYqFx/ng49nc3zyz+8Io5AVmq2XPtiN3wrpMcq4nUV5bM+kVdDi7pIXc/diJRbNvjtM2WC2K84\n",
       "6kIKl0n9SpdebGu5f6oDNmKJIhLSH7e/AFiAz1NQjhkhrqmbkTpsmAVf0mj4aiRGtvsy1yE2QEQW\n",
       "k8crSZRN7DAOgfIgu5XfViSkg84Shxta7+VJZeuy6vTx8kgjt6RBbtqnA8RxdqlwlEBmOtTcKt5y\n",
       "jNs6WVqWt38ORHQWyIU7x3BFsePTwOvV1C9AAK1kCnL8MP/IU3nMDpRF4S8UHHR+A6hCf48UcpcA\n",
       "RbE0EWhaSfUUUy8rNPDGbc7eTkZ/WxodCNGxJEaJTRkmerbqayF0e1uvbC3CkM1rdSIi8DccVNtz\n",
       "u4KOhR0DaMAOmbaBf1D7xRPmGMN2VL7pbxbLzT/tP8Es8WtZNID3I/TYLqjqBqfDBrbWiJTcf64q\n",
       "gJCuv3zE8NhNvh4rdwP/erJYJo6ObdSKB5BjlNAwYnL4QIICKNs4qRY4K9FOCograsooCCrBvJTO\n",
       "6N99VDNihLlxjjHBFcqcuR+Y8Z8Q1KP2gwWuxa8oWorFt0rT1Kl+2ugSltle/wqq/OonMmE8mMfS\n",
       "oBWWDFEpoLExF5/rJiQpxas996YazIHMkD5g52e7DQ8388/HWc2kD8L6g/pcuLKpjOmT4Sppp1GI\n",
       "MBhpnQMFf/zcAfNShfVClrrq5ggbsj7EZwuLzLaX+3VTfvwOHmq/wIb6SZMJSEMjdXIcRSjb8VTI\n",
       "T+FNgmHFmtw7YhkupMDPtncUDSb4pifRyiovehmDl5BQOeWImb3aYmBWHIZ72pTTTqOjWH+ZCwp1\n",
       "SJjFJoe4hDtHkOAOsqSk97xKq1zQjGyY9au/sIZ/faytxVZ3vSwA53CZI7mYtlop3zkEhBSlBuWG\n",
       "KM6LHQNT8dnqY5fq9XDIcB4gIsIuSNIOrAIr6088kWGd1bRYDtXyJexgl3t32Dq5qsjT8DXxYOLe\n",
       "FL5u9dO3cLl8oEXf5VcqxI7Ik01Mp+m00F9q+U9yFTm+9SppLYWIKiv/aHUQlJg8vEC8ug7bypmC\n",
       "PHUmlgpVn6AJT91X/wXlRxJi2HVKyDm1LtTGpzls2xfKUg1RIM0cyuaHRHyNUZeGLlXcXf+bXeUO\n",
       "4BjHsSoRt5LI5kt1LFtIwLUjbFYDq5jbfd3fyVvKGzo8M6ZLsl3ABsF/uDi3XV8viOCYqgSrVhHG\n",
       "OHitBNG5qmoQ9GwmxxoResnIWE8VHaI+d++1T23ymuUzbLzo/pbwX8RvZDE4aHK15MS2VnTYiExT\n",
       "0GB9n34M8y2kYVSe20LZFXz8TaJcYjYZhNu38XDlWJi9dnEzN8UgyyOlN5hdpD/446PcxO7QJuhS\n",
       "o3kXUdAgxBsFjXypMbqyy8zt9j3gwRdk+CWxVeJy3j6gZ9ZRrMadt2GPp7iKR4tiBSbFpdsE/Jp7\n",
       "Ybz/kFfhXtJ2j3E+sVI7lMT1lssDmKjrkpYYqlzELGoKOyeGgrEVIhcDoaBagaAowMJy0yi+KqeX\n",
       "JJSnWMbCCInsQJ2ozfY2MJc4LuMognd19nq1szd+yfnPmeFrUJj547/HPynvjol51B+rLsuUyURp\n",
       "uoaR577iCTkSQU4f/93LbHG8Clt72enesU8su1BgXXipZ8dqK4/SL4MbcaT/CJFDytQdubOa2wbk\n",
       "PjLfqoec4CyZeHJMr7j3DlZfgxUQHtkEtS1K3lvfmFcDIR1Ui+a3vp7vjiQ4N3AsU1d7m8wWfruq\n",
       "3FU+K3WnEMQrNpkArO5WGsGGujHYKsaip20bBV2QOWhkrbJzpo6Sze2PCPGqtCzjjAX+0EhmmFhz\n",
       "qjeXGXMcbpF00uyGXq6EYW33SdMRv7kPVrIYzC8IHOWQAfquWMKE1vX4dpBgPbPF61q5UjiHhp0w\n",
       "TrTlsUBpMMwI0WMdxmFz1I7GYmtZZhk/WeAnxVTlX+zszrLRYDCdmTBe78+Cp/CD3Mxa+RKBe68t\n",
       "MoHc8gnjHkkxepN/Pk3+xqp9dtXR5XRfbNSK970A8JU1szGrQpAfkR8sIwNZFsgn/ByRCJTJuGYf\n",
       "j2yT6c7R9fbu8Ih1uXEWDzryalLE+cxu9N8bp3DKyIgyJgpquE5YJA5EP/nrn0eQlj4BZGFWvy/b\n",
       "hLs/YgXBRFyiG+zfkQaGKc9nvDfd/hBbtrvEjGNuxR2zVE2HSyQK9J084omvjIOIcFO2+AAGaL3s\n",
       "Yj633v9qtuzNw/KhP0kbg2MJ38ndvy7IgoTYYKE6+YiKViDLKmaNspPvXM9/gtjRJkEmblKv8Ho+\n",
       "IjE19ZYbczASqyXxuJ180Rn4OezGLTz2xE2IBJ834Q7aCy9mJOOAGBp68qi86u4W6CnwMWt+r0Ls\n",
       "yYpDgqFFhzgJ9Y268yG05/xxDtm5bloOKLFcrdgM3C2JBL4VnR82DSi+TjP9R0B7JTnADWAFIP8G\n",
       "XQhvRW/Aq0bIIt7Zgw8GkDe2fWIPJAL7jdNdznxX1x7mh1YcqatGyOuBdgezT8x5swlK8JUsNs0X\n",
       "DFjo8o/06uC79O6Z0fKW8kmapLTdEeMqNS93u60Yrnptgr7BfORCOucRbDdGjquahIQctXTlr0Zu\n",
       "eoYFw4C79QFEMZJSRBvcubRGtMO1BR3LvULm9G0kkuFUHyRfb03Nwn6p3XaiNmvaFIXJmni3SxVK\n",
       "B51n5Vbe/IAHmpSVUFdB/Kx/aoTViflt1yLNm35Y1sj1078s/7ezssBJZuOyxUstAEhi9HTXTOjK\n",
       "gSt0NaJ4NzKqqNra7w4lKCwr311Hs2I/vV8BlQMJy/aM8GVyhGNHKX3XjM4aywROfGZTaJEhzAL4\n",
       "p2lpX36RsDoZOhu1nbMZwKcYBlP8r6X6T9CzaxxfrTsU1Y6iSQnMUV9AiVOqu1rvA9AOHGFWtdxN\n",
       "5dRhBbnt6vJHfewsAdiX6GgNWPicu41oiP3EG2SUL0Z7+P93JiKAQNb8P7bf0lAdptJZF/4vamRg\n",
       "5yNt1Z+Z6e3guAqC3YhN9PmGH6Qc5pywgdROxr8+XBvgwBFQHRK0echGMPlTUdxRoG83kIfJhazO\n",
       "sao8PGNUtHd7L0Cm0HuQMBJlyih5h6pj3gxIH9Jsacdu6IrFday8f8oKxPTLq/wOEp+EEx2aAujU\n",
       "s2Vt7jL9tN24HzW4NLWCIds3OQOOEw64Y5/VY+RpSOOv2wpV7bf4N1bbV2NSRcIpmpFGt012UjsO\n",
       "zoSEHIH/QWaeD2R+XcwKUE02lq6gZg0RyahdzrslYUBtaWMA6x5DOWGkbDKDEADbIwF6u7QqpZom\n",
       "EQARts6CFDauEaqTAgg1R1jZNIhJ3AOV2WDM5J5X1NXcAWsKpsjcQwUOByVJJYhXqrHig/6qXRCD\n",
       "I0KRqDxWEFijZZJeEUXzIZhKiPjNzixQgBHTpsnc0lOnenCSJh33yHH67HhA8C9C7kO6KOJUR6px\n",
       "ZWSxy+jbUX/96CEoo5M8jP2GD0W27OCLTauvFjrE9EKKbclxKKuQoAn1Vhb2Y2F9jjovkAIve98w\n",
       "Gf4iaq1S5ne+i07ea2TYCmhjSbj4+lX6gw0DC84BS5NmnQ34bgEBfsggZ5MMgpgayQAHc9tOuc7l\n",
       "Wlv2fzgTi3hkcNkxZseFRxaMQrwDHmwUyLWIUo53xy1RqJib0xtxmov/k7gayGqN+/JCGlVJT0aW\n",
       "+zUTP4B6BL6wqiWJJVNj4C4K1P+8n8cHqX27ilLfXsrHoF641D8l3BTxq5JWzUMluBbm4yIzdcgV\n",
       "pJGn2Qnyd+ZdKG/mRi3HPd03q1QE9VxgW41bv42tQi92MeQbboiThMUqIkl9oTy+hKCi95x3/cno\n",
       "pcynf1AaaZWKfewGRAoCMH50bZbRfoDe3pXOBUFdxKZirwyzn7Y7KqDLKftwN4Ly2T9tRJi/6ESR\n",
       "XRnWqpO8Pj0Hz677/LABDiHIKDLF220S7/ZM4Q8zgJHfC4dLpspZe6zGsfc/l+jDVvXjGatpSmLU\n",
       "yzrrwbA2c/9qU/ckg2dYjA+QRSIie/hGOzIuKhs3E7NLM+Ny/dAsOxFvtr79Z+pmocwF2T2dsEou\n",
       "5vZE/ByAaS4/fnOBXWVR1jTfC/dG18Owof/RVBqAv9fkQ+B0rASCFLwHJOaFWMCAHsQNoLcmHoVm\n",
       "+fnYjh9epbDQD8E3OfQECgBn0SK6GopGfM9NwINpGOxE0bja37QEi886WZMVzRKeM0dph+Ha4JQm\n",
       "cNs8WbIUyTIrymRrA9T7xH4ibNe6HVbtgYU6Tj2vbzx+9hodbjeLa2MuXXbxB4ZXqgeYdcdhhPzv\n",
       "OH06bvn9y8vqLy7n1v5prMa+J/KSD+wUkehFk0LH7ri6Nme0T0fbtF2NF0IujUxFMQk2FE0OrBDk\n",
       "zsXJSGxl66u722VVvOCxrpy+5zewvHEdU9xkF/roUfoC4QU0zzZf7pwlpTJ0Rp7D4hfO1BHJi6ZD\n",
       "XDDpa4o7gdo5aWkkqV2FFpdaqGdatbURaubImSbp0kluuvbRLMtDX5yjJgya5UGv7EqitHxJOHe/\n",
       "jnTMOsiMkzjouzlIDWRZGJBRPkkBt1WrlJkr+TepMmvskzVF4fxC3QCOSrwb5/4b/Fukoky0dZZB\n",
       "OFtezmklx3dCEPOD2+6IdaQVwpUT+DQecSiGuNj+Q/KIwbjA8HdiY6FcJXD+kw9xekS5Tbbe3Zja\n",
       "AtVGE+XWHWnVnpd54T3aY/8+A+1E3Sbc9hRIzyIUxJk1cm9oLYEHa0K3DI7u859AzpKqIY1hhlBp\n",
       "kVv1mqr+o49x8heIROu8j+X0SqliSxSotSqk34KyXZDA16EWIRpdLNyX8DKq0Pt+TQhISronzaCT\n",
       "l9jl97KrGGk9LbpPnjJe/9AaXeGpzFpF67fSlhWq+Fuz3WsBWJa9CTVTMLe30XflNpmw9E2qIe9N\n",
       "IyYc0xjV2a3I1W+nlyRF/8al1npzJA5BGRB8jKsu/6Me60z5BtJpY65BD3bvjO44X/y1Cl5cFpa+\n",
       "Z2AM94zOkIvh75BiTekRo5MnLqJhiAU8kD6TnsRzal8Xa8cI7xMPP82AkWiexPNK27LcGLcrboIE\n",
       "2+/FNSr04WmU2u+nW7koGW0MCKM99lA8ihZa3d+9t/FhSUnArrKo6xwE4zezhoKAhnjCjFUYKzzB\n",
       "1RIoqhEHoZrtUdY1Yc7z6rzknrjxMQoI8D6sMFpgSgtvaKShPNZ1+nvyeuDXd+LMWk9YiYNolYtJ\n",
       "vxU4/HY55q5ssqU/ksvUwIsIaWtEL+cIXbFPPll2TRBaDIbRO8pDCPtYRYGwy8FyL0fujKNL5I+Z\n",
       "9ocnCL4oq2FCa7zqMIHl7AoO+94WgJQmMPpFUnB+++fwIJjWv6eG04w2iYhj2nfgOAgnKGA/bIwb\n",
       "kL083A1hYeK/gcBcKNsi0gu7yWYskzb/3iKJ7aHQtftkX0fzxf/HEStwg+UF6ZwpDZyIK+p4Ak1B\n",
       "llrk3yZfJhc8PSAuEZA/hucK7kuGhwTnrsZsu8r4W55OuVk/lxQInD3Wl4e07+L6vv59P0uFSqmY\n",
       "ZYCJ5VIfJreamVUJiYOqpxrtKnGizXLhltR7jON7qXqntrW4b26BK3FEkDwSJL2icsvDHjCn37yP\n",
       "K/NLq/sWjZbpm95Js1H/aNFm8yUn6UQ1FKxyt53lKI0VcEgPkzw8oiI228kdVwkqvDYxDP1A6dFf\n",
       "sE4QYsO6inb8/7XcivDDqzscdeplMlmXjn3jPo7Vq1sfo1S3JBJmQyE2OpmgiBcm6H0S7g950lPy\n",
       "6d8oeVLcOEEFwCDgB4uZCS+1H3xH1XG4wTk6L+zDzwcjDa2q/aZtLlxs3PohPZHjYjdCMmSBt0sM\n",
       "gjRp8lQUJI2IH//TSgEvTZYYMHUSfPtfBQFCzcad5taW7K0y26dFmRdR+FORbswB4j2+oLgjxN9w\n",
       "yG1zxkS+aMSXj4gt77P3TYHUVuSn4mlIyx9gJGXl49ajWEUVVykXoD+YSpT7fgKatKRs6mfR2V7z\n",
       "0nHbjmfOygCnwkAiscJI6g8mDL4QDx5QtMe8c8oVAnSbK7o+YHqYB3QbkJBjHHp8d6HluKNvZjFB\n",
       "3cBBWnaQctwlIroD66IRBrO9sCt/HgA7H1Cbu9dKOADJN9DMxNCRQNYkBzZI/3Bld5Lx3EgnXAEv\n",
       "sO+fPVyvYFaWj4yg2cp7HWbjc2bw1y7m9SCQke0N/Tw/Ahbf3dxTrixXyuSBz7qSIRVRlKZD3tL8\n",
       "wFbrnzVaxBlpmhLn3KA2y+wO31kBXdA6gBHWeoB98IRkdr62Aa2V3eNAIkknZ71k25CtN6ud1hUC\n",
       "1AabbrtSNO4H1xKe11K0zaNYXH8i63IERH6NEYRtAKe/2fWLnX9z6qQtcQUYrWjF+f4wprtd1F1Z\n",
       "17Gu+zu81MAUZshIo/F8LZBrtVKFmxJKRnrNlefsBv13AquSHWXR8froCFJmLieIWB0kJAuv2t5i\n",
       "Nd9SgZiR7bqa9mehazn4lRgrfdT9F/daqh/cIlDjdgxyXnqtS7t4HwdPj2W9CCkb6cHDXk0cQRu3\n",
       "mGl6zA2VHeuGUaPVOQELw3HU4tEfHPniGtLsO49uGb+Le/fXmd5pGpP2sPQuYnZCuFk7kG5mnaOU\n",
       "aD20yetQQzcDBDIm+EhZqmLh1AKd0k3MV0+oxLxHVUwZRDTHDKibKg0ZNCLugqmkaywm0IrPTDcv\n",
       "TlJPd8OhX39+0bDOrs+qrTeJyxXoRzirzEW7FCLy+OWekSgZCdSV00UNu0ua2ybyTTbkuR22LmhG\n",
       "w4XalZp1tGPeGf6tM4JamzbYY6gJ7uEz7Z07CZybJmtjaW5lpu2KRzbSZxpRLytD8Xr052PFmgR0\n",
       "hp/yFNB/bsEEHdFfkP1pY5CckTn2dzM4myeZ1xtdYN4V6eupG8/5PI/sH9tRDthK1McNgCuK0YeB\n",
       "mxUCD175OaibjofehMtRnfiuKkwzb3Z0nfEVWeOyMbdjjg3YHTHp8U8VrglT1BpmAyI/IP2btquT\n",
       "pImy5s16duItKnRU7N/60MDQdi4H/aco8bSchakHSJv5P6BCg0OOnFzLZXooYOry2x8YdjinxICs\n",
       "2ecqPP1jBWQJhzCV25xDAM47tkpQUxKmQJmMw0sCu/ZJs362/pdrpwVN/2CwMztyZ0+hFGAX5TVE\n",
       "TVlhTOth6xb31RgeoRhd+rQwJvbsJ0tJk9L6Jy/5SfCPfKIPE/0DCt9nXaV95EHJK8YxvQzXao6x\n",
       "nbx92U24ZonGN2IQQi4DW5hjIdbrUZNqGCSxwEmOYNvlZxnW82hnLXq78KyREWcl8zj/UmdeXG0W\n",
       "HHSZWI7mbC2CIjOAVz+UWBTu0Y12B6v6p49intHG2y1Slg5EstMAKRvgDHDUwTkiuWhdGU1Vp0kR\n",
       "cdyo1fXeGUcEXFcaQNOkQu4tty9Sm2LIShX7UaO23t2mCmkJ6azdrfGoZ9QQifM0AedzCXWoRKdV\n",
       "rQhyeICRrObK4kf3ytNcQ3o7AbsB69/glU27H9WrIv5QXkNdBp+cu0uH5Vpwp0av/iHxJlDZwcoD\n",
       "LS0BkdrXWq6wI+bSuUMmWkWGuZeP0tL6SC5olbSeOIdU1tdMB8pOXucf21SzJiAqpcpCvmfzkUDq\n",
       "nU6YCjMHL793UY7NMzQ1ZfLqgRChiqYeUN6/B5e+ibXETDWIgtE0on2kFecfCkrbBvcP31EKQg85\n",
       "eZGwrLSge0r90hAettuSMBvNx7g0W7SAZ2ri/vElbgLENWgYueTSkoKBf2/F5x3vlMMqf8e6tXOm\n",
       "0a+O/lNTao8Jnwtk9zbP4DEirPbkh7ly9ifAjmJ3GUK+t16eFlkXsz0DK+Wz2pAxrpgmQyK4ZQis\n",
       "v1AKHRqwow9ED9QIErfDp8D10Z2vgVaMABEjaN2k5F3zJQ9qH7nLkmu/C4hOFq212qbBPyNuoQPD\n",
       "9AkM3ad6SddF1SsnpbtYfNk6hfBOG6EbinoCob5p6ktBKD8+iOSuyqvASaxdSDPGZceh1OBXDu0U\n",
       "M0C5F1c25Nem/rS0WRr8pwaUAFzO1Y8g0fJHWFPgWkzOlu4IssH3tb8jKBUA7WeB4aCoqOKKpWpm\n",
       "V4qiWPeLviF7/fGT1kOkZg4Ih47w5zbU2I+3NQsrYQGJFTykUIhEYdEIhSKWY5PdrUk3Hz9k6vLO\n",
       "dKJalfyZdMqx4AzWYGWe4mhpCcbHnt6DJFStqxywSa/naRsiBX5364or3E4XGVNicCf4g6Xip6cC\n",
       "XgwCtEMuT+f9BT7Afg/Z14wbbLLJr2Cjv0gejY4AdYH/jm0di/8c7MFd+09/t8TnVsnRDs4ZUf12\n",
       "SmhiFOl4KoVXgKmSV2FIrljSdxp+6ynXYhodJIfzfAoUav3foGmZzPh+PzjBlVfjpYS/B8OtJ2lu\n",
       "7hv8N5LIL5hQeqQmvKKZ+38fq/rBfrH3NY+StM80f/8vt4cqa6dVBiCHqZ4yDSM7S7n1Q0/E3oe6\n",
       "HEltuJ28ftur/4Us0n+zq1ZGwObK/2ZIndvRQkg7BQ5A/8X1kXeUceRC0m0OXBoXf8eltNEACfs6\n",
       "KydWAHUsFuuBoGiENDXSMGSlxJk4xhDHzgfqSgz8iFXU5NAQ19NTK6dvQcHmbZMifMZkx/7Iw/JJ\n",
       "1ijkQiFIZGBb1bnOTMfiJI2s2EqE9cqypKN9cQ+0pniYYAqIX5Qz1xkJ2ELf+qqSGti9kbLO+jEe\n",
       "+Dl5k3I7e3uKXE4EkSPUIM+nfrUQYPctO892RdLM6oir2ABnvpSVnp0OTE7ZZU3A+ewEsRBUICxH\n",
       "Aso8lspW2DeAaX1bQyd4GmVUh+CJck9ak09DwSUEAAAVV0GeQniCnwANjaJ5M0cAAndTInFkTV5U\n",
       "5rFwmt84TPruK/JShKX3sy6J70IzAUxB9sjHhGCC1GD5djUOg72Xs5yhpvDfrvqbgSb1jycxNyC+\n",
       "EQIbyfK3njoa34bKbFr8yaFz13+dM4uqwEbvK53HJ4zkdICAwtOoAAC3XOXjddaJE57xWbIOvWPi\n",
       "88gfRxAQ9djdRdX20NgHfq6WuSLvxNQFXdyiauDedE/FL79D+XqzdRfhx1RJtpds0X7M7V45HpUn\n",
       "b67EK4BMbfzMET22alEPHZyrwPQ2//RSFquGl9hT1BE5FkBtX64UOOmhX43ogUzkv1HWtYH2kc/6\n",
       "aGl2O6rA9yXh1lCGOLrf09jQDH+m2fh5oXUzoq5SIEX7rvlZZqMXRTBDdN32HMG1shruvSOg51Y4\n",
       "UvpnHWf6Vhxsb1Qx4NkSP5HdD7ZrEId8TyjubKIhZmvSTtKVme4ty1sCbk3qelCCq08fCzJeRhq6\n",
       "aQNC2mWmpuSIiRhLaGcjIR1L2eSRX8kYRkVOSNWvnJKX9NQs0sxvV0E7q+XgsaaW4+csyzt3MI/D\n",
       "WKvoraYpQYxrGRpz1/QIcWcsLsrJ7BQuxBpPBQKsBLv0228ECvsX2QOBCHc98yfb8m1A/5DwnzSY\n",
       "ctNXEHcGxsdRcnScwlRTcfWDeOQzuhW1w1kSeknHfFGIIX0mNEhaleN/9OhBrdGBY8jKKhMIKo4v\n",
       "C+k1L/AbS1qP0z47oHKkCQs+CHeItnIYf1wPSq5RS2WQbEcNIQOPeSL1qg8YFWDZx80kQyKP5w0X\n",
       "j6r16fQghARHjDkbT0eqXmBlq7sSXm0StQ2nmtKqKHn2MZI1nI5zd4Sb6NZwYoZ8x3arX+K6TOKT\n",
       "5IE2Tl5O1cyIgRn0ERIUz3NAEKadEqVyKeTfbEVEgrqzUaXEBt/YvxlL3NP09pESy0iIFj0tfPm0\n",
       "vr7WA9CQ6psMorb9mff1qp0Aqpoi/vxdZdd/wqUEdasOZeTnCh0F8qz7EvnGbg7vxO9iDQPc6NR/\n",
       "WyivlzNaSfNneMdZHRGgJFDm6DcB4j7Q4b6LC5ASzKUZTLg0H9ZNPOIYjRdV5mqMIjSfC+0ulON+\n",
       "0WrN6tmgkYT5233WqNveAhwwRl6X96OouJ365OglA2BlOL+4CzDUqqi7/g53WIWvBhMwX5mHgGkU\n",
       "ZRlqIZWn10FeApUeeXWwVeh5c2ZVTJAheUMWRjDuFqxyXrjg3cBokjSmzSxJOsPWyBuzxKcUUqC0\n",
       "oHRd63PotmGvN6Kc/Xxc1arSa6BIQ8fiv/SW+xXJ7DsTSKewy3Vs9OIoeuMYyEnLduD7QBB/UCv6\n",
       "ltmKkLNkp9E5HKS1GAibDpW5QyBqwXmg8E0XWxoxHcE0vZcW1y0v/ZRRspRyc/rsRHB/CrJsC2ML\n",
       "9Zkv7QZkPs4VEaMGykNVULcvl+jtjc0IxWo89MrBeAj++/OWbC3rOhsBsK/XFEf4RM9A5juat4c9\n",
       "gzq8Lm+7qENARM6ngE1URQOwlVYFHJvCkG7BRIrpR+eoutNKx+Vn6HYOD8ba91xp5CL7KgiU3grq\n",
       "5qwIH0m6QwCRGKgetzbsJRpRtvpkkjIrapsX1TeQYs9lWgffNMLUYdbSdJ2egX7oOJF3IHD+0MbZ\n",
       "MpkZFhBZa/eo5JbB8+Kzx2pd8zCzbi0FmFsDlqXE5lGrbo08g6fULwynx0c41oNLNsmC3Pf1ce6x\n",
       "390vC/NkLnLPChCGOAAbVmDt1AbFd6CcVy7LD/7xNTcX1tBykH4cVdFvhYvYa1N2Pi47Pem1aFFu\n",
       "4QHwkq99xAWfVk0fnDSO7F4ZiiO5HlNFFX2nH2CF4QoxQbR+9GiNo3X3nlCPu6ZDnnBwdZuUkOse\n",
       "S0s07MaFNVRAvShecsM6No1rD0TWHU1HGYWfV14XIezYCefrGEBig05lhXe76g7b4RcxoC/5YXkx\n",
       "q4FMfreRIrNznfgSOn2saiiWUV+x9H+CoJWEMNjd2pBtlL4jLFGUsmb/n/8kC/w4K3pLdsfc/KOM\n",
       "Vp99I2OR6hMNu+di+LkVZJcE5uIvvUutPqy8sg5EAqZUFwTd3xgMbQ1Mh6/0vlzlPQcB2JZRc6FP\n",
       "Aqd7okZLo4cg/4R06f+6sMMwHMdplVLv4gCsMTRuHjrUZekH5vZXchVYWjSe2e0EmhniJt+D9o1g\n",
       "l40DDSkWo9a7/6V/oeeefAX6tw75fZIYYxmca99c+5VJk2TiqMUvXSe3iASd0oXrqVM5GqfgeRi7\n",
       "J0bMJ21QhL1PCcBWox+clDDgQA1B+B2ew8AI61op2PVGgyg7lnPrX1x3Z+VyzvP//Bz1ripPKbR4\n",
       "fkBmpaWvW8bAVlMLDOlRi1K8cVM3IyjVf+9wQxqJni+j12uCZSQh447S1v+JAA9A8N67BsA5sCUq\n",
       "Mf/VHejAVcZpjgvSeewJKMFC+7sLnMnn6BZwwMCKOboLPBM9KXjrGSU4zwT1Rpv+5GsrM2OHo6GL\n",
       "llmaL5OEZS1LYiDQQbv9gJSzBZDhO3iBkmhbkskYYQNlKxPwHyjpu+6MMFYU9VDWtTPT9uPoC4iK\n",
       "VKl5zUUtC9rgTiWwR7D1JPryLYVzjseNETUcww+F/AccuQefvykYmdcDKsG6WubUB4QZlVyzMQ3k\n",
       "UScFgpEFBdUJsMZ0LJPhZHytmafbejjyzaIL5zuOnRs/Lpi1BaTgVclB841g/u9ne5BtZpPXrrAv\n",
       "ANmzLv5Y21UItnGE6VMJ0JZ4HBlM0daWonEA2VF4rsi82CcouJm7obo22vgcEFH0aqAtAGsbIJv9\n",
       "h9zZYKvCVq2x/mXwZwHEYLgL16FwtegUEFbNOCegDM6S/X6QtN+d0yMDuWlx0Xc3hTu/Xp7QGpcO\n",
       "1FZ/B/MFscJVE6J1nSkDYWoXi1urit8c/lbA9Fsvb1ZyWlj2a+yrZ2DMRe4C3aOkoqmeNGs/JfbF\n",
       "s6IXTGhgtHCt6y/dCw1LisRIEMfaxOHpbelGxeu6tZoulPP/IUvwMd5SfyKpLsRAsgN/+pxHvwB6\n",
       "FZYCGC5+V/L/7Az1vJVU0z0SV/yezFnUy0IF89x4FJ1eLk8scGaRjWw1zfpKU5hD+Kx8LWPbmeI0\n",
       "jqJ4IuRiFPPGEbRMjxbAFHlIuO10t6uuvYhO1b56I3+A82W60erezubo0S/Xokvfm/zGklWzVZZY\n",
       "AFeAWcrjt/dpOgqxPHdDR/cJNwO1dNe0CTwj9tosBYJKQ7Bn2Wy9LZDMEhXP6D9+ToLhLUa3ozTn\n",
       "2YTqfThgqjO2WFVG4E+PYnvyXAhPX43CIU1kpt/2xJTPLNfhi2jlKCG+joiAlZXd39pp/Qlj74Za\n",
       "7+8M6gM8bc8lP6jEq3d5kZCSSflIVkmC+Hrx5xj+cYU5fWNWdWKDUbQxS7lORFogQ+TmGR9UYk/e\n",
       "5tVDGWG83YnWQp5Bfa7LR/kf+cqarZ/YJbtZ6ykRbOVj0P19hdyQ0eMxmrKXoATu/117hegodqOS\n",
       "LGQ/HWWtuxBwUZA9/XIbCSfOUVbC/iXJstEiwRJyIQ8QykKTfGnTOvBiYQREwCU2ZaakYJzJ68xX\n",
       "1Zw2lWjJ1ERK/AkKfiuyJEPvU/fTJau2YjFvDj5BNEJOIpMKaowensG87EbwK3+kPhnNCeMOPNuh\n",
       "/vBXNtFxQdJbLrXbiA2gxLpIGuCTSl0KdtwgTFd4Lo3YYfyOkEy3rL+PVfA4G+LEz4vVxAizgdvM\n",
       "qmg4tnW6p/Sk5JMacl8H0W/wDgy/XTZ5nu7vBgDRn3k5y5jkzoBj2QZ6X0M86oz7KYR2yVdtROVu\n",
       "qPdsPWqSFY8B3DtKNB1Ln/OtkjnDidGPeXrYyLNUWOvIIAbZ1uEtOV1QawGTda5/SfGKzuJizows\n",
       "5RR2wzzfQNudkh2qTjuKEIEunFlAfw9AWRG64d5qz7sE8dLhtugBR3Vn1kVQey713FHkHLhD+jdR\n",
       "FI7hwGRrXa8WWcMaHIbT0XDBi7Q9rHHA3EeefgTLILI2ZVRIlQV4U4/nYg4PWz0baeB14JtXHoVC\n",
       "QXjUJbrej0/j8CVwrMwsq/WffJXZJJD6cqunAK+obc4W8aQjbID4oL8wvhpQrN9W/+4QHgwP3srV\n",
       "PsCTClyun2IJKq25XvjL+0i0xNaC1o8oFBCsTXUoA1rMBZMoj1+f6wgh6BKkhzJZRUpLiaJ3iSyJ\n",
       "NWGfanu2XctsYDPRr8jA4cD5OVa0Y3JZ7aXZQItzhr4C5AwOolLfUWvZvEbenaf+HxuCQArV6fSk\n",
       "FvMZvCo101SL8JiVM6RHh/Q/SwwkAdmWcKD1FV02fNMAaR/918gB+N8ZKyPytWveG0fIlHYe27HU\n",
       "LFRBE/EZWMAmyDAJCJ3TvmH0HDsSu9/VSsYlDCUvRGCWo0eqpszbi5ZFV1Mxsv5K4Lqy+ksVKlm4\n",
       "eFZRI67ZLE04siC36SyFZFEQoohe+SXWWt1QOsBSvksBiaC6daKhd3JoAeNQjDB+eoxfhwVHiC2D\n",
       "OgGPsGRKMvv1pepuV4YjTdL659MSuIcMYfJ2AYGs6HxKwepe80M6P8rKIU2PpF4PDDjelXbBFg1K\n",
       "qRpjAOew4qqfqS7DV2wwzlNZL/x3l9EY7tMtYsdVmAdouDTsYPf+h2a0kpBhidgtXdgNeqL4qSTs\n",
       "UQ0wnar1IwSsuvL72cj2aaAByONUZ2+BW2qGunC0c+8mPLU/fBbrPS1GHexo2X8FZ9jrokWsZFMZ\n",
       "zFyiKK7i8K2ACEO4Pf67WxDxsh3VvircC2UD7FviVdFLC+0h2c1kQs5Jyz142Vn8vlDxPdtw6ABf\n",
       "fmS6TXjVLfdnvRhDruKju0UY9m/+Bvkvj/Si2m3dg51P8h3BdpfyiAYFON5UHae30ryk7q6DuxwC\n",
       "V81eLIjU0V88uW3oShWLZ9I41S1lAXxzWaA4UcPn8E7B7R0+VfGjkv5CHM98FuMe+cEqSPlCni/e\n",
       "eU3qPNZ4MjuFn5FeSryGwgHG6I8L7y9OXtemiKspYQmqH2ID7LLkZyQuthFLgX2dlOfOLHKy2hli\n",
       "DyT1hOsK3n7d+BWX968jRCnuCvFIYo6T3isLCIqLVUdfXRygI+S8LUX0OjfV8ZEPoYcljyhyhKrt\n",
       "gyNQITdMRzSRjKtMMTLpe6Vzt0k1cu4pg38RJfK8wDFXynn/d8i7VKYSQThNHvf7anFz/Q+B3ejv\n",
       "FTmdEdbUhn4xrvwsOiWxdlbh3N5b3TTLrmBvhKVbnoXHHQJi/PnZlwzS3rd2HVChzUUoQQXxNGQj\n",
       "gAwk/3cQPtM6a0ImHo+ugDxJ/iVm8XHDVur1DrZ4QhHFVOmTh+aiko98OBB+UkBMjzW5GA6RECFX\n",
       "Q86dS/z1E5YNsdErXJ+Yky3/Rzv8UhpbyOnMMPFtvqOnlZ9IyZ0rjHovyT/a3kTGKdE8ZQA5nmL8\n",
       "acTwG2PHsf3HIdUcPR6z1afq4fFnE1ZtshCMYAaNDaOx/jyzCcxQHAWPlyA8cpGNrcLafKSTXHg4\n",
       "cWEEXOSIMiZkfA6VSqJhPtf5O6NvUbRDCoNLLmDJosr0KhdVzwaEx5SjVWemyAYbvAKG0GKhlVnA\n",
       "XwbW5+aAvkaiQCx18IEDD5DanW85P+sI13ZUN3Osyg60BJkV2X6lZZ+VrzvhELnrbSYf0jYnFa8y\n",
       "2rGarY33VNKXJBzyOwIEzdzlHViyvbftgxO6GkH5B6p29kabs8mleMgmM20Dk5hJQPHLdnzhxkoj\n",
       "zcxK4NtfEtPbYFPJ3bnOtVqoDWnJszGnuPr8SOOYyT2BNaPhAkAh77OQ2UyrUcBqsH+Vv7/+z5mu\n",
       "dHCFsU2ryz+eR2T2G2ebIX+eMl9SoogwBuJ1fR544gbVV8Tq7GUZUROT5z/3l5qcIjSTN+fFEMHe\n",
       "/FJoWOZbKnsMh51zDWxPJT8PKz29H1z5uR/VKtoWz8XF6stnbFVEnW829m4w7Tk2vV6RIkQwBj+d\n",
       "3/lkbUNNzdQ+w4Luv4Vb1XwDFkoENGdn/LVtwxmOUnot9FgOFNxAUML9YzD5wSXAvWpvRn2Xlc0h\n",
       "9ORsnRvxHBNU202UtEppXUQMd6ekUv72HiCBJIkCkP52f2eFdOMYd7FO4QZw/snU1/1W9TLcjmy8\n",
       "NYS/xUNmscYFk7+qctrMnGlwE1Un26DL0Dtcl5DELM/of0sK6jkcGb7cDq3ClDMsuwbf9bAkYpRh\n",
       "JBc6tdODAaPHmGfY89IHU8Oz2RD+mGPoSp1gBPvl9oE24Q8paXoAMSYEwYbFiyBtEthm1Kullbex\n",
       "MnumqOunzafe7JLzL+mce5/Qe1RdBpuKoPq5qL80DoEtZTX+889QpWvKpYoSN1TTMg40sWSrHLjW\n",
       "qjDqpXpEMVjmLrAIF9PQ863iQftLr9bWxCmA6X8GQ9CTAeHWWBaiIAx3SAePQFfCc48+uEGisCYJ\n",
       "KOGtcg8Rsgt7DY3ax2CA5fgJBPzAiET5+GRxzqlLaI+aCoI5LVOci+5RVL7P9OqCv7qH3KMDQfig\n",
       "RCU3+e4N4vgXCRdGm+3x76dnJMAHH0oTPC5TVUx/M/InVotTZmF5psJ5pXgQpbtis1N4CqO0wlLg\n",
       "lBjgmRp34v90P2o8Hklcz+bTcfTeO4RPHEqKXFA8Tjb6ijVvzG3pNgYCu1Q4h5IWxn8oiak0J9az\n",
       "n6v8xxi2ZOw1geJ03Q7w0zb5rmRMf3FF0WqIsfxM7+H8RqTFSzYbSy1P1xgqDFfe6+NJTyoQgTxm\n",
       "3zzNE2wF5LIrK+i7pwPu9its5oreshHUovGFgAQZa68RX9V/yH+gsXZ/OI9ayV50fIsLdQr1dHhw\n",
       "XrUevitwyqNmM3I1ek8GpzpOA4+EnSZp1bexeYPxINufelUnkT1yAT7mt+48yY6imFVMk0sugNo+\n",
       "dbEy3qoDQyUjCs5QCWkQ40W76ssV4u57V8Qe94S8ALXBQHDOO+yAs8xRAByhKD4eP/sAhtp/7yeX\n",
       "0mRWwgQkWmkUOxHWck1gPrjEO1grRDC8Pc9RqoP5TtvvXKLPYezqgIHTC2knhxgQpo/O1O3zuUSy\n",
       "FLwJr2lN5XgpHHZa1mf+daWX7p5gM0g8qstSHl873s9DgHEdDCuaI+PNJ+Q0DDIeCT6owhUtj2QX\n",
       "1TCPXtuITztwuqK0SSsTF9OAwGg/d+3mMR4moNfM81BGFOzC81r+VWaxW3oK0ZApB1NiV39UhpB9\n",
       "eyQv223cVpp3op4v5CxxFBYnMTLNQCEUeZ9z9EUV9MGpxbeNHDOyvNuhQeae6IKaQ9RBMgC0/Ac0\n",
       "ZDnxc/+8hFXxZAoNB9iRbuxm/OgSTO7B9zZ7Yhom7Vp7T1IqtAfV4jj/Fa+1RTphc/ZMPKN0kKU9\n",
       "vlmuvzd0OFEhzVfOcyGGQoB6RY/QFR6GzQAADHEBnmF0QS8AIrbz093JYa+oACXc5IL3N6+ImJ8c\n",
       "B5opmkWQrfHAO8K2+9FKAE12IFtzmmGDCRw9jXCo49TSHAoERfjLWi2Xp64TrzR/O70BiXMPXQml\n",
       "3gAACUiKlzNH+bRlN48ahja7Y2O/4IYXFahGxOJ1BC+Pun+zIqUHrdEA/o/UzZquUE745up2sMDG\n",
       "YYky0QwSr/8fvO48aoTTtNf05hUrHKJ21jkIKlu9ICIB2PyGH6rr/hGX1PVurhUEewJLV1ipcys9\n",
       "0KHboIwaEk/iaoDrcljHbKkxVgBntz/jGRFUrZKzWBNmKPcQ3kZzHKX1+IfVaLe+9vz9lNyZTcxc\n",
       "53CMF2RbXAo7FgtFPh2bK9ec/JqVTbeNZNJD+oF7tkXMPJ6kvvBBFkVmufrHe5sIKDKLfLXQ9hzR\n",
       "16BhZ5h7qcTrhnU0K+SrKxU21cJdLPP++2jHDtvjrKv/Y/Mgjhwyq/N10KyZECCDl+UDt4eazz5X\n",
       "ebTFYH57ANmG+JfTsqdAZ+5zA2auQTb+mO5bLp6gIVQ1n2tG5K21pqDAHXzFuIAGBv0/iheHR9kl\n",
       "tJC6D8NTVpVdbSA4Da03txuCsLUrF+fSsPZTNsV5LwR1wMAMsS8yhOQLImt4F//U3WVK9W+wruxF\n",
       "L5cSvyH88uGHNk5Z6gIb3/fRRfxAJfat63CxF6uAUZj9KUNue7fvb7BfXy/3sP3mzhahK43GcO0C\n",
       "jhjsyIngFK/b9QOHD9bQsPbVAP4A0lLvuGvaW6ynqbN0ibTelzldL/g+I0Rd/86WedeuiEUeGAHm\n",
       "42yBLV7otbONNj+IRORAgCIHqllb2vhQqaTD/hwFjf2OfVvRJlG8+6392h3eth1vTuAb7GOxTaPV\n",
       "/IBmGJfGGb5hjXTH6SQr3l9u5pxGAQ4eKocmu1r7TEvX2l2N/GVDArqMXiLh/B3zRQwxwfYHWpNa\n",
       "HijWgwNreyT1Aq+rvIxyaAUhWiv6FfFaEIuPzIrUPoWVKn5OJZKJ+F88j+NWXJyJw/MCFyDt72p8\n",
       "3jgkTiVYqwTI4mT8cKkT8ZUQPDMJrIkHFvr/BOQ2a/VHKikwR0DXwQwlgZBUtrq5K7ir3wvr5pcQ\n",
       "979vzADnC5aC9luX7+PEXutC7GR/Rab/5sC2ZIb9HBi6AWkNFwngmwukOM0uBicZqom/bd+R2PPW\n",
       "6ohGiaigAolnDgiojzTMgzFUJajkBOK60ICbGx5ki+b2xAN5zwH00sK9/oBUu71KnCH16+iEKyH1\n",
       "bWAqdX4S29eyOXw90hJFWRV8rEIitnmeKozuvVV+e2MLmTuNRWMU/zQgehgBH1oj3nGj3GU9yNRi\n",
       "c2mF8t7QIi6BryFz5zbNNZwbJyE1RDgaLy007o6nEuFb/wJkvOicV2tYQcpVXcHVegh3+yAV1lzB\n",
       "JWiQpww6q+Fh982ar2oLDn6Wo+/GT3N/RS2KY/D8MNNxKIhcwgiBfY6mVtjU0fsZffEwX8W8TNiG\n",
       "742JHWHnnqL4eftiwpnc9xjiM3lFIz/fsIWyvr5VGA5S/HJdSccHH6DquELtnJ4+ciwYiQ1+iVXs\n",
       "KbMNgfE/orTnV1DtgMbsoUTcnWc0cuvN02nhEa+9pv02vYmgzuBVtbFsvBhiU/WCsvqbDdsOqBPH\n",
       "FkxLDDPGYrNA+/VOK1Ybn4gyPzb+PH8YXuOzAXGi4/+Adddh7cIKTw2ZWx+sHKyem6Clj6r7cMCD\n",
       "rXR0bClTbHOwe7UA4o0gtvSCxD7t/vRcgNj60Ai0OTKp7ghtG7nK7L/AnSIDN1n80CcGFfNcBWQu\n",
       "reaULieeD1QUXJBCCGL6i2WMgPyGsSjbM1wsw41XAcKm5DUhaJQP4Qpw/JLgqnWtQleGMC7XYDcg\n",
       "L7U4/qJjlHmub+N6oe2963QtX9NicLCstfgEPd9vaqEfG5IBwTBLtR/BTPnm5aGghDH6j1Sx2q7J\n",
       "B5FRR37+OqyHlZj5x34tL/7sKaEfUpx56t3Q2K6eJy3lyOtpWuICGo6DXoBC3wljRMesbL3hTQmF\n",
       "v+AGXylOiERRyXe69OUQAFiq8vd+FExDDxa7CKWZ1tM3ssQPbFnaDHZE9RV4KdFTiB5HLWLhY4xI\n",
       "BuU6ZPm2uSQ6rYRfTDW0mmhFFpyXZoRhQ6W3EFBhxBgljKxN2oCOrwYtzUtAyLdWq03YKZPHcKXH\n",
       "Z1XpsSDt4wVPZsuG+qqC7UnVXRVg+gWTPQWQulm1iWM/EOY9ryNzsxXjjSW2xIqX/+b6LxIBcqiu\n",
       "fF3zbd+cUAt5HfdbPYLVnublW3M1STWcx68Of7dsL9/LL4KgCNeFfxdXtMgQsP39PHOeQ8aztWm0\n",
       "P8NQGF+MRKA2LosqjN0OjnrDWCvbZLZIzhje5nkRFM+SjIebz+FKOu2ZyxmucIqtwHKv7WCpNOQc\n",
       "+qZrZ99raLWgK9bRVhOhAySqJGnsAm0tMuXoVCxaVl8X0UpJakiOIVaLFVoKZ0vLVulQF3O0BHQr\n",
       "bANuV25YTfbCydDEk4mo35ItT6AaLpLBf2b9OSQv+Bx44A271a0hOkHXxP4TxCemuIt6/812ZLX/\n",
       "uztOu4HIQsglaSYL5BMj3zYmq2mVCI+aTvUeaeOwYyiEsoGivbael5hlgi5Mv08dd9W41w3F2F5X\n",
       "MMjLly32tn+U3ctfKGomlI+BX7SVeip0xzvfyt2b40RU5BhE2WxfHuuUKQqQ2CCmeOhf4L0buIAN\n",
       "aAiFgl5oW8ro72jwLx46lZkz47SW+ncelhXdSwGL/tWuwOyLtvL9TnRM/jbQu+5dwt+61uX40Ic8\n",
       "MVA9XxdwG8/HV6sKv5MNt3XXHniMVv31gq9efzJSoKoPQrwkXkOfZVvoyHtzPtLGbyFzdY8Jv72m\n",
       "HRfT5lkbD9C6bYAa5GPPMaf8PiaCKJY5ISRfdYXsTcxKPCEaaLh609v59GdevnXF2c+lL/Cgk378\n",
       "CT+X1ey9Z5qSqNLZuqmu9LgIHzfJFEYyTSKKCZwIl7K5jglEZlRUSAf8/fO38YwVoA4Kj7bNEddy\n",
       "yTfoE6RHp/z7tGKyyj0o63Ilqup6mioN3Ji0QTrnTKCsfJ/R8S5BaxjJB1NqbbGzCPaDIXxANS2w\n",
       "hvr0xl31VDleBsAxKHYqvJxHeVU991i2sh2/USyqfQ5SeM59md1W39jvWqrv4jI6SGtVOOsKXA0x\n",
       "cWG1xHj/q2t2KgWkjOhT963pbxAxKX7eJtO1+KwetaXLNteyY00/q5Ly7L6YeSQjfPkQertpctVj\n",
       "FTUyL61zWyWVxzKcp0nQKK7etYcIjiXinKNfUBoRRcrMlcUNZmbk3Iy2YHm4M0Gol9cTOMU2n0Wp\n",
       "XAtOqQl9RVMc0y1bg1OvaxFCZ1v1nc80Ea/RZ+4PbaZKXMtCOsgTCYUWt5LTmz6+Vj/QR1yxss5s\n",
       "8iOnLlUbucnY19L+5+HtQfM/vfvWIdbEpSxCoVvI4VXbv6Wodcucdjg06rx+bu0MwpkTbJSy1pCs\n",
       "l6XsQH71FoB7pDD+yrIf64W7gV38SbokjHvleVDXyL4Sem6qAigD1azXUyYIpVXGhMquAc4aTMGd\n",
       "znSxLfC3KlC5/WK80ghpQyLHT9nY6a3qDad80q0nwVHkx5K9qC2Dm4IHI4teWUchVn1QRqt6B/Rp\n",
       "KNP8UNoUHoyeMJAvX2F3VBe9ZJxfodQkcy9wHv4UlJQiiiUIHaMXLNjDXSeRzR4PY8y7uH414CN5\n",
       "qJCqyx0euHc8Y3Yeu0ZdWWcpF2gWl+ju/DyFM1FL9alCpW+eEInj+2JAVsc8Sp2siAawjvxHWJj3\n",
       "soLc0UficMkoYl1V46gSCZ39pJvDBEllMEBgp4779Dzs7yhN6x30M8o2yAVc8PBbjDzhGT+uBC3D\n",
       "ulIa3SKh9n++cr0p1lNOXl2C1DFD9eCnEWSJEykrrBQi+nrFjY6gxlhEujht9+VT5OuapkG2RWP0\n",
       "1WEsw/0R2gFanMLy68P1JeRVLbs83RcLp62vM0QpFtn52/9NjbUNoaHVAjk2mIIxL5On92pdj8l6\n",
       "JKNGGGvMDmManu0FFEN7RKxFo+WbScUs9FDUKCTWJyQNEUQ7QqobzjdRevQxmzL6Qe98mFzq1Rrq\n",
       "WCh8OMkOZeQ180z74SFgkNiMNmbZIXQgPoeHEIHs8zORmNrYz4KCzqA223aQcEm+/K8Fjg+D/gBh\n",
       "7VejMpy/9R20pcCo0Qm+hh685beC76jIyfltEAhnFjbAwNMez/rspT5X76JrL+HxKrWXuLhCz2Dw\n",
       "86G7z4EA0x0+GC+UdxIMxaDtT8RlQAAADy8BnmNqQS8AFlxG266z5sAJpzkg86BBoOVz4OfM/ILZ\n",
       "Hp5B2UzYRwWlArFgssfXNfwMiaw49/mRPpxMQk+O8AOhpsJwAGDZC6PSeIa7YFurtLruUQ6O1dNY\n",
       "1ilrkPuvWvFyKSVjWDwVSCuYZakPq+kiAESlSDOia6/7ZYegr377T6XX3i7t5KVrXwlPPGH4wGD+\n",
       "nWXvvf3YIXZM64d8b2OfcWBv7i2rJpYGWBLLblqeIWulLKMFujrr+GNy3YAOcNzWp6nYRWKJf7g/\n",
       "W6s+7rm1BaRihuapR+tPRgq0cbKmobO2St1/BuqrblGWkAa/k7r+PkI8+KiY6CMBCUlsmNf8fCIK\n",
       "qgRMHzTCS8BBR27uhR1B5wAk3Sen1i6Y1BQKT9nTPwtfnE0q/o2q+mEn+tWN7VPx6Xrc426F/ryn\n",
       "RJg6Kp7XHbirT7aHdbZkZqs+o8xO4Fe58QAW1MN72oLjisqAlGgDek+Q1S/w61Q1BPvWwQvNQFCe\n",
       "7tW+FR6g0G/QWg8IjRWUF97VSHeaNudS8SS6lksWRfsNdWWVNNmNoHttyZUvYNtzw9L/+G8EA/1A\n",
       "FATXgjMnCk7eow0nf/40Yib2l6DYB/v1prjZlmv+IRI3oE46WynHBPNS3FBBVQ4Pw/cgIK7CLSTo\n",
       "Hx/rRHpETg0mh8v71s/6nrBaYLVRQJjMpChpseWmGi7pJvzh52KtQo/5FSlfae0AMW0tgnOuoi7k\n",
       "QLie3qsHj5jPbuA8wF8taXddBNFiPDUb6ldLOy+ouf/3kwnZxjdeQnqimxdmYFbHqpdyGMhv185p\n",
       "YP+eBTQIfmuEsAQPi+mJBIYrabkrii21Z47prj4dGejePMWp25IaNFtHGkhl9uCpd7CAB2SzmgVB\n",
       "+7qyUeYLx/d3GTBIAQ8634T/R8QXBbeSOSxWQGMUjXUfWJcYNssXah4GiPLMJ0gxrH8gHz7zUPSl\n",
       "+3xkQOv5KKEVYv4Z8lt/ZRCjL5UAsPeQuQ2ilGO/TW2qwWB3As2ibxHXh2m4OgqD4AbxeHXxnESr\n",
       "m9vE5GMu7z2oeO+6GF0tvRs/IAXxldMRvkPkD5X+QH7PzxYa5BPvarL+7ssn+5lNH53jWt6AtsXa\n",
       "b7LNS1F2LlmjOKUy1i0aGTj5eJKQKchzM0ncOx3eQk6SggWsxEabJfro3nXeORDifwFCpiDbrh3R\n",
       "fhKsZN+4tc2dH+W5b1pOuOo4FhDPA/vL1c6gHdro8PcZV2MYnkn9ufGKUqXXNb1/3WpcRmBfNS4b\n",
       "FgEtKMVEOHK/2NjcwFxgbfMJQ4QUk77ETuG0/stSUimnmOl5ZHBONfkq5PsqSFQzW11ynvwr6mpI\n",
       "U8VHTxqqd70Txa4iil4Kp3CULOcEN3R5PZ9Rvv4tuDT+qtD0dqaSC/N86m/SQiC79evGx75uRGMR\n",
       "F4lZUThR3D0/40S6xpWhkvWzJGmLT3f5m8cRoOPYwCQXBOfqYpGV/LjS7JP0pi4LDqtrI5qCkQ7e\n",
       "yDw0UgoDeXLhqOAJjg94jHv6uJKJIx0t3YUBx0I/XtbExnfDu8o+lS/9CuVbk3qGGru/3Jd7MlFN\n",
       "YOMdNTO8Vi7HlK2bI9RxWlA2PwOI0c8CKstlVJumnva+M00KBhuZgszedv8f0xU/tuw6/rSu6kXU\n",
       "xT84wWG33JWI2SGohhDP+q7MCz62NfThlkxhitcboC/xBhw9L/oY0J/4kOD1Vlmzj9ycuDIayQM4\n",
       "/jz1UMBUBVQCLtVba8ZHLM/SPQSw2bzbQ56U1/BQO3N49iV8r4lRasHg3ns5/q65oEJO7cDlBekL\n",
       "UqS99ZZhx51tYb2zBiCWKcD9fKlrkbA87Vvdo1SkTsZ0xNaC5HbB7lSrC9yWlgk5AttW6qfJpLxI\n",
       "V/l2vAztIAMZgvHofyBgYi61ua5hfuZFpW55rlYkal6SW4tci/w6mgFYlTFnHcYd5/rlR+z3izQ9\n",
       "Aw7u7gkB1zLDK/TMN7PuA+cq92gvlBvMU+rfrGtBm82coBNEW7lkckL03ijmXzI/ZRmsr9bou58z\n",
       "09lc74g4339ZgsUVvws4vX8zGlu/udFUBB6lvb3gPE66bYuRCc6DWPIUUV1iccsv0ba9OVNnyFg8\n",
       "cI5ZdyIDxaRyU+61cisyjMpqQBZv4uuVkpppV+icHrPqk0uWjRa3fbraKxYCN+vNPxFtM6WK+CSE\n",
       "YhVS8i3ujI6DEm6xHPyqmkc88nksAWdczAbHaq2NzaT+77/DVtHg2zsxbODIp5v6VvyjOsthX0u0\n",
       "lE9CU4yMstrlyWt/wy+YKV/FrwmYyJqE90wtn/K6G5kS+oeNcNMSSWN4hWw5iZsQKu4l4uHu2LhY\n",
       "ok3gQ686c7sv+ahfRoaXoGxUtR9yzYh2Sz7tywprLfvcjmJXZbESRoqO9rNOV3GoICostByuLS4e\n",
       "HSwmTuJtxMB8aOCLtdv28eF+NgSDCrEojQgz0RC1hfvYIrxXl+qZ3ZPerLyQHoIy/ZtOWW9QlhpM\n",
       "Jqnmle95/YmhXIqBq0hSp1WdAQx3oI2mqRmkEhwP4nc3TkUZMRcRxrr1jdVdVtE58HDyP25CitXz\n",
       "tw7r1kjRXpGUcw3Jbmf2GDePXEzk4+wJmaS1STx5sCFvpRGPuhWsZHdxTEuy4qERRwoJq57A5zBG\n",
       "mCmIWjNI1kHANw1LsPEfa4eYZiWrvi1rnI+l1dCwcQLRkY3Tk8xTZwauVb5H8qi1EPAMfglt74vI\n",
       "HHChX8imYsje/vNwjkK4FPDffaOpJTAfR6FTR/yIqKEzHrpboqGIzJq0wXjfNZinHc1Lsd3Qam3j\n",
       "B3w3tMwoVyzd8Rpb1WjVXnyCQYyIJjouACDB96/4u+X0tzaBcBZOaU9evdJLP4hfYPWOfpyPFuel\n",
       "3Krsu2n/9EuZZkL2otR1KSvga1D+u1jaDx2nkHAI8uFDh4+rF0jQSFCTNGjFvECl8t6qHGzlaPQN\n",
       "6ildXlkkpSiOo3u4wEDPOb2xwfClZxyqDSKVJ4gQgSWgADWhnrvWA2U9PwfroC1O62nZZ+YMT9ja\n",
       "6QP4JFz3PoIsDTwZjnCuhrHdsuqm7MoX1pjHRBeCAKxtSM8qBmO788ZEtFSFTYw5xCmXhnKAPt3c\n",
       "eYmNOkujMGqiK8MwoL3yMtYvIni3AuMYxtlEcFE9djjz6ArcvZBGl6mvX/+/iarN6XjAj1ySZ2a1\n",
       "gv2/Dlxh+ffvVlAnAbiwMsp693IoCQTiuFrTDBes2PkFiqGJnO/S2zxB9w7I/IA864YfkurA2q+k\n",
       "U8oXvShNTqRr/W3+Z0+Jsw2oW+V2TgWccSh2o6v77FmgOGQIwUhL+5nJ5NM5STIpSm/fPSA8Vdg7\n",
       "BV2T883nKlv3tWdcJrtkvIAiuIZwRa+K3T40bHKmB4N3vvYzRhpvdVWHH/HoKwVaLU8GF8eA1iAr\n",
       "Y0XKHJZQNOavt0yWy28r5mHiTdOhIqwluH9Y7/8EraBLMu86ygEBTuyAcjXq2BrPZfQhLCULbO4L\n",
       "6uLLyDnFPnOkwR28FB0Ta8bC81qCtt5c1UaNkumFHfmQtSuHw8K0B5XjZ/+S/O6Tu46MAHVMKOIV\n",
       "OR6CbWRmMi79jUYe8ecGlJ8QBltz1dftrWmjctGLLO/Fm6V2pusw+3FFhXEJtIF8eAWjyI86lZr7\n",
       "8Z5rweNVz5sXdycYcgVryx+Jiu9fZqoJS+6DQL5DcPjowvD4rGDQHRIGcSIsLtZ+p1wqBgY4Rw27\n",
       "zX/RHOg7uoMTYsuRiCTf9dYSuSa1IZDjALReVNB3/quiGax3F0R64p0w1c1Tb+qX0BnZ7ztpgbp5\n",
       "e+Y2p7jRR5jXLVIRy9FcfnhL0ZzpqYMV+iDH7LYtBrhWfwBTJoJoQeYJEnDDZop/XsOv9Uv8vGbh\n",
       "43AnzcS89jxOYDQ30kfgFHymNgQ3oy0elPIu908+7rjvVpsaJ2KQRKeq0TyEOL3Motpe7uqAYgCy\n",
       "nvuiVyyvro2sHH2g0N2de+2N//+pHgdzIBfzlkVWSr/HOZm7eP+zxyLCa0uV0ApQ19re/93G13mn\n",
       "SkHX8OLkb1dvwlaK1gfPQO7NxOWZS02EFFEvhZrlz5AdtGYuSwa2Fk9gY5xloFMBB9pwFricQbv4\n",
       "2d6RB3Z0JgxBa/VEI1UPTEbGS1tvgR2h3QyoGvQAVJgkjmJJx6jWNQcx1VMcx5JLDltpOgQ7/b9M\n",
       "Fv5w6pLiYf5jE61gDJK1Vmi0rfQQwtRTW0PGNG5wuw2GNVdIL3OIw4uwzCeR4VsESeYGKGsfC9Aq\n",
       "EE/3CDISSJZgRaeQzTUKCEbas9K6k3jS6oBytS10mPczbEVPZcAKFpqgmQRjcEqo4GKPrAnNcTIZ\n",
       "JAQyQUnLmuzm995l9TIyZqS3blET+B6XXgJ2wgS165NZWwrA0OwkfHjU4ghrUJqXzWm5I+84VwMR\n",
       "pgGpklaKyfpKU5VPgh0DigKeVpop9rRuoQLWeh+kcWKpdkmpt4IL3tHHWfFuGuy+Yr/RtcSvHOLc\n",
       "GaYQez6+JJ3GW6sa/GMRcue8y2jy7WQFx8JzzZ1dDoqWTUfRfZPbY7tU1/9S5Djecne06NUtWmd3\n",
       "13HnnwJhGwKirBFWJ22uMSHGRkFCsY2ejW+uPlWITTYxTIUy2P/px68OrbkoMwLoXa11lZ2Np5Kz\n",
       "DtUrK864xnDHWAkeMSoglz+4mE1YgOYwe+C6zNgSfeM5X4IUcG/Llo58Dg/ZShX/l64clZfB2avl\n",
       "P0v23dVI09I+LJZkV0mD4v1pugbvr253MCZUM+vZPIhOEH+YrY33BW7fzy3ywvSFTMp8po3drXvw\n",
       "BMJabmubczqMBTNqgGHxOJp2s7JjCIr6Ty44yOnW1PXXJpUep4NIbsylrA6iaoP0MjmbBDRCoAQC\n",
       "fCdfg2KlsMGdDJn2ixzsUFxZM24yQeGXuGqLOUQboyKGgKiq7IYgOmwZCwYe8RdQqyRmMAdbvFou\n",
       "67II25swvnXf87F2s1XboaQd/xIDKr5KjcpQrYD6JiW+Df1ikbNN1OvCEwAHG8fNtDDA+3z+hcAm\n",
       "tYYyWK0bW85YyKiDPkEsBnAjW0zOcSYNOqiSV2pB9zwbzT853ti/PVcvSD1UGv+YBLaoRYiV6Xvw\n",
       "o5d2K0Z1xTrKLcaWcJnUKXK3VqBye4xuAVHvs8wL8sidpRWnHp+5hmlUsV7McJYy9ja/NPinsZsG\n",
       "Z6A0HFitU1sidMB9OD/9th5r65QKglA8Zgnb8xaWfARb8LjAgQAAAUxBmmhJqEFomUwIKf/+1oyw\n",
       "GRJS5e8f3QANljcNUv+/0jPm0G0AetY6D6rSTyIx0YySMsEKNPf7jKC5OvdmxaqE0RZiJHAYuxX5\n",
       "tSbt4WZKIlM5kFQEK/majNRuslBrdKGGeulLkzvtcflK3xfh2niVKfvAx4UH11McfU8iEIhIM0Ip\n",
       "Zutogs/NSiZgEX76GdDl+aULoex3zJc7QPWjPmzP6Dzb80z6ZXkQ3gc/rv/BCKqAAJI31sQNzywZ\n",
       "TShE+a/7DQ+gxytllQgpWTylD79PWqYPN7nIn8QIJmqdv95xkE3alnAtDAUKqQIkI69bob1urfuh\n",
       "TyU1t1xhT8ttoYwMhvG2WGcnzeBtvb2JQpRnke7TP6AlOfmfmf0lUgUePdbeHtaACzt8BGVSZfTW\n",
       "uFfFBGO64Da5vG3PbGFYNRZXiNkEVOHEEXuE9QChgQAAAI5BnoZFESwU/wAIQwosD+6ABduvnDBQ\n",
       "bD0HdFav/FRnOFwtCL8pYaY0BUpxJ8jfNl/dErypDlN6+nd9LtQ3C50wlSo8EqfvyHT+sW9/5iW3\n",
       "wtrkbRYS/nxitMRROAHEsJUCrOOMQE5GuVUIFvzvjIoGcdggvy+d8t4z06Q/1L1Wu5+7cUGkccOv\n",
       "uqSTFCDhAAAAkQGepXRBLwAWWXKdvNSUPUABJolhrVOHWtl64Uacc6px9vibfnKmbGXrrxQGrZ8N\n",
       "nHbLe/ncfB4i1O6EieRCMzK/l8xb6uxpk8e8RI1zGreaAIB4Ayzt+RzFPjGXy8iH8KyfECo6uab0\n",
       "wRvZEBa9is+2ZWPAG44G9vkWpwQvbntIBurW2sZ/QQgH+k+XqSUsRcEAAABpAZ6nakEvABWf/twA\n",
       "fJOSGxfVbM11F8zeqr2I4vsiSJTbz0P9ltGC7WrfINtX6jrea64Dy8AfRcAA/UKK6eiNZpSS6IKS\n",
       "gKTdn6zoAGROkM8KfsXQAIgEhJpTv8KqmfcHNeCb629R5I2YAAAAg0GaqkmoQWyZTBRMEv/+tSqA\n",
       "W6tC2jQAD4LA4r6PNfD7KFuIcRwk1Y1qezguy1B9NzpxgtT21baOErPK2h+qJU5liJENFq0VIWhs\n",
       "vfsQQ6qd+AywgIkaAUQJi3Skx2svW19Wl83iMdPhV+RqEQpGvfXgAAADAAADACWlUec/6h8bdwLy\n",
       "AAAAbgGeyWpBLwAWXEeNAAQqnpiZT/JFbEIaku3i6FTjjEfY17hT64zc5mCHmZo58O5gMtPJTZ8i\n",
       "Q/QkBGs2E05iHlCES0FlS8nRdQbpPq8fSAALV7cLqFtqwJ6OybEjGk3CtK+1EUDifVgSDdg8KYGz\n",
       "AAADs21vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAABV8AAEAAAEAAAAAAAAAAAAAAAABAAAA\n",
       "AAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAIAAALddHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAABV8AAAAAAAAAAAAAAAAAAAA\n",
       "AAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAUQAAABsAAAAAAAJGVkdHMAAAAc\n",
       "ZWxzdAAAAAAAAAABAAAVfAAAQAAAAQAAAAACVW1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAQAAA\n",
       "AWAAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAAgBt\n",
       "aW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAA\n",
       "AAEAAAHAc3RibAAAALRzdHNkAAAAAAAAAAEAAACkYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAA\n",
       "AAUQAbAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAA\n",
       "ADJhdmNDAWQAH//hABlnZAAfrNlAUQ3oQAAAAwBAAAADAQPGDGWAAQAGaOvjyyLAAAAAHHV1aWRr\n",
       "aEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAAALAAAgAAAAABRzdHNzAAAAAAAA\n",
       "AAEAAAABAAAAaGN0dHMAAAAAAAAACwAAAAEAAEAAAAAAAQAAoAAAAAABAABAAAAAAAEAAAAAAAAA\n",
       "AQAAIAAAAAABAACgAAAAAAEAAEAAAAAAAQAAAAAAAAABAAAgAAAAAAEAAGAAAAAAAQAAIAAAAAAc\n",
       "c3RzYwAAAAAAAAABAAAAAQAAAAsAAAABAAAAQHN0c3oAAAAAAAAAAAAAAAsAAE0PAAA1XQAAFVsA\n",
       "AAx1AAAPMwAAAVAAAACSAAAAlQAAAG0AAACHAAAAcgAAABRzdGNvAAAAAAAAAAEAAAAsAAAAYnVk\n",
       "dGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAA\n",
       "ACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#Make animation of fitting process\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython import display\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "#fig.set_dpi(100)\n",
    "fig.set_size_inches(18, 6)\n",
    "plt.suptitle(\"MIP-parse + EM fit\")\n",
    "\n",
    "def update(frame):\n",
    "    one_shot_fit_grammar.load_state_dict(em.grammar_iters[frame])\n",
    "    for ax in axs:\n",
    "        ax.cla()\n",
    "    make_figure_for_grammar(one_shot_fit_grammar, axs, N=10)\n",
    "    plt.suptitle(\"MIP-parse + EM fit, iter %02d\" % frame)\n",
    "    for ax in axs:\n",
    "        ax.set_xlim([-8, 8.])\n",
    "        ax.set_ylim([0., 0.7])\n",
    "ani = FuncAnimation(fig, update, frames=range(len(em.grammar_iters)), blit=False, interval=500.)\n",
    "video = ani.to_html5_video()\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()                   # avoid plotting a spare static plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist parsing with MMD + REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:context has already been set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da73078851844daaa9758b6467a37da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [-1.94591095 -3.66356565 -3.66356565], tensor([-0.0194, -0.0062, -0.0063])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-2.19722558 -1.38629486 -1.73460172], tensor([ 0.0002,  0.0008, -0.0004])', 'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-5. -5. -5.], tensor([0.0072, 0.0101, 0.0140])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [5. 5. 5.], tensor([-0.0252,  0.0106,  0.0388])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-2.19722558 -1.73460172 -0.61903949], tensor([0.0036, 0.0093, 0.0103])', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [-2.  0.  2.], tensor([-0.0091, -0.0103, -0.0054])'}\n",
      "0: Loss -0.007526, Proxy Loss -0.007526, Gradient Norm (0.019587 +/- 0.015353)\n",
      "1: Loss -0.032122, Proxy Loss -0.032122, Gradient Norm (0.036222 +/- 0.024958)\n",
      "2: Loss -0.004522, Proxy Loss -0.004522, Gradient Norm (0.043124 +/- 0.021580)\n",
      "3: Loss -0.033437, Proxy Loss -0.033437, Gradient Norm (0.055639 +/- 0.023670)\n",
      "4: Loss -0.037818, Proxy Loss -0.037818, Gradient Norm (0.077070 +/- 0.040143)\n",
      "5: Loss -0.041346, Proxy Loss -0.041346, Gradient Norm (0.101438 +/- 0.060900)\n",
      "6: Loss -0.031395, Proxy Loss -0.031395, Gradient Norm (0.124759 +/- 0.075045)\n",
      "7: Loss -0.040532, Proxy Loss -0.040532, Gradient Norm (0.153223 +/- 0.099585)\n",
      "8: Loss -0.066081, Proxy Loss -0.066081, Gradient Norm (0.185521 +/- 0.124485)\n",
      "9: Loss -0.139734, Proxy Loss -0.139734, Gradient Norm (0.225820 +/- 0.160830)\n",
      "{'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [-1.50223987 -3.22079157 -3.22275718], tensor([-0.2654, -0.1016, -0.0988])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [5.43489336 5.40230349 4.57125364], tensor([-0.2886, -0.2826,  0.4602])', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [-1.55041346  0.44888576  2.44488731], tensor([-0.0808, -0.1200, -0.0566])', 'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-5.44410111 -5.43667028 -5.44460296], tensor([0.1391, 0.1565, 0.1694])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-2.63319297 -2.17851803 -1.06220101], tensor([0.0769, 0.1353, 0.1612])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-2.62707556 -1.80006771 -2.14007736], tensor([0.0248, 0.0312, 0.0279])'}\n",
      "10: Loss -0.229041, Proxy Loss -0.229041, Gradient Norm (0.268437 +/- 0.190976)\n",
      "11: Loss -0.175626, Proxy Loss -0.175626, Gradient Norm (0.313131 +/- 0.232396)\n",
      "12: Loss -0.222079, Proxy Loss -0.222079, Gradient Norm (0.362664 +/- 0.288709)\n",
      "13: Loss -0.294299, Proxy Loss -0.294299, Gradient Norm (0.412170 +/- 0.333914)\n",
      "14: Loss -0.408525, Proxy Loss -0.408525, Gradient Norm (0.462920 +/- 0.363012)\n",
      "15: Loss -0.368341, Proxy Loss -0.368341, Gradient Norm (0.516348 +/- 0.419608)\n",
      "16: Loss -0.513132, Proxy Loss -0.513132, Gradient Norm (0.572666 +/- 0.472925)\n",
      "17: Loss -0.595342, Proxy Loss -0.595342, Gradient Norm (0.627436 +/- 0.509024)\n",
      "18: Loss -0.534600, Proxy Loss -0.534600, Gradient Norm (0.676948 +/- 0.568175)\n",
      "19: Loss -0.598022, Proxy Loss -0.598022, Gradient Norm (0.726861 +/- 0.620031)\n",
      "{'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-6.50788783 -6.50958326 -6.51902216], tensor([0.6387, 0.5212, 0.5232])', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [-0.46696138  1.53916955  3.5220511 ], tensor([-0.1869, -0.2791, -0.1529])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-3.69856561 -2.85971034 -3.20298813], tensor([0.0866, 0.1165, 0.0905])', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-3.69434187 -3.25727875 -2.13700096], tensor([0.2791, 0.3950, 0.5662])', 'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [-0.41791019 -2.14451912 -2.15273255], tensor([-0.3525, -0.0784, -0.0528])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [6.50644598 6.4528287  3.52225832], tensor([-0.7852, -1.1869,  1.4458])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None'}\n",
      "20: Loss -0.573936, Proxy Loss -0.573936, Gradient Norm (0.775801 +/- 0.679857)\n",
      "21: Loss -0.811416, Proxy Loss -0.811416, Gradient Norm (0.827781 +/- 0.727124)\n",
      "22: Loss -0.835261, Proxy Loss -0.835261, Gradient Norm (0.879733 +/- 0.764180)\n",
      "23: Loss -0.812353, Proxy Loss -0.812353, Gradient Norm (0.928619 +/- 0.814505)\n",
      "24: Loss -1.073287, Proxy Loss -1.073287, Gradient Norm (0.981166 +/- 0.853809)\n",
      "25: Loss -0.858598, Proxy Loss -0.858598, Gradient Norm (1.025870 +/- 0.903441)\n",
      "26: Loss -1.060362, Proxy Loss -1.060362, Gradient Norm (1.065934 +/- 0.942918)\n",
      "27: Loss -1.129041, Proxy Loss -1.129041, Gradient Norm (1.111696 +/- 0.985832)\n",
      "28: Loss -1.304479, Proxy Loss -1.304479, Gradient Norm (1.154665 +/- 1.020693)\n",
      "29: Loss -1.202240, Proxy Loss -1.202240, Gradient Norm (1.192709 +/- 1.057805)\n",
      "{'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-4.91836101 -4.48230368 -3.36535224], tensor([0.5257, 0.6960, 1.2026])', 'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-7.73141965 -7.73837485 -7.74677716], tensor([1.2424, 1.0334, 0.9821])', 'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [ 0.71663722 -1.23958198 -1.443317  ], tensor([-0.3146,  0.0245,  0.0935])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [7.72823128 7.67213997 2.30638617], tensor([-1.1614, -1.8101,  2.0678])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-4.92299945 -4.08410838 -4.42841706], tensor([0.1451, 0.2059, 0.1543])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [0.71583712 2.75177068 4.73370899], tensor([-0.0892, -0.3267, -0.1978])'}\n",
      "30: Loss -1.348724, Proxy Loss -1.348724, Gradient Norm (1.229472 +/- 1.092146)\n",
      "31: Loss -1.277287, Proxy Loss -1.277287, Gradient Norm (1.263735 +/- 1.124682)\n",
      "32: Loss -1.328584, Proxy Loss -1.328584, Gradient Norm (1.298010 +/- 1.160983)\n",
      "33: Loss -1.220931, Proxy Loss -1.220931, Gradient Norm (1.330853 +/- 1.194760)\n",
      "34: Loss -1.355263, Proxy Loss -1.355263, Gradient Norm (1.359255 +/- 1.219426)\n",
      "35: Loss -1.358410, Proxy Loss -1.358410, Gradient Norm (1.391598 +/- 1.244997)\n",
      "36: Loss -1.436924, Proxy Loss -1.436924, Gradient Norm (1.423018 +/- 1.266131)\n",
      "37: Loss -1.524525, Proxy Loss -1.524525, Gradient Norm (1.456901 +/- 1.288689)\n",
      "38: Loss -1.737105, Proxy Loss -1.737105, Gradient Norm (1.490992 +/- 1.303442)\n",
      "39: Loss -1.532298, Proxy Loss -1.532298, Gradient Norm (1.523844 +/- 1.321003)\n",
      "{'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-6.26217577 -5.81884157 -4.72426886], tensor([0.6599, 0.8798, 1.6194])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-6.26046602 -5.42611922 -5.76973247], tensor([0.1825, 0.2580, 0.1918])', 'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [ 1.77684797 -1.36191258 -2.04136647], tensor([-0.2210,  0.2565,  0.2960])', 'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-9.08021368 -9.09057255 -9.09311875], tensor([1.5789, 1.3527, 1.2761])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [9.04361598 8.99422993 1.00315935], tensor([-1.4380, -2.2194,  2.4622])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [1.3089467  3.96978427 6.02371371], tensor([ 0.3222, -0.2434, -0.3105])'}\n",
      "40: Loss -1.736444, Proxy Loss -1.736444, Gradient Norm (1.556527 +/- 1.334241)\n",
      "41: Loss -1.660544, Proxy Loss -1.660544, Gradient Norm (1.588363 +/- 1.340499)\n",
      "42: Loss -1.660760, Proxy Loss -1.660760, Gradient Norm (1.619618 +/- 1.342094)\n",
      "43: Loss -1.689172, Proxy Loss -1.689172, Gradient Norm (1.651406 +/- 1.349024)\n",
      "44: Loss -1.831989, Proxy Loss -1.831989, Gradient Norm (1.680931 +/- 1.354526)\n",
      "45: Loss -1.893890, Proxy Loss -1.893890, Gradient Norm (1.709433 +/- 1.359431)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46: Loss -1.958889, Proxy Loss -1.958889, Gradient Norm (1.737453 +/- 1.364010)\n",
      "47: Loss -1.839549, Proxy Loss -1.839549, Gradient Norm (1.764981 +/- 1.365039)\n",
      "48: Loss -1.998346, Proxy Loss -1.998346, Gradient Norm (1.790697 +/- 1.367119)\n",
      "49: Loss -2.013069, Proxy Loss -2.013069, Gradient Norm (1.813940 +/- 1.372916)\n",
      "{'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [0.29476791 5.0695338  7.47421805], tensor([ 0.8169, -0.2854, -0.6284])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-7.6393165  -6.81066377 -7.15036198], tensor([0.1979, 0.2837, 0.2109])', 'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [ 2.67826729 -2.62118644 -3.40113171], tensor([-0.1682,  0.4589,  0.4454])', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-7.64823507 -7.19846124 -6.14197973], tensor([0.7075, 0.9548, 1.8189])', 'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-10.47695226 -10.49722173 -10.49303277], tensor([1.7701, 1.5419, 1.4580])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [10.40052882 10.35383641 -0.33016201], tensor([-1.5971, -2.4486,  2.6578])'}\n",
      "50: Loss -1.895805, Proxy Loss -1.895805, Gradient Norm (1.837132 +/- 1.375613)\n",
      "51: Loss -2.095666, Proxy Loss -2.095666, Gradient Norm (1.858576 +/- 1.381229)\n",
      "52: Loss -1.933318, Proxy Loss -1.933318, Gradient Norm (1.880042 +/- 1.384131)\n",
      "53: Loss -1.876586, Proxy Loss -1.876586, Gradient Norm (1.900239 +/- 1.386306)\n",
      "54: Loss -2.243174, Proxy Loss -2.243174, Gradient Norm (1.918027 +/- 1.389970)\n",
      "55: Loss -2.011872, Proxy Loss -2.011872, Gradient Norm (1.935009 +/- 1.394658)\n",
      "56: Loss -1.961448, Proxy Loss -1.961448, Gradient Norm (1.951567 +/- 1.397374)\n",
      "57: Loss -2.230977, Proxy Loss -2.230977, Gradient Norm (1.966669 +/- 1.402099)\n",
      "58: Loss -2.156090, Proxy Loss -2.156090, Gradient Norm (1.981530 +/- 1.406366)\n",
      "59: Loss -2.265827, Proxy Loss -2.265827, Gradient Norm (1.995360 +/- 1.410758)\n",
      "{'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [ 3.42437831 -4.19850447 -4.95120935], tensor([-0.1291,  0.6153,  0.5343])', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-9.01596185 -8.56466411 -7.55468571], tensor([0.7207, 0.9736, 1.8710])', 'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-11.8726591  -11.90824783 -11.89952085], tensor([1.8794, 1.6517, 1.5648])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [11.76263905 11.71408077 -1.65837879], tensor([-1.7227, -2.6154,  2.7944])', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [-1.27066669  6.21651996  9.08217335], tensor([ 1.0718, -0.4027, -0.8619])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-9.00108053 -8.18340389 -8.51726129], tensor([0.2006, 0.2905, 0.2156])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None'}\n",
      "60: Loss -2.213064, Proxy Loss -2.213064, Gradient Norm (2.008174 +/- 1.414415)\n",
      "61: Loss -2.162101, Proxy Loss -2.162101, Gradient Norm (2.021166 +/- 1.418245)\n",
      "62: Loss -2.221078, Proxy Loss -2.221078, Gradient Norm (2.033421 +/- 1.423348)\n",
      "63: Loss -2.172930, Proxy Loss -2.172930, Gradient Norm (2.044324 +/- 1.428952)\n",
      "64: Loss -2.363393, Proxy Loss -2.363393, Gradient Norm (2.054684 +/- 1.433839)\n",
      "65: Loss -2.368685, Proxy Loss -2.368685, Gradient Norm (2.064277 +/- 1.439252)\n",
      "66: Loss -2.273587, Proxy Loss -2.273587, Gradient Norm (2.074065 +/- 1.444218)\n",
      "67: Loss -2.328911, Proxy Loss -2.328911, Gradient Norm (2.082867 +/- 1.448832)\n",
      "68: Loss -2.346790, Proxy Loss -2.346790, Gradient Norm (2.091453 +/- 1.452564)\n",
      "69: Loss -2.316726, Proxy Loss -2.316726, Gradient Norm (2.099569 +/- 1.457124)\n",
      "{'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [ 4.03983543 -5.83721745 -6.5228705 ], tensor([-0.1051,  0.6719,  0.5655])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [13.11613512 13.06019608 -2.96899483], tensor([-1.8150, -2.7343,  2.8968])', 'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-13.24429797 -13.29772933 -13.28667789], tensor([1.9481, 1.7206, 1.6317])', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [-2.92264846  7.529156   10.74047677], tensor([ 1.2106, -0.4936, -1.0099])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-10.34019661  -9.88965305  -8.92437263], tensor([0.7240, 0.9792, 1.8862])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-10.31963427  -9.5166517   -9.84398472], tensor([0.2016, 0.2924, 0.2170])'}\n",
      "70: Loss -2.391454, Proxy Loss -2.391454, Gradient Norm (2.107368 +/- 1.460126)\n",
      "71: Loss -2.342176, Proxy Loss -2.342176, Gradient Norm (2.114719 +/- 1.464199)\n",
      "72: Loss -2.483957, Proxy Loss -2.483957, Gradient Norm (2.121343 +/- 1.467960)\n",
      "73: Loss -2.335269, Proxy Loss -2.335269, Gradient Norm (2.128014 +/- 1.471676)\n",
      "74: Loss -2.331159, Proxy Loss -2.331159, Gradient Norm (2.134349 +/- 1.475268)\n",
      "75: Loss -2.286857, Proxy Loss -2.286857, Gradient Norm (2.140617 +/- 1.478550)\n",
      "76: Loss -2.432194, Proxy Loss -2.432194, Gradient Norm (2.146246 +/- 1.481701)\n",
      "77: Loss -2.417964, Proxy Loss -2.417964, Gradient Norm (2.151244 +/- 1.484977)\n",
      "78: Loss -2.346611, Proxy Loss -2.346611, Gradient Norm (2.156402 +/- 1.488030)\n",
      "79: Loss -2.381094, Proxy Loss -2.381094, Gradient Norm (2.161520 +/- 1.490972)\n",
      "{'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-14.58474223 -14.65641697 -14.6444746 ], tensor([1.9883, 1.7607, 1.6705])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [14.45341687 14.3854887  -4.25888198], tensor([-1.8741, -2.8071,  2.9630])', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-11.61887619 -11.16996577 -10.24347085], tensor([0.7249, 0.9806, 1.8898])', 'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [ 4.5619342  -7.43368094 -8.04418595], tensor([-0.0913,  0.6856,  0.5721])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [-4.55187928  8.95633801 12.38548446], tensor([ 1.3052, -0.5595, -1.1118])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-11.59314767 -10.80502575 -11.12647177], tensor([0.2018, 0.2930, 0.2175])'}\n",
      "80: Loss -2.514702, Proxy Loss -2.514702, Gradient Norm (2.166014 +/- 1.493778)\n",
      "81: Loss -2.599220, Proxy Loss -2.599220, Gradient Norm (2.170030 +/- 1.496511)\n",
      "82: Loss -2.339013, Proxy Loss -2.339013, Gradient Norm (2.174113 +/- 1.499390)\n",
      "83: Loss -2.401528, Proxy Loss -2.401528, Gradient Norm (2.177909 +/- 1.501555)\n",
      "84: Loss -2.576379, Proxy Loss -2.576379, Gradient Norm (2.181085 +/- 1.503713)\n",
      "85: Loss -2.503319, Proxy Loss -2.503319, Gradient Norm (2.184613 +/- 1.505646)\n",
      "86: Loss -2.413698, Proxy Loss -2.413698, Gradient Norm (2.187997 +/- 1.507489)\n",
      "87: Loss -2.556531, Proxy Loss -2.556531, Gradient Norm (2.191115 +/- 1.509199)\n",
      "88: Loss -2.435082, Proxy Loss -2.435082, Gradient Norm (2.194092 +/- 1.511039)\n",
      "89: Loss -2.369688, Proxy Loss -2.369688, Gradient Norm (2.196816 +/- 1.512941)\n",
      "{'rule_params_by_node_type.Root.0.0.mean.unconstrained_value: [-15.89236594 -15.98137134 -15.96927612], tensor([2.0099, 1.7822, 1.6912])', 'rule_params_by_node_type.Root.2.0.mean.unconstrained_value: [-6.13183787 10.43154527 13.99090028], tensor([ 1.3631, -0.6006, -1.1728])', 'rule_params_by_node_type.Root.2.0.variance.unconstrained_value: [-12.82799972 -12.05333643 -12.36980501], tensor([0.2019, 0.2932, 0.2176])', 'params_by_node_type.Root.unconstrained_value: [-0.91629073 -0.91629073 -1.60943791], None', 'rule_params_by_node_type.Root.1.0.variance.unconstrained_value: [ 5.02447942 -8.95339762 -9.49557547], tensor([-0.0824,  0.6892,  0.5738])', 'rule_params_by_node_type.Root.0.0.variance.unconstrained_value: [-12.85811736 -12.410994   -11.51708837], tensor([0.7252, 0.9811, 1.8909])', 'rule_params_by_node_type.Root.1.0.mean.unconstrained_value: [15.7687569  15.68587555 -5.52646109], tensor([-1.9090, -2.8485,  3.0021])'}\n",
      "90: Loss -2.486906, Proxy Loss -2.486906, Gradient Norm (2.199289 +/- 1.514513)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91: Loss -2.564901, Proxy Loss -2.564901, Gradient Norm (2.201724 +/- 1.516030)\n",
      "92: Loss -2.472997, Proxy Loss -2.472997, Gradient Norm (2.203965 +/- 1.517328)\n",
      "93: Loss -2.550848, Proxy Loss -2.550848, Gradient Norm (2.206052 +/- 1.518398)\n",
      "94: Loss -2.513394, Proxy Loss -2.513394, Gradient Norm (2.208124 +/- 1.519367)\n",
      "95: Loss -2.552355, Proxy Loss -2.552355, Gradient Norm (2.209914 +/- 1.520468)\n",
      "96: Loss -2.447713, Proxy Loss -2.447713, Gradient Norm (2.211484 +/- 1.521522)\n",
      "97: Loss -2.589282, Proxy Loss -2.589282, Gradient Norm (2.212758 +/- 1.522545)\n",
      "98: Loss -2.622425, Proxy Loss -2.622425, Gradient Norm (2.214110 +/- 1.523411)\n",
      "99: Loss -2.651949, Proxy Loss -2.651949, Gradient Norm (2.215259 +/- 1.524372)\n"
     ]
    }
   ],
   "source": [
    "# Note: this is doing really poorly, even when seeded from the GT\n",
    "# grammar. https://arxiv.org/pdf/2110.13452.pdf\n",
    "# suggests \n",
    "\n",
    "# Do single-shot fitting of grammar params based on just the optimal parses\n",
    "mmd_fit_grammar = deepcopy(gt_grammar)\n",
    "mmd_fit = SampleBasedFittingWrapper(\n",
    "    mmd_fit_grammar, [sample[1] for sample in samples],\n",
    "    distance_metric=\"mean_mmd_poses\"\n",
    ")\n",
    "mmd_fit.do_sample_based_fitting(num_iterations=100, num_samples=200, lr=0.1, tqdm=tqdm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MMD Estimate')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=300).set_size_inches(3, 3)\n",
    "plt.plot(mmd_fit.loss_iters)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MMD Estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-5., -5., -5.], requires_grad=True) +/- tensor([1.0000, 1.5000, 3.5000], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([5., 5., 5.], requires_grad=True) +/- tensor([1.2500, 0.2500, 0.2500], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-2.,  0.,  2.], requires_grad=True) +/- tensor([1.0000, 2.0000, 1.5000], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-5., -5., -5.], requires_grad=True) +/- tensor([1.0000, 1.5000, 3.5000], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([5., 5., 5.], requires_grad=True) +/- tensor([1.2500, 0.2500, 0.2500], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-2.,  0.,  2.], requires_grad=True) +/- tensor([1.0000, 2.0000, 1.5000], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-5.4441, -5.4367, -5.4446], requires_grad=True) +/- tensor([0.6703, 1.0170, 2.5689], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([5.4349, 5.4023, 4.5713], requires_grad=True) +/- tensor([1.8209, 0.3839, 0.3832], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-1.5504,  0.4489,  2.4449], requires_grad=True) +/- tensor([0.6742, 1.4184, 1.0526], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-6.5079, -6.5096, -6.5190], requires_grad=True) +/- tensor([0.2426, 0.3707, 1.0555], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([6.5064, 6.4528, 3.5223], requires_grad=True) +/- tensor([3.9702, 1.0484, 1.0408], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-0.4670,  1.5392,  3.5221], requires_grad=True) +/- tensor([0.2416, 0.5418, 0.3905], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-7.7314, -7.7384, -7.7468], requires_grad=True) +/- tensor([0.0726, 0.1118, 0.3340], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([7.7282, 7.6721, 2.3064], requires_grad=True) +/- tensor([6.7187, 2.2451, 1.9103], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([0.7158, 2.7518, 4.7337], requires_grad=True) +/- tensor([0.0722, 0.1656, 0.1179], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-9.0802, -9.0906, -9.0931], requires_grad=True) +/- tensor([0.0190, 0.0296, 0.0880], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([9.0436, 8.9942, 1.0032], requires_grad=True) +/- tensor([8.5531, 2.0393, 1.1493], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([1.3089, 3.9698, 6.0237], requires_grad=True) +/- tensor([0.0191, 0.0438, 0.0311], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-10.4770, -10.4972, -10.4930], requires_grad=True) +/- tensor([0.0048, 0.0075, 0.0215], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([10.4005, 10.3538, -0.3302], requires_grad=True) +/- tensor([9.3573, 0.6779, 0.3226], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([0.2948, 5.0695, 7.4742], requires_grad=True) +/- tensor([0.0048, 0.0110, 0.0078], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-11.8727, -11.9082, -11.8995], requires_grad=True) +/- tensor([0.0012, 0.0019, 0.0052], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([11.7626, 11.7141, -1.6584], requires_grad=True) +/- tensor([9.6846, 0.1480, 0.0703], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-1.2707,  6.2165,  9.0822], requires_grad=True) +/- tensor([0.0012, 0.0028, 0.0020], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-13.2443, -13.2977, -13.2867], requires_grad=True) +/- tensor([0.0003, 0.0005, 0.0013], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([13.1161, 13.0602, -2.9690], requires_grad=True) +/- tensor([9.8270, 0.0291, 0.0147], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-2.9226,  7.5292, 10.7405], requires_grad=True) +/- tensor([0.0003, 0.0007, 0.0005], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-14.5847, -14.6564, -14.6445], requires_grad=True) +/- tensor([9.0946e-05, 1.4191e-04, 3.5688e-04], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([14.4534, 14.3855, -4.2589], requires_grad=True) +/- tensor([9.8967e+00, 5.9076e-03, 3.2096e-03], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-4.5519,  8.9563, 12.3855], requires_grad=True) +/- tensor([9.3290e-05, 2.0397e-04, 1.4817e-04], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-15.8924, -15.9814, -15.9693], requires_grad=True) +/- tensor([2.7049e-05, 4.1735e-05, 1.0058e-04], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([15.7688, 15.6859, -5.5265], requires_grad=True) +/- tensor([9.9347e+00, 1.2938e-03, 7.5278e-04], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-6.1318, 10.4315, 13.9909], requires_grad=True) +/- tensor([2.7845e-05, 5.9251e-05, 4.3448e-05], grad_fn=<AddBackward0>)\n",
      "One shot fit rule probs:  tensor([0.4000, 0.4000, 0.2000], grad_fn=<DivBackward0>)\n",
      "One shot-fit Mode 0: Parameter containing:\n",
      "tensor([-17.1682, -17.2730, -17.2611], requires_grad=True) +/- tensor([8.7889e-06, 1.3160e-05, 2.9924e-05], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 1: Parameter containing:\n",
      "tensor([17.0587, 16.9597, -6.7711], requires_grad=True) +/- tensor([9.9573e+00, 3.0602e-04, 1.8890e-04], grad_fn=<AddBackward0>)\n",
      "One shot-fit Mode 2: Parameter containing:\n",
      "tensor([-7.6566, 11.9090, 15.5448], requires_grad=True) +/- tensor([9.0566e-06, 1.8278e-05, 1.3643e-05], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"1296\" height=\"432\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAADHfG1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MTMgbG9v\n",
       "a2FoZWFkX3RocmVhZHM9MiBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxh\n",
       "Y2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHly\n",
       "YW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3\n",
       "ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTQgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAEqlZYiE\n",
       "ABL//vet34FNwEDta7pXOLTLq5Q0PVH2lKZ4tkgAAAMAAAMACej+Ddsv8QBu0bVvhKhG5n92YBAH\n",
       "AIMOb5tp4HXGPOY1mOjF3AuHF4Rdhb1jBquh7Q1HCEYq+lIGebCMKQwkZJ9kDhrdL2blBHnhkdWx\n",
       "OZsf1wMXtOCq5Yt7Pz90ehIX++BKtnCPC2TYAYwVF41+IRzNbjfheB+6uV2mUr2jrIMvJD96INUD\n",
       "UZzPekism0ijNIQ1z+ZZKfLW2KGZQ+A3HRwG2yJ7U/oVhlaHP7kXIQ6oECSFZo85sM6XSfwEKF8V\n",
       "FVAyQ832C58S7FUac9QXuDk01e6l8mVwoLe7b7VV5hn+DG4hS25JuhjFAOkw7mPIpishzottgmPk\n",
       "PgiaMa5q/93jzg7rBb8A2RgAlNhWZVO+59oQLdMwD6Td5r/t/ZdMxcKRen83QllMZs/zMnLcpCRN\n",
       "qAle5s4A74D1EemimHcLe8uu+Gias7J8nW8MF/HUtnZDrtWZlo9koFVAop51MUtMYxh2C/TAqJbO\n",
       "0wSZdFvcM4ctLMul3gIqzB3MiQemRznty95T6pGjU5qY9WZANpQIh/6TDDULwLiHIzWTfIaLESm/\n",
       "kg/fAQsdbiG/BQ6Vv83WS/YNpW4ZiAu1W1tVvdxEKzfYm/JYIfuJjIbeCaLEGKhHvr8fMDVp4faH\n",
       "ScNSvd8mRA2ce5F3anmEfxkgf/MxCLKBlyxVpHe26UQyco00hDrtQGZZYQCZL0ispfAsA1vcRMVS\n",
       "504DBr0UG90Bchu//yRICNFL6v9LssC6p1x1SJErNS80SKJaSejmv2Wx1AXV4yOH908Com9XnhFk\n",
       "yx19Vi6JKB+JYRVdxcOsVJtdHD95u2ELVbRQhCfRaAAAAwIa8PRtbAAKX1lYQOIchc5/TkBIGz9z\n",
       "6cBBn9RA5EQ/NYB44/6zaOnQy2ZEnX7NwyFGueKOEAv1JxqkkcU+i5O5IgYLwD2a+WKERwpLvtY5\n",
       "pJ/90j0DI2DUwZvp3c5s6acUZuVy0GYClCaZPt6wC8UvIij4DcqTJkk09F4GQ0UOtOnXICcwY+yc\n",
       "dVVndHe24FmueMzaEEAPArYVeKlEOt5N7YvgMzwb2fxsClzw3hRL34YyTt7MIIiBYcvj+ZKtGK9Z\n",
       "lFYfmHmKtVZlitWzh/ifYAcizew6nk09K3i5VkoVFPFxpS850sZdPmYuHjOI6IjpbagdnKcrrWmp\n",
       "SF9AxljmgQFNlfcA/5JBG0l6kFoSAuySOPGPXASlBecZ7NbgHNuVUSZstUOT69myhptGOYYVa2dR\n",
       "84FRjlRefblwRVSLfWhYQwBJ86avZpu1By64fwBucVKP3VaO6QOHhsjcB3VYhbFBMBPa28kntr+T\n",
       "W80sb0+i38/loiLrq3BK1GpxvpkfFAm9Dx9l5jy+KZuI0zDQEp/Gf9WSs+/5iZ0mFDMX5083TTth\n",
       "EHY3M4ffc0jelCxasN+v5I9uGxLGsZw7Y4ygicE0ThBsQl8yqKZQ9jqauYYQsAAFUmQzUjW/ip/6\n",
       "TGc2wVs1IShBHMYt8khRfpW9+8UPRF69+//h3XISLwvLW0XBjorTnLsQsEVG0vOmniuSS+vD6HlM\n",
       "dlYFbD6ymJKXdHY0RJiM1RGu0lpxwOoR2eL6L9Y+u6ejc/RVUY28PHdUHWb+3ZX2BhN1JzZffPzq\n",
       "YESzprSzX/D9o/1HPLDg6B9MWkqC/OgFMYQaNQH8sdk7Y/FyAcJVcKv3RJtcVN5OgRxSL9k++X4j\n",
       "s1ncHtABYBFjQqg4lac1c/4HHRYzkn6h3PSDKRaiHRiZc/vPfBqxBoqZauMbs5Byqzh6fMPzI9ti\n",
       "03cJ8BAcFhw3I43bbWLvmFTXrKfzxylnC2cRh8TUpB65Z3ENd1A3S4kdmXPFRzioLmhH6iogXDe2\n",
       "FgCsNvUHr+Siage3SypZr+q0pnIbNE1Js6c2t9NnIoNbo7W9wjpTT9SgbPmOsBmON7KtzGF/C1ZA\n",
       "CIDjZqymNs3Wbta0ktlfr5aQd8cQzI9UPnIyfyQWNnO7RF64dz9ft1feDW0YOMcApHmd3QuBVLIm\n",
       "GHw7+zuNtc4MgMF9AEkzoI55Myz2XfFhQ6YH5b7PNqn1O/JHeKSotTzcmix1fPj4+MHmKrrno6Xp\n",
       "IFUZ+1tRGkD8WQF/RAx8WonFe7+S8GtE3HP3C1Er8g4q1lIeUFIyjrZrLQ+ibv5eVpvqYYd+yNAV\n",
       "pLEC0gO/63fD2tzJTVgT6ZVOKSIYeTVFeVxxh38tLvv5TH97KyScb3z2+rlz672AAkPwRwLKUVkc\n",
       "8hJfGm419JR20aK0HJn0qOaVwACOC24g9v70Qz6OLyIm73E6PK8wM1pCyelBZmFq9GX9blptDlfM\n",
       "1ehWXFBc+59JH5pNxVTPt6XpFsTzEiPW1RzJq/EDJy/Qd2t/XXWyibwzHdZ/YOrvqYvdC9lC2USC\n",
       "a2oL9u48TOyx3XF9pxSzc1k9/0TLFbunsSVzZZL1ixyIrpWUx0V9Qhyv/1dMehCIkhgx7dAj0ckP\n",
       "uAJA6FNN2Mokjat6YBTBeAvHPC823H1aA1wcj6bBfXc49BqOLFV4CvNvxjnk1fDZ1QxEY56+qjSR\n",
       "8OatcBdwLm87f7Z/ZuXQ7EtTkicR6eAn4UMrc9niq665BrBI2+hHJ9sC9u+CoZdVM72mL9kyz1XA\n",
       "sxHYQEZgFgvG3/57zVmQu4C4cjqFI6fmXM4KAEp4CJ+Ex7lBJ3iABF8lYkbZVF5ZFt8FtnubreUZ\n",
       "Rdnldcu6zFZJvJS4cjSfwn45J5LMk15XpVijrvYYmNu3J9304IMrA3ZrPGVHRZeDtoiue9iUyDaP\n",
       "0OIdNvBQ221BqhMsZnFKk7/8XsvHsCWlw3/NddP+tqdNOlI7bEwTjRcPAlRpJ64xCpgl+0nsGGvE\n",
       "UboBCauBR9X/GIarZnEX2h1THEwaMSxrx3OId0gyZHX6kvhP3O+Tk7zIKLZrfuoCZxXoobycIfq3\n",
       "1kzBmOOOhS/xK5uMe2f+A8535UiYlkPsnWOkQ+Fb9RHYHdPdbYyndW6Cb9MPOy/InJKNdhnEtwJU\n",
       "aiqiikOFJ3fkyuaMW1eE3aKUFBi3iwvo/kiYJEEQUumIALNDo+VAOJuMrKLHyrjJOQJUbBE9MSZQ\n",
       "Lq3uzenHE7HG9x21Wh/7KeswlwNKeYSnq6VMOvbO/I71btMQB5QP6db6BptiEO7KDOHZmsGNKDHx\n",
       "8tnvBDGNlXAQwOzI/t7LhpwA9D3IFTzRgvWheoS4XvdNg3GE9EDgFS08w6LMUCCPbautKHB53oG+\n",
       "7zvUTYzEvx9pZ+aqF1lS2adVj07qnHW2Zd7cBuIzBPQxdvqUu1LAOIMJflv2OHEQEmtVsfq2q7YV\n",
       "fXvEsatLbWfVyUxpWN706dHldoExfmfRPw0KRfu16IRQXeQt9LtJ6NUwmv9r5NXiIHAhiK/xC/DF\n",
       "wWfPO/26nrXOK1puRUswLDWHUtoEhZzpgFgtFebinVXFOy68TH4SjDyvh7PYxnRa3wFJUFHh9YXF\n",
       "7HXawRZw7C7wpYbQ8OBHPEPItxVnReJ7pXd7Hq+kR8EJkz4tInwBbif1V/PnWQlan+3026iGlYIF\n",
       "TsNhF4G4cF+Uo2qHP/Fkir83GHw4H9GUWQE/1F8UEEVMCe6yfOVWenoJRe+gfHBjbreU7/2tii+m\n",
       "Z41k31kF4THgnOumk7pUmruR25rSxSA7DJF9jDSGqNgMCIcldAXhMsNWqrGeA6PvdPhdxZmZKeTQ\n",
       "38TV2zeypUaTEcx7Rj1rCNIeqm15lB3WK3Ut+Mqrt8gfuwNQ8hFTVGhS8pWcIYJBuWsAfk0SQA17\n",
       "Y26zEm5IjBJihgPVsPaRX2VQ9pjPeaxp6tH+A9GRzDOy9ON6tzhyjdtBnz6CALaZLIb/tuzdRgzS\n",
       "lrutJWTXYhdHuwiRxLS0B5KqOWAL2vYMeSYHdJLv3SnZc1CXUKFcsVR2O8esqcP9mV/bBj0h35/X\n",
       "IwdTS2jsGJiIANXBxk7Qn0GC+f9s4nu2Do2u4bIzg6df8bj4TX/CyZgCLG9d8xmP0RlKnr+afag+\n",
       "jwaw2ajSt9/0w/s+EWxyWIXa7kjwVVF8e+gAELZB6OLk6zIdQqmbhTmEKPlA/mwcZ1UGXb/Xg8u6\n",
       "OzjVZ0+5gopghv/ie4yoIWPRPH6qHq3fqccdq4LyaIUxZzoPrIDK6LHcQSdFl2Shm3oBWFUiypqV\n",
       "4zOwVI7LdpFygLGF1G1odNHfkb5oUcFgcTFRwg2WU+X/YIKG+k6sBrAYV9JqDOqf+fi5ITi2RYWo\n",
       "x3t2jtu0QNnw8wDC0DpRsm+hHRJ0C1qQ8epS2Yj1Qq2qIHbyDE1eFQ9W7sIhqfFcUNOBxK+mWZ6S\n",
       "w7c2fw2JzQRe4d3Izf+uBndQJxJ5oGhEcp/EF5pLe08u35IidtMxQntSBpmPd7cJWA9YqKUOP+mk\n",
       "H1Y08bSwqxuR+r+6A3vu5lm5tD/b/bikRoYR2GYr/6TSxQ0UzE/11lJ0GPYHnpqOfCavyS1REkUt\n",
       "OkNAj/b7TKvgHvTTAq7/kiBGpQzRTB+ZhYMRjEHnql3Dekwtv5WRgk+fOZz6IuXUnexQ1igHPh+u\n",
       "a+oA//YpoCo0z7B/83lqn94Wf/CrTF8Zm4DNdyQB7zCOAAAHnm6K6tg3LrraUR+S2/MAqiKX+0+N\n",
       "z6wxZptWsPVFtC8+bU0YQXG/7ajI3swH8jAD4jSqvzZ1uvrBy7JrnnIYt/vrKbWIr88ZWilN+E3j\n",
       "avm+kSBjMywu6c34/p61qi1cuwu531LQVfiBIsJvBfQ8XWBH7PZP4HbSBc2VfFvKrNGLmNeARHxG\n",
       "P41fDJeQD5+9V1DwJy6zzclxdDNtAWnbgmPbsfk5FgT/sDDPS931T7q46K2ECksXw7MhtHrKNKxg\n",
       "bl9Dj5vMK5vSYT0QWF1IyvQz/brhJW7sdQYh7akd8YOvuhcmmGGg6m56h19U7t5M2wrk/giZVeYh\n",
       "U67vkKy3/p7HXbmKSNdG09z+qaIG6hSf78SCEwwEAIFnPRf/ftyE/kv45wfRLauHZe398S43VvzF\n",
       "bU5jnzzsex/LzioaBhBDDKzK1zt1fad1XmF4/wVTXzN7OBNbFvhPQsRndUGLER1Fle/2lFpMZXdQ\n",
       "iIQolJXLbeSvUPPH4kvA6lZf/nWBulVTObZmiQ+KtefOWj4NE91RMsQZEhfMBOQAu8jLmmDr36gt\n",
       "rh+ZIxJk6bBSTOwLeagCXOxvWe2O2vjl4w+CgaefRt8Qmn5Y8B+jYlCuQdTpA2daex/sDtGFDHyY\n",
       "9irOuLCb9Xuyr6FIeboLT0d/b5JmvgblLV0C62d33cD7yXY1nxAXnv8BoqdhNNT8bxl6f5FyUP06\n",
       "+6r4yyhYxJ2Dw8xrJ1tgWY5Md31MkC9Md70CnmlPv8gCeOxol+H50R5H1AH+KtKHmUyD+/InvH3/\n",
       "1n3H1wyOq25GEAOqpbw3VjbW8gK5tDIH0l7YbzxrScd/pJfg/zISdoEXJIHLica5g1soQoFbOlfp\n",
       "ymgDNBb2cDgh5JNFoAzKwjEthT7NFv5YiGlo6TS9YU27TsyfHZCnsAliZOXR0bohOjDnfHV7CJmt\n",
       "yxtYb+JOfzEMihdmjfXqpWqFZHU+APLlmEcPu2EpIolJ6udy/WyapV56Wb0myh7WYACfbOqqFSBf\n",
       "ATSOreBBqLK+4NlXJA/DVoZrIsj4YyYB+Pe2USm8So1oE0s0tYRJun2p/+PCNEOuWHqMUyqIxmrt\n",
       "0NA+hdyiI3PKzw2lLJQayokbb9Ouz7NPVCv8CeYaJrkrUjeplKiowyT21DAWjcB9OSgBdTKb3m48\n",
       "+brdkn49yYAAjIJyOCRmGQdwYQanWWUgkLnAuTwClSt42CmHOLGJFTjhh4k6UJPOBWyn0T0ZbkKd\n",
       "eUfAjT3N50Vh33sBnNG/nvrquSzmgIDOL5OBIguieABAtBLcJUbRUR/QW28WshFIyheucMMDxot0\n",
       "q2j82S5FQjT3vfayaVkstPFBwobBnGjCZI2ucW3o7vmyeOp80EdMK2HLfJlIV1dcXt0RpWXECGCv\n",
       "Ygz5bjxU+osbEzuO2dWBOE15Akx2m6Gr2hLPF3+3JN8PrObM1jQlDiIHt4TYR6BVwWi0fimF/oB9\n",
       "uj2jur11sEmeWnXUYUHTR6zRyLpiUBiYMBawxXECIU15GHwK/dvbgGCBy4hhTxkR1FsxZXzCD/RZ\n",
       "r1Hi4sJkC+qITssAAtq9KoLmTHg/XGyy0zN8k+YI5O5360t+ripIilbnNbhATQi+KFNtoK49lrL0\n",
       "UAm1QPQ/dZFydcArJ0b3yiXvd5PUYYq+b2+PuLibOZDorwFTv2wxEbwHr3CnzaXw0ugCk8jqUqZ1\n",
       "tTzxvlEI8xCQ2CrSSiu8kd2mQCgjLCGEzl/og2AJ67L0cThSYhBHbvP6OVqFK0s1Vbevdz4wGsjl\n",
       "mYtfcYqafshbMDEP8CbPZD/dvaChJGtODikB8gwzIoW6SZggYsndO9QG+2xA75clWUE47QlmdcRk\n",
       "xTmxDJ4XQ7mcldJfjGV2DnxVuCfGAIQrcmCQTtM13SSz78sEY6lvu+LorpDoCF/TkthguscdTNZ7\n",
       "pN3OO12lIWYrrdvHE4iQBuIYYaSBumIgYbzWzjeIbp6nqBfF43yQv9oBMVRGd3+iNixZlOhRNN4r\n",
       "FXZdK7wcV3eefcF7wHnr5tVjfAVsXfVV4aXgmr2ueWtBudFWaXDdwdbDnYEuof97GpVtFDPgrnDP\n",
       "/C5UwypNCWv9j67JOhM1femwaEFOK+BmqQcCox8Lwkh8neq3GixdMISBtjzY7YXXn+AwVNtf40gG\n",
       "4UwlIfCEZ9Died8L0UGTxIf/ItAGQjVNMzWC6oGpAiktZm7oj/3FIAtWHO+PYTuGKkJkMlTGsMAT\n",
       "0tq/XAh5Yjp7ZFBjW6XDUgHRV+OUfR1jiRxCxHBg+MvyKqmO67pc1P9sp9/d7fw4lax5YLtOi3Tc\n",
       "x7OL/ybxtLHGPho3zqrd1hRtypvYoY80KL9E0wxLf9H3cXZf/dsf7dX1uKwAF9aDT4/BOzepwawn\n",
       "QA3hILBAIwayBwnXkxs19nxdJOU/M2ikHr6T6wVgL5waWomrT0x7N2QRDKwCFx1nP/rPAbNLL3a7\n",
       "j5hnGBRI/h5WTa+myNh7Nq2HP+PizuJfF2Ndq9aKNOGbX97iUB+qSEp5qBdwFTwfsp0z6yii/uEi\n",
       "lhfEf7flW0JByZeqNyfZk8/pXvVzLAyEAGUcTu7AjDKPg1snVLYwFQN1lATWVQD3++xE+aNapkNZ\n",
       "cG+QTj9DN/qHMHM1JDi6ELcttWzKxum9yZLQREp9HOTruv9XaLW0Z/4liiWwjf/5lCgPTjn93rPt\n",
       "fDF1mJnO1w5P0mYjYbHw0EOpbJ7u7iyIeQkgAQIZtnNFBisY49uG9RHHPF3zI0xcicnvyFtv7Wsq\n",
       "R26bu6tDIfTepw67bn5u+mJZgLHw09N8/zwB2Qvf1npjHQMVT7bekyjCUONVOII0lZmaqetTHjCV\n",
       "3BErsocksXKOrlLJrQrowArxVQoNFJZ/QghBnpDsNbAlbmzhOcHbzotwLKRe2aYxWqBbdGEnpGk+\n",
       "mrhq2umfGwXp/bJ1RRYdQVZUViNwgFt7YYvgOZAWUXAry0YX2B6vgTwrpLnSrgRR/mI5Pj7Z/5+b\n",
       "RJ05cVefdAmAPlwfOlsRqPn9AJfY8E63FhKHP7AsgbqWM/eWLmXaW5zYJKNupF4aG9dwE5Y4LiuP\n",
       "xYdvFWbr3krGoyAGnNqBNwdpjzo5cmsLmtr1sGKE1sSeY12B3g/0EOdm00Fsor8HDVMbfPfRdmmN\n",
       "4575Uff8v36pZkZleANTWjrPPQ3TjGl54WGk2JJr+M+xiP5i5NF3fc9WMu4p9fIDMG9r815pYQhC\n",
       "tdaaMwKGhM5qh4EjfnZ3Obr86T1r0d2ZEH1dGy3DjoMZGLV9NrDUKojcAttZHLS6fXXgU8bxCjNU\n",
       "pNP/NfKaEbNTV+jYFpOdqoNKC4OAPFqL+GXRTvFN9oCFCb6saQYmJfbfm4CKPm/k1p2Uo+wDKptZ\n",
       "DxZGcJvdWGO1T7aq3iOfixjMmlafgjYd2EuZ5ORbnWqQsu4bx4p5UDsISqhEakNXJ9Zminfu7K5w\n",
       "WurWFgZkcXyVeIFHa2ph31WU8fFV4rt18R8xRoCQ8Npvznac19kQJ3ouyoANIA5aksTpEo8SA7lM\n",
       "wSHAHRptdxHHHAfvTmRYK3U8OY1Zw8VZ0Uw4V3nfD0IFI11qF7ZlJoSAlQD2NTHAMkn43Cnyd11c\n",
       "snj0n3qpaunV3r04VHk1XMhAy9aYH6GgvABt/RU6e20thi02IFd5R30p/2dbEa1NA2qKBuPwTth3\n",
       "j5AkzmuvETwJPQ1hpbCZnNLOwyP6rmj+6QhBPCbVwWYqwWK7NizLVM+qpTn4ANJCFz8CMOKQWG0i\n",
       "xd/pmPVhnrm04LW3MgzqRCSoMcxw7ZY01m2W7zKQ9/AWy4EKLIPJjSWRCg4gufqm0QwQAmlPEn1Z\n",
       "BeZun92GPN2StbLtaO2jdYeSCia7+7meJXIg+sajn8iBy9dFtkBepiHngv/BWhg1GZ1YI3xrmq6Y\n",
       "eHFr+eSeF3aFNVTq058Yd/IwRpD3Xq5KhbAzXb2gusdpydER7OQwEbW6+bv5GCxAdLHWhmMfyi+k\n",
       "GWkk1mesuiejp+EjHXDlMfjIHzb/KkkimamY72V3XgHQ43mKA7aoPa8Xy4SNN8voFZX6xf/UJdNu\n",
       "4eM2m9u35uW0JjHGkQAITd+SiQN9igVOfoYKjAm90Qnma26GIJ9W+NhD/QbWlJ/+xE7idCzQCx6m\n",
       "lNmdUs6AtHG6LiniTODZ6CityTBvqJ+LFlN59gjKOv0lRxaGxUBostqydRk06WuaTsuuoRs8nJDt\n",
       "/mZfu0WgaHEPMv8E1CdemYygG7xXQvnGG17XeoK8jEKW7v1Y2zFTnPsOTj6wbPG6biyJ4e7UTAcX\n",
       "eRitPFQq6rgCtaqJ7pAgvxGMJdW2D9hfmclxVa5AraXC5//QRRb28APlm2kC0K/BRAO4+YYbYK24\n",
       "xJh9/PRWdESRft8wh8hqEpFUyzrIJyHm8OV/Sighl2UotFbfttQw9x9WX/VkqHT+JoSCPTGjZ78g\n",
       "OE4AICbj99rM1VPHvzsbdmCqf3EW1Khdadx0gvl3tQrA+dMamcaRtbl2iSVHkmZ0ElpYAOESbCPM\n",
       "3wYof0YryQ+9nnKx3OR+iR+AsLQgoVNVKCEyzFYLmccHnYkJgeyDuqiaRaOBQhfoSncgdu0lHJ1Z\n",
       "md2hUKxbmd0TQuAVaIBdka7CN7cFFYo7265yWULQnZwjebGI/E/gVwsqiV3lhhvUvRCThCj6vASu\n",
       "Xq520d+Q1mJAfvCEu5fEcw96bVmlb+ghxAjxIFPNuAQ77ejmg1lD/N2iZQBEPvPKU/rAoJO7+hL6\n",
       "ONlPUrJ9viftq2gdrFpAKkYtuefWqvhVWt4DRQEpN3J7MDpWtOV+j3agwGWcVbEt62iR+nkHCj8w\n",
       "rFGtQJEv/0TgcO/NXPIN5ncpSA0uRaB1YhnGP/THX4H6okVdLddoXBornrUJO3NaKpAKHaKLUATQ\n",
       "MntSaeAQWWJRuF5gzLpiF7jP9qBB3usaikEQ4W+dPJPshkVg5/ydd4DbkSIqLjR8ngvjG71FGAUT\n",
       "Pve40of9Ap8hcNQKZHIbZbGZ2XopKF5H+2o6+vyU3O0Kji6AxUGofLbN3H+ObruXSqm+QWrrAdud\n",
       "bfs4IYd4sXxSbOf/LABWxX0y/O1QGRp0X0vsXySObWmmbYphJRvaH5wkQ7+on6xYDo6F9cCijy71\n",
       "6P4/1hTGgouYHm2cKmCr/p6U1MuiC+/Cob8BJ3npBqqYv3JOMuGmJJFjUhMDXAnIKCsvohdux1Nu\n",
       "UXLq6GcGhSrK0P2883arGGwRRDYI3nDKzVUG0x7Tj+m8ISTUbWOvmpbp0M+jBw6+o5TI+IgrOYTi\n",
       "ClBifPbvFZRrnjlZGPLqFthVTN9qXtk5t2DndJdetPMG7PSrAurjcuox9Y2Kr9riIDhNwNJYL1+0\n",
       "li3gB49OpodDm5vUTMmd1eSKu9qEfJljAcATR0pUxLbXaZvfvNJBFXZ+sXm82CyHx7sKdGE8zkR+\n",
       "1aw0Vaxv5XuKW+cHK7ZYVF4txlMGKfv4vnjbaeQce9pLqrPiwtd0iaWCCzKrPLKln/yH+w1+30bm\n",
       "cMExRnYnz27a6fDSurugeJMLvVgBUtsgtqGRXidb3fS7K4v60O2x5YcX8RarI2XJzF/zs6hsmh0m\n",
       "WbmtIoHzPdYW+qr2P5T/WuQfvn4WM4aAsAj2ObqyulK/FshZcQHiYmaizRAMuQJKelAPTs3iVN49\n",
       "RQZPVEpthSbkYQMcu5pfEGCpaqEpWPgHNZVApFq8j0l84Mtq7hrJXt6fd1xp/I2duBKqx+cNz7Uc\n",
       "LmFB+IofUYx2y4VmZ4m2K82pB56EDMCiS3vtKzR/09W96bCHoFAlVkWauml7EtYgy0FgTCNLUF5P\n",
       "jkG4FY7s8/l9EPCR9MUFYLMb30497jNWOk+o1R0d+8AlRHDM4x7e4rCO5S/0zgI2/1s/0Do+PqEz\n",
       "zHi1NOD23vsFby0s88+Yar++uLLHw4NI9AeCaC0usxZ7DJCBSO2k+x0x91LZLliHfAUrAddD8W+L\n",
       "m6fvcHRe+D+fvFQ1z8kU8Lnu+hHcXF6JSSP0M0ufJkVGRqmMksew2Ya1OxtszVgq6p+g//1KRjhz\n",
       "7KfwB4Ed2gmeH/m6pTXTYqp1N+LBBZRclmxU8vJoDyD3hO9Xb9O5J7ulG6JCuBFP95+zwvAMc8x3\n",
       "6tYZdRk9QO7HGxbrBb5ValPj1n3VL7x8XIyYj/Hks238ifqfbjD159hSe1rgui30FJ7p9gwpLzRm\n",
       "ppS12f6avdfweZKsd3T9X9UITZzlXQ1Fe1udjGnqfBhDD3gk6ActeoWPkAvn5D8Zz48YqkUnFw5e\n",
       "bDH/41IhvQc3TmrRT7UulEYO+F/2Ig3YZ6zCUwmx9wyaznMwFXVtWK1oga5XESLqCdDyifG+L37B\n",
       "KnNA+n2SfU1pUwfl/+WXbj98vhWlcYRVpuGSqbGLrjsBMExFAAV9UMIGSFe8d7o8VCjW80PnJqDn\n",
       "9ORyDnAE0c2npUUhkj3tzKC8x7gVfnb+ouek+7/ih/As/JLQ5t4zVVRLq44w9q9tfQSi6yVzblB3\n",
       "OV60gArBF5Zdi4+4vlfHsTTAiUL7vIOYF9JL3L6lG24lpWYX1hN7faahI6dKhFrZ4DFvp2DphgRI\n",
       "0NXa7hOF9elY5N8KWdOS+VNZ+5bEVrpU/uyTmMVJuI7Xl0r4QtYYWxaMMayY3CiWSLNP41l/k5+Z\n",
       "FyJ/8pcTz0vPhzZSJzT9WlnpmNTPxG5OjOYId+ifPulg8xGJS8Dma7bDhW028hxJFySzqq5HWdLR\n",
       "cPE2raLH75jpcBqXR9Xvt1g6XjZtrmZB7NvLWLh6Bh/J+n1MUpcv49aMHQ5z7g0Oz+TrzN5u0+Cp\n",
       "Hz9iWDsWUne5Oni7tbSu/ADE/KlDCGQNfhLR4bTnn+dwhMWH6e0eYCNQY6p47iCxO1zkCV5vRBjI\n",
       "7Y46FilFLJPTNB0EIkrJfWtAGEDWKEzOXDbywiTCMRJFYOF6OxIcNQOAEzm9RtoGK/lQ8/HBVQpX\n",
       "wp+jSa/H8zEdAzs93k6exBRfug/7BMXv7mWaDQCb6qMSU7foqt0i0X1uBPxyOvr7esEvJ5p/vp1V\n",
       "ywPqTuL50pd9HSHOjmg8DOjcaXMYnb1YtqoupHGXpgmm2k8dS9iOMKo3FvIWORoqGwbqx/ua0g3b\n",
       "721wClSBhGdqGvrGnMEyPr/u05/Vacz/1o6djjMrA3M8IpL/WBegD3MmodxRzyk7mp/pKPUgR2OR\n",
       "d/Mojlr5GM5TelyA2qWEBDaHlCaTCwsXhxR+4oF1kcLSoUYok1bf0X2htB4cZckvF9b+2ywaKWul\n",
       "MGS/hUD2fFu3gjuhiNMgNkctvceWJxWH3DVDbABSgxl3IaLur7XYD8Dth1oX+8K17VeH3DDB96qi\n",
       "sMubTtD93zeqD7XrnThycGGN4e0YcNw3iF5IIe2jB09gbDiqDo4LO7kSpBUFEnRb5CNZeNzn4zy8\n",
       "X+Je0Xrjuf4qIkS7wXYI/++WLqI30Eq90ODbF901n0TA4g8erlRKvt3dE1V16TvCtXTU/x8gKF3s\n",
       "vWZmV1g8fPrZx/+iHyA9peS+h4X8kMryLxGuhkAz5csSFk9/S16zKnA9oPi3k44Swz72KutCPhKq\n",
       "yXA1eGQQQTJG4lVLYCf/TWUGVuLYRkxRE9OB0sNrAyW59faqsjJeg1YzZbEdbHwO9DBcVu0CFW3C\n",
       "7Mb8J/ywrqyq6COlNFLdSJDjtkk1MpYAQ1vZ2rh0BgzyIjIXQkhXp0zZqGzT53fLEErR9jEd8yd5\n",
       "tynOy7BWQmceNa43jim2Nu3BXQcx/0YUrCywLdCPDc9KtHyTrxi0z8UCYDluAyAScRcjbllCFwkR\n",
       "LwgT+St2j7XgyhJm2OBsHEyIirLBdyz8o3UmVzl/AUUEaeyyymHNZIb3PiwO6VUJ4CCxkW5emNMC\n",
       "PXLkdz1PETei9oI9jpZOwHqwyoX0SXeidFZQpCqGjd71AiCrsiPpf8WLGt0MmK1PSRQChR3KMpKi\n",
       "tz6WkQX+ArhqMAXFT4pt8+qeBjsuC5qYMs5DM6pTDQcPaz+4Dd7GcU3SvdR2voqiRgZBesrW8M6N\n",
       "k1HLt1sjzQBZ2oPP4ThrzBU8wThuC087+XhHuIy+D3w0BL7MTWgbdSaw90+BiYrWY8EDLCZopLda\n",
       "wrXIYpbMFfHK48gbNV86gLTGd+wqneKW05Qs26qeoDix7Uclqkq/wEBJUOnBxArfd2ZJikk64Tvn\n",
       "N63njYkwksodfX9DNVssODP91+xTbj4j//gaiKLSC+mE6SocXf2RPBwgVVbsVd8JsKOz5smZvr/O\n",
       "N/3HnSVHuLTjEt5umTAmOXQDhHpgQ6kuKzwS4gvRlbFqFiPf191qoMNzXZsdSpE85GXSkevkn0IO\n",
       "5a7OlCMuhgRbAqeFiIMQcvGoYvr02EMGV5pJTqmVFzgHU47t+Sn/Inlzf0mNsxRKasuRH25jd1aH\n",
       "ke/zO+9QcGZ9cLzjkACAdCgR8z84x+gu0U+0eW/2OSi7jFTwp+Mjll1zUOJAODzanQUqTwiIjvVi\n",
       "aVH4hHf7fLMaLD2O/rlfLcExjiUcf69ubtENRMjiiCGcKZIINoWR34qQPuhlV533ARzp8XWiJlTx\n",
       "6d4xqKNdi0R5JFeG6s/T5ZWaP3u9y6RYBL7Bzs+L1D0KA5zskq7Ot8Rb4YZ76yGIHsFydoROiw96\n",
       "RLzDCZ1QLvh+by3HAV54Yc5uJxN+26RsuCnSCdsOtFtpwc+AG3XMCHhHltOge+mKmojczSPhEflG\n",
       "oexjRp77nvgdNwTnSVLO5QNa1nC1OdiKEjMMP8YqF2PmO8Z2OVZ6Ksav3TXC3pvADGcXcjPb+SD0\n",
       "Ga3/vWzmgDRgeDQutZRzoFc6dSjKSrIvULweRHP+OL9csIwrazDztvaIXw3Fnaee3Ad4T1809x0w\n",
       "R0TpcLSlHXBrFoXqGe9fz7nA8g6H37yg98ClVWPSBPPCy2gG9WquL1VxquVcyS7QQpatKPuIjngY\n",
       "nkOJrEOcd/4Z2hiahVdBslqfa+uSS2WAqvopu2mIRpXIu3hBqvSy1B5U6/Z9NvKJZAWWDnwdhmDi\n",
       "oHYbf10/8fEHgbpHjfuCzROcLOzli7gR66VD/ebMtS5MUX8KkEsaiVg+tAdnOVml5MrVVz4Jc8L0\n",
       "XHzX1oeH5byoWeTALtiPRuaQHDCWsySSnGDdfa5bjFuvUlBfk1Q/4ybSNxlasQfyLRl/0TFJ7K+I\n",
       "+xJwqEVyom8nffgVS878bhmHi2oj/yc4qVr7+TScDRNoRiiWDZ3Urx5qq4IuQl3ZJ93T1s2KVXLb\n",
       "t7AqMulRLt2Etymsj8aDOI+nF20o8FiC/+GUCZ5KWS/ayS2D69hyNFreCmnJ/dNS2ujnKULvZDV2\n",
       "YeRWpP2LB4Fdv//lddYgJ82kWoagRjHBAHKsA4YUzTg0bvL/2/N3/LVxxDJv1sNU9zM+PIkuCyn4\n",
       "ScaEUYiNHDMJ1j25X8Sc87gv5C+XtOfx0hvg7ycyv9HWB6BB8z2Y7+XkSaG0FlKgaQo1/BTCzys9\n",
       "Bkfjib6lNCjbLafGHqAs0hHWhX8RHY3xtmoVhoihJjNXIkQJUVa9okgzz3neC8MuEcXb//EKv8A1\n",
       "XhSpPy10J4L2/araQV6mmloz/wACZl2kyv/QP12WvXjTzwoGUeznL7DvwSoYVl6EK83F3Aknfr61\n",
       "R+joaPDcBeoz/qurwCSgElGgKFBVcAHvmnisJf6Xz8/ut21gPW/yxSWixP5fEaczbXjQdd3M7DR5\n",
       "qIbn/PlNiavhY1IazWUCd+cNlWbJuudfuqUQvb0SUnSw8Xk117CWC1Xf4BpVg+Dj+qLYNM2jeRlD\n",
       "KLBWn4U/saQfvQWy/0L/bwAbf6orGZ7odO4LWgy1X6Havf8i4Gygvehach76KF+GlEj1nAF5gGEp\n",
       "TWkwP0WhfnUsCOwP726UN7bqMzxIHuGEzmqQCG5R5OVQUq39h2F035Ku5i5X4duVwAJqyYCdedaU\n",
       "bpNb/MsOv2B9X0iQzqcz53qxtn7USYp8ZIZECpN5OvjPZtb7n4f9Qhhdxjzl6Z7trjUTDQ/HUxvF\n",
       "w/Ogm4yPCPqxWPbtA0bJrwcYJmGV0vQdyRoPeJG88sOWUwGTCuqwiw6E8kpD7P29Gf4oZe9qEETP\n",
       "l9mZKwgkItfnh4itSC0PfMN/+zkTej8KBYdQcru0ALwNjjnC5Ty4GWh8kGqxvGzQTl2NH5vuoX7t\n",
       "rf5AIuA91liAwZZQ34hTB4UcohxxWinXMVj0rmAypjoqgv8+bd66mTeluUI+aYrjwvt9f9EOqG2H\n",
       "I2vru3n9SE/xT8V8/yxaI38zjd3kfmlKhQhIzkVgJxmlVYzyzfF+sNBbM63MdVlw23h8EqYSa0We\n",
       "VldM5GwB1A9aYPRI8AAGXAZIVB5ozGQqiRvu8czESXC9Tfh2tIuDeLHwQv8PgU6jo/Ac0ivoF7Hi\n",
       "OmdtjuS9uRRNBkubdHLA2tpzMrmUTnn6ljgsCCGJjSTXk95SzBqhKAFnAhUndS86h2/+IUFihw8u\n",
       "izkK7MPhOWAt9HU/GxolphMP8+sSjkBPMub6a2bRBd1WH0oUJIImEbJuXCq073lIvTglncVbVl8L\n",
       "9XQzT+N64+Kp75v451lD80rZWWSZ6lj+06GSeEAoWc1PtWx3JNtSJXHbb+zXkS9ChPM2975b2QVB\n",
       "dL9YL44phtlrPrNdbZNUyo0XDRz01M1bIIAFDFIfzemvE6dSWleK5h/dIaHybXRImvtD6qDqPwFZ\n",
       "W3TEYgvj6QuCZy+mYQmbPfk1OBN80zvBeCD01hRXsIrgTLLJ/2SrL5MJa5j0aBUU1/LsM652PMjG\n",
       "j0zcL4Av/29F58+W8muRJP5/v7UL06Ky/t1ksFtqxX4NHlu2hAk/I+aE5Dcb5C4E50y5hur6dC65\n",
       "MqKvSHNuSQLUKXQZdnq9NlewOVnFE4B2/SEQ61HtGI5qtQhbdYIXZ6Ikq6CyEZhCRby1jjg8btjG\n",
       "J80elBEc+GUeuBjNz/1sgZQAkGGDv3K8ME4YW38xYC02bWSZ2Lqm9DapROX05N+7xuVtevqnfrAb\n",
       "7jRuf2qtgPku2BIFWJNi7psaGRguPx8cj0LsD2YOdzd4slmFkKNTN9U2S24AE3M50U7oesNtpySl\n",
       "dCblAXJDDRemeLJLYXmL6r5ZpGUDCPWAIIC0J5aSqZDyyLNb4zbFpNTiu0i9OrjmTdcFqbPLrAsg\n",
       "sfGQ5PDzKURFkfVLPqEE57vWfUrBAHcb35Y3cveN3Az0ml2NWKdTu0y1DBQ9gKyYVTgabDEALxgY\n",
       "z2S6pP8SZCwNPKARs4pYO7QpqJ7mLu03KKk0sAcJ85Ffo6wJ3eX+TDe5V3aohEG3Cgb4lEs9rL3y\n",
       "B2t/Uv1acV58WnPHs9c/LkPbyZ/YWvdvLa+PQWU3aPJjRR3ipOSUrjXFfGrK/GRBVauTC9vWCZQr\n",
       "0RSKpV8/1gbOVeLRqZXpI3AvhraaUc5PDrmu/YZ0xf28Axz80mv8dCwaJ/fxVUnOULMPT7a+YUHH\n",
       "DxiFhZ+CiPo/0Z1WWSI5YA3s9fejdGHB09WYl2JMqEMzVYJ1nrzguKiA/ERSftOSipHbaKpO40pr\n",
       "Vk6vXOUS53CL5dlbw2eXwPN/RMuPKwQyGlHETGr/loCyNSCNTXC+/E3TaJGxuVqCh6Waq4Z/R0+O\n",
       "+0r+tbLGe5fF2gfP+zQUFZhkHLRHCp0rK1QD8VVKNMU500/hnfdGV/i0tMnVS7Frl2luOq09adcP\n",
       "4NZ1MI2+GLtmY74dbLM08tPmFN/mpckRMvuzs9HNZj81viuaw/HtG9c3skBkIaENQpx/pt0z6QSL\n",
       "q5CXz9ImlRBRRqypnvrq0pDqYUtFjZ1r7ZOY8CSyoprnSfO5OdeQgUYJ/OtRkBcEO20S6AO4NLnE\n",
       "4eJP5XTjTPNNU/+J/FBTyt1qVED2ZMGcDHtGWZK+tER+H1oAm4IvFaI900dQsEUd7U9Fw5V699kB\n",
       "RnCKcdUCa0seGVDVZVv59dqCujvI73yG4rdH6hfJotMmHuFJkw5pgnkVu3LmsaVhHuGlLVfW8W+f\n",
       "8x3rZt8plkE21+IyEdYvYKmdwVwCmMqj5w8YRWylSaMf+zOwEspftrPFkW3qSJjZWQnL/5Unzfn9\n",
       "w7NibxeJ58yEQ0nkZbEZJGV/aSaHQJoyCd7R6AZD9cYzjbMnYrVpsjPFlh6pm0QK3cAuJ+56hQ9t\n",
       "HPwgMx3oMgBZC6iu3Jae66y3phfABKhxcEz862nGaMADylRofs4/SNN7Vij4DnoVLXt0jUHFYmnE\n",
       "OGinM0VH0lJU7ZDnayq56AYyBU4MTMfspI+qseYWj2YgFU9RvCppHZiMlDWlKJWtspyfMyQYYVWg\n",
       "NqIj0foGNw/G6ArObzUrO1ocS41eyHyiYd2h8/J7nLbVlrrLFeexMZUU7PyhaWzCzfHDCVeAgFVE\n",
       "R+ppMsoqHWMn7iqXz18PHAji0sFkfS1gJf04RCup718Ex3zSGao4wlKbIO3j4x4cwU6LUwu+ZDCD\n",
       "qajDnAawzAE3uQiAHo+dBl+s6mzrGWEl+65eeeHEcyFbOgSYGh5soomG7tac+V6guDRpMGFDRg+f\n",
       "jVn/Rc5zLk2r39lFmhLwnwB46bkQHjdofAxAvBoA5KWHZDKtb/Z4zH99Ras+ZCGpIZTeMNXe0v+B\n",
       "H0KaauyCrZ3nsmA8C1LVan4lMg42He7h7YDrkw6fcAirzslvmEtiJVct8sagnU8l/67ikk2K65XO\n",
       "kQrtheqBd4F8/iMD5BkXvQV33hv0nYClTAHKTRVgo+0wSH0+PcoVEGfTm73vuBaWFUCJGFZce3h8\n",
       "/HTSmrAbagXz2jndBJJA8IHXoQXynisvdnd/iwBOXATprUCUAaJVUAtL1SHRF5AjrXQK77VVdK9V\n",
       "/KJio3mr5kjk1db0In973T9s1Brbd6p1YyslfBoR7o9qh/mh8kwD290/251P28YYKwv9fNUS22KT\n",
       "YWSpN+LQyt5kzlobMlGCYYRbMyvkfRPLss6PcMfNmNXA3262DdW4SQz7FrpmwEhZKfbFDELYM55w\n",
       "1qZ8oVY1Fx03eAi+7iMsQ9LFq6ZJxqlaFRTIw4HcCEapTIquyOc7rEq9HgwQK5+FtqS+w0y3vMUc\n",
       "KH6O00BWN3zYxxvf5W7gf7Vn9DgLAcWGBHH77lQ3SiLkyWj40hoBP+3GGt/p2XezgEftNGm3DMvL\n",
       "Uo5cav3JRu8Amk4lHXSSpHuJ2GgmT6jiX3DNH1JBL1FYRDLKIItgsAIXe1j1XsBk8JzkCRXt5kXB\n",
       "q33kmf9MksQ8O9a5bvuf9b/Qt/LZBJ5/XAhg/4kyyFSXxuM67vrnutiZnY5wI1zW2jT6pGx3NqYN\n",
       "kmo3LOT53qHzi2KM8LnWO+UFI14T9RCt+5ssM3ZZqZXcSZulDSDPg3ZIKDtt//FKudPQy9GctEdb\n",
       "KPf8VM8Toyt8nbFOPhudBGMfHtpUPl9va62K69RKa/9E2QXVF8X3/wxZ8KUxFkm8E/c8WfUIpcmF\n",
       "qnFD1Uwo3q6fUokhQE84x9k4X6zkjv9RKE0ehKeeEUYDYBRs1GJjbcY/JRFfqAYyGkjf78otob8R\n",
       "pOfM2hLu83pzl+ES3g9cPDanrorKwGvJBSUG/4tcR+SXsqm0bPwWqebyYjDaCn1V69k731M9GqPf\n",
       "GYjBZSlt1eVWNNbzvhb8O2czaDzSbK6nS7+xerk/ewwu4JXZzEbJBWBC5PWUPaVKoh0sikOH+jK+\n",
       "PtdKQ0P5I2uUEiLWnU+t5BNPS1WSiQp2vCN1JMdMW/6fBm9IXCImtNvo/vN40bcoc1mPKhzAsHVV\n",
       "DjSvBSEoJdoMgMgTYlrnMjleGYkb2TZK2K6BGlE3PlhsBha4xovFVhry8i81BvRJxrKUPz56YkEq\n",
       "3l4ClDneV40ODFODxoyj7xi8oFaoGdSEpi8NJUYZXLCDw0aiQUy/4C1Y7xX32d9Kl64yJyN5A5Fb\n",
       "kZotNqgesfiC0tkSE+L0T/2QL46nzNbLTun54fX1aAyrBHKAnC0tXDKtZzGdYCZxMCS1FS74As7m\n",
       "zEazCG2pvg4Yuu0um1+zOozzsinY6kTTG83RS139bBYGH+xqHqdP0Bl4arVTAGBJPNZaMlrAc/UK\n",
       "onaVtNLiDatvl4ZZNZ11ICKFYv1NydvUFVV70xI7o+KrOHSQf/fY2TooWWiX2K3/Ei7MDKKl5Izx\n",
       "JScvhnycQn3Uozc7As6Bq0UdBTSkQSB9mKjKZNv2bxoizT6euks2/A+fHX1wB51mxUY1kgYqy6UT\n",
       "q7V2bBCRoDWtIcoK7kymXmtEzS4MZZUT9GswajDtjFfOsEgC2tdQj1+jIdVp3IKk25IW8CxedX6O\n",
       "I7mPV2zQ1z3CNdHZjYcP7PkAa1DJsOgh+CeUacAZmPme9Z1GFhjhJQw8/6XCPCEtO4CEIAcgrgqU\n",
       "xnIBgjJ2/UBB+B5MYsH2T4draFbvPHZfmL/XsCjAnOZjCQ99AELLUZqij/bj+uSHRuoLtunpxmVp\n",
       "Ru9S+ITBcZh9O8FHshOfSBxzRPk1CN0xz6yx1LyqoXnTTarmni/E2IVl5u0Sq9DAHoO5TOBTCTsC\n",
       "OA6ekW0qgISCfHsrwfsYkh32417TA2UCIdcMcwhFHkJYpWjPMjqZ8wt1EYkq8XQ60c5VZvZ/cUMJ\n",
       "P/HcYSt1CgMnMvB9sHGF00Xg0oUoLnUo1lJWlaSF7RZG/Q2Ct+Me03sCEH05Haa0yzQ6r4SzUPVR\n",
       "E1cUZxTIVtejI8fYequmXVXUskjp8mAu4qgBRMZAufb+ALQn98r1n15Rra986S3DIvOuVuPFKUff\n",
       "6sJWhI1/iopDfMfJSjiUKVlIN/4Gsrxe/lhu+xQMbaw+vvvjENNjyDFq7fzvcvFT0N7Am02uvwwb\n",
       "T7AxQ4kyOdbkkJVYlz+e1SUFZSWuehBrN0pTYZ7oGk+bBOkBa14m3mhqarE2sK3mnYQlZr0UuEhC\n",
       "VgPCkFBDnzJg//iSJtoyVbigyU0hEVBSUO0pLYv5AZuJmpqrtTeG7AIioXfklcIZtCH7MHG9FPsk\n",
       "zP0FW8kYK5r9JEFH/PorVOPNBIOZ9B48b4Z8UfiS2ebI142CnIVfbwSFMn8ThTrpIpAa3nMrl6GE\n",
       "+SvTANiySQBpcgfaTxGVAuyN1f3Q6UP9bKU6XgoJVjb7RQfW0u9RwBUgJmTHwpmuM/Q9l1zS5IEM\n",
       "+9VgFNOiseINqrE09nR04DySa3ChENdTS3jQUCFtYAfheuPYR965hVH3h6T4zYs/ME/lWYB6JxGT\n",
       "hmH9jt6Ut8v3Gs3hoZzwzL/qQrV75Rb4qVAVIP2admWnFF9x/yjbBr4ZnBPkqAb6jkRVKLTHDdJ9\n",
       "hc3xvqe06YLB0g3fD9zjMNdsAt2AtQvBYI0gNVdY93W1fkBgGfafIEWzVevV0J1yWqY/VUVhglUS\n",
       "7xAdYqpY92wAW2TD9NQnFNvqCADO+KV7OGmSM8ypB+XT0Vob2sPJ4FEy578gXponcEtogA4ff4kH\n",
       "N0Otw3/+2nuQhbQ9LdLRunHh+1W7k2y8DM1Y1JBGG0eotrhwBSqpK9d1bA3uPj6FJRYHupxz7St7\n",
       "dFGxsyCKgsAFYSNWdP5aOJAQ7lnaj0E5Dcoj2WjIf/8lLgftN/b5nvhpjLCjBFLwwYuFLCqQ7WyQ\n",
       "xGXmUhp1q096xkLpsliIvQjAYUMrDBXIKEs/GKnRc7oZPm55b7sJmsm0HFj5884lWryh4ZJRt3EO\n",
       "LlRKySZXJLFs1E834va0ZD+1FpLMQqt/1gbZ7F2ZmGxuYRlVcTHKsOGBBY6NJkE5mVEvmM43mMAJ\n",
       "72zGBzFM24CZp0kkSuOI2u9ufxgF+UnRCcoULi8heWc7ueO3wRkhW3W3OoiwjSacmfKoDQbHwmHu\n",
       "kycAiKxQ0qtf/AUN4/wZ8Osi46mw9P87Wbi6NIU1xkXAXdAyZqI2bd1sqd9IAfDXjk2y2A0rh/pX\n",
       "9AevwcuqhlJkJyMrY9ZCUwDc3M3R2ceVk1GalX4e+uwSBW4FL/bF4tSHGHmsvKgYmjDLYcOa0cMu\n",
       "CDiBCnVvu/J+s3F+B7ibmvVNOURmMcdntDWsGcfFFMek7eFo+NwDEPzo21IrBqZjMuoKqbGW+YP3\n",
       "8vfEKVSsZwuDreYHv1e0Hk1DLIPZF9hkh6BVJk4Akt5RmyY+kU4n0kwW88gEcsRmWqnmj7w7JdRT\n",
       "xCFVpGl7JHJi1qYgIEJupA7J2cMvRQQqtpHV9C6/JZZeq5uHkUNn44+w0lKnyrxDQHT15oG9FoPE\n",
       "v2xp9x5YA6uIqW+t/N6T0exRDZ0V/VWZE6GCDKQvj1cZrT2WCEP8ypCujK4991s1uQyeKQOUAMdR\n",
       "qv2NQlY2VmubefLtEV8wcP94zy5s1oCaXWe8G0aa13Lx/QPETWBqOsM7rZUff0bWMP/3PCJjJZKE\n",
       "DuLxEh4xwBq+UCLYLrV22FCkRW9/7ijvv4mQz79TR8kEvPpQ5Er76UQRVvl/1N0fODBUx2W77Ekh\n",
       "sQ1d8iqiOTRLqH0n2XK3QCr9QQ857gztv0Ns8YnommlPJdl5/DW69xUNHDbLE+bgQucbroLWpiXY\n",
       "S1lY5RYJqo8WxPFPHwLQ4T9qiGe1AEbq+wLyr1OufuOhFCDbXnyyVJgikD21j9FRyUhuJrKsqE5c\n",
       "FljzzSGt08aXE/pVQ8c0TRdSYMJESgLCr4HEwmsAMGCrgiSZrxW6xeVlyXWbAxcV1c97mwtk4gpa\n",
       "DlY9g2WK8PfZLdZu3O1RPmXlH3rJSEIhdWQsyqXSAAWm58l7XiU6l01whKgKv5QVtQk6jsgQSfR9\n",
       "i4v/eQZv/tI3O+ANn0D1Wu7FRNVx+q6JRNYhGkreuszWaSInn/eyZrv8LaG4/+vXBszQfJhBoLuK\n",
       "N+FqLDPw48HKFul+k2MI71zpuNW1ewac5/Zjrw7fUX1pp61jqhiwoHyDjfv1dvR8u3UmWMepVf1K\n",
       "TsMeYFptdz39hbV8/RvrdwxBOCmJpSun2bsYMR2wLDDjrZo1o332VcOCSRzpdCrAQGRMSUVhyeIz\n",
       "Cuqovr+Dig2+3jF9kki7F1FqABjE4ff2Ov4kNtqvmJjNs2e+K/7o8hfxe7f0181hNDD31dEaju1W\n",
       "LqrrJGzVk8AHZFc7qg9L0rz/fgSvtG2wlB8dkwREPZ6t3W320Pwl1l29+CYCI1Nzt3xPayVCKVYK\n",
       "5P+Ae08lsyEmbs6Z1I8sa2ZosoeJLOjjefxBTpaXUUukp9v4L116EH7GSkZsCyAgA9alPnSj98ZU\n",
       "a5xAJywLNPOtDN2GuujhXTnOXFg1vrwn5u+19C6C6VcWZ/13gs2Rr3yek74yxwULOtdatzoHRs0o\n",
       "ZHryLZi/D58J2W2gtallUCVm7S2yXt6h651GmReitjx/aOcWYUzJU3uooXmLEZQoe5uWmVyT50tB\n",
       "PRV3c6CRYFFUM0F3Woa/frsdy/tuvHiSJoLZ30yaX/Sy8zX78tcg3ge/wlFasVL2BNrWcugODXuW\n",
       "HZ0K+Q+Wv5KZni8MKkDS/7GnhITAJndsJJwXl0oov6GmovooxsKOEq2aBMDnjV4rW0UDBtRnQmuj\n",
       "i2Owgb9YBZakUMqarrSU1p9uLK4vI/wVA8ESWceqIjdF8SQGDQp0ZQvBsYi2JC2kSPP50qKd9o/4\n",
       "4JD6A1xov2pPRODjjeqi+KwXiEIStk819p9g8YKRjVCkKMFcK6f2o7AlQ8ZELJUBATT1SyDmDmLS\n",
       "Xg89OVS+6iWMtWN/7L9P4MGLRnmn+2pWYeSTcJ2SzLKpYXteWndmoWdHN49N+yQvDZ7iQUTE9hRN\n",
       "yyteaJY7fhA+TSilt9MBQIqOu4sCcIOsCp0o46bjuK664YurZlRQOCd8RRynWvEePvwBZMzQEJYD\n",
       "O9RTLnB6AbG/CGMxCPhPg8YQKAxMpJaZHM2r4EBoUExa5kR+C4+GtAlhMJVtOvatjc1gyyGisW20\n",
       "j3lvHkfjhQvsx7FXa8mjA7/foHnC28hXsL6KXYqMlMxPbT/+z64s5ByBP62wx5PZsREiDqArPavx\n",
       "UzIicR0Hq2KCpILSJ40PtS9UrYDz5K0Q/dDdCwb+AjmTbtNmS03Dy4FwPB5lrrOf7fXiyAmQDatv\n",
       "BKaIPYKhWktdvnPA1I0rIDRpa0lgkmoB34+I3JSSW6gVfJnKautcMHQ+Uyu7iISl8pAoD783tZPr\n",
       "9rK8He12Mkx86DKfRbQKv9u3tNR24Yxn34wvaSaxUCv4WY0Bk2MZ+aN/nKuBuC321OFo5ool+8SR\n",
       "dUEDfVbH9wHA0iKDA2/CT1NGslB+YTqWW/Q9ZNP20OnS8YujFTbCSgkXYeT44MIATdjBhe19zqHr\n",
       "11zoO5YfJUMObmqgDclPhGdZD/u/51st0Xk4nx5aBJDomUgBvzBoez/5tj2F/JLggWAniONHySNO\n",
       "bW7kYbOomohHuN7lKUhmmA1dpeisvGEQ9bn1st+BdtOa9WI6CyS5Kf1SUuGXh1GEdIkaWj0vva3V\n",
       "GHE4sfP37+/PLWUT/TMdHB8IAVbaa3lC0bV5/l/lrzpp4cgq5hYowOeo9u59S/qZKS86/5Xju07j\n",
       "5pq7XTg0mUj5SAzk7gmqWTfu+knN+Cz3h8f14/BBVAayjHBi22Scl3wZFZin6Uukg52R8quI7Gh8\n",
       "tVmbzgRMjE1Q2evSj72yXOpAvMaWMfvGfRaotECZ+p4ZKhrPq2HkrhOU7+guF7pbey3UvdbX7jjo\n",
       "B50EOqb+V+xGcScJX6JxY5G674tLdQ81Avmx1+YgYjIdeTYk6OnSd+F+BWy/9ca0TddtmVa4/m55\n",
       "tJFxksxt9X+4zTB5SvF/qOm8dVOJL99inXWx1zPCCx+Xb2XVdcBj74GfeRe6eV6ElvQaNKGgb7Yd\n",
       "/BloFjNCHiPWUkDrAvXiMybm9sAnQoxhTXJykp/ASezDB8d6L0FfDoZ3BNS/l6yufPvBXNpKIL36\n",
       "F2KmnJ/EakgklWSVnPnrF+j3uHUYubYtbpXjJdQFXrUthcu3dw4Eo7sbrfnabH8Ez7TaOdwHs9qp\n",
       "ja8f18z/yV1EBrYoxFWNijI3rHcEMWZrNHKual9duSPq4yjeTBN1OW/Nx9QD8tc/tNW+UZOenhVW\n",
       "McFcBHOu00n4NHxHVfNg9u36HA0iEnqjqi9Y7Lh4HpAykCBK6ILM4jUAFtv5tZ7/tGPoshQOxo9y\n",
       "/MGB1ZFrrPIcbjl/H/lbyJxPvRat0aeS04NYKJRYjWXruz96FONzErTAYMynlUaYyWMNsKIpiaSk\n",
       "MytHDiJvMtPkpzwEDfLPpWfSt8Iq/of5vFd6ji44V+3f7HfmMLxdcB//giX+RccGCFd8+jm9yPYO\n",
       "eP+I78qYRoU9plD09pIIF27ViZ03UvyqFmPCxJ3Z+5DFSesVzRmiLMC0ihSz2iJo7ENhHZ2G8bd2\n",
       "xkmPWxPCZv3bylPwWsn5VFAP3PaxXH2djlS8p7hfpNAEWTiyVV/fXiZnTq+a+b/fr67S6E28JCu/\n",
       "ey6p635eNlPCRs9Ag5zSm6mdb/+N+jtt3OcWDIjr7/C/O2KaYi21W+6GGTnYfIbQrpMPmAuJnIqG\n",
       "BgsuvIjSB74e+gfvBvj1oy3sSz1oyArekyGF9rIEUSY5UZGDwpYBD3yy3OmRgrHdKb6BK0flOeLJ\n",
       "UG95SGMhku8KqvcDPCd+HiTNvuWiT/KROIVHpB94sZmS5khsP3pbbUVK40hBTjkiL0YIkxqu7kdi\n",
       "5SaW2R8Gj1+21zXeEqkt4qfIeQvRjkh9sm0uEsTUnHMbIkEbtdeV8gyWtiUYGOpqY5oke1PKHvHT\n",
       "gz4rIwAQ8aiXyX4CCfRuz8Dr65X/WyrQYz3PBns49YYOABlnJAkbYfiGmKgQvA0q4f1gqJziKmZz\n",
       "V5SNDfUp0TxK8JiTnFpMJRfkFTdwtjdPqT1bc+mXpCMfEbmVu/YUfs4EJo+qJ71wIuKK/fFGUHk8\n",
       "ne7c42yMyQqbQIRw++eAX8OiByr6Mxr1GtcVL1w2ZqWkwjlv7thaOZzh9Aj0bcLL7GlM6UJ6QuWe\n",
       "5b5PHy/yH+6mU+4P5e4k8Z3cazElVN/CeHqW8uFNY+tStZQu79VVA7X0g/E39k/NPy5kim+LR+TA\n",
       "/LGLqC42e0FoMyZeDOAdtsqf/xvJzN6p6JtfU76kyKJIX/bVnsWikmMqx56IrRcgFVRmd+FlBQZ5\n",
       "E7yg9J8B3IDdjmN7sVowdEOgVmEPQcBrrDyybYcS8cFB5ikosGonA7OSMZiPWxK6P+oqCw0G3Zd/\n",
       "qGkXTnl4dSU+gp1txW0dF5uQCBztHS+t5EtS1prDF1uLN5VuVlxeJg15XrDymfrRgVNZJgaREUib\n",
       "C/etW2cZ+p252n+9k3vZs/dkIi+bVrigQMTRUixhxup5l99Ii+AtY+BIJE3k845xMJiU/bQ/6AbW\n",
       "QcOC+9MmsSTCTCdy5vN5rjYaTubsNAhODp0oe5nOR+qiLbeD3nmegYFCQrmeQn/h7fTKVYsyJ4Gt\n",
       "w2JIdnOy+DG37JsF6JOfLFGzaCtoxkhnO0PTe+OR8i9wcO0sV5XPLCgF6hrtRXdA1OnpnZd5z/gM\n",
       "4BeLwtSjY4gV+QuSZ67pnqhXepZ56hGFp//U+h5ByQapsFfC/XRzZeOVH6rDjK3/fU9e5JV4E1hP\n",
       "6lsSICks8I/egpqlDmlZcgxjcWGBzwxPOMd5k/hfBuFi+JX7YJVGtbRRjKekXVbYH7VD2rA+9F9Q\n",
       "bCbeG+E9BnAt+trAI0z/Yt3cP9N6vpYRblhlS0XeCmeKfqxPhxZr6hzQ/OpYBEYmOYDah6YaQMvz\n",
       "RXZtrFEZsI08zurge/xlIwdmnhuPlEhyMrlP8LZFK5v9mthy4sZ1apTC0f//K2a8amN4OPtrcv+u\n",
       "uDyxdkmqY3A39h7mMrD/vEI8WHNYkZD1ZTVnTs+BeY9nnK7OHLmiyMBakGQOckgmsmI1EbVB7XWb\n",
       "JehOWRjENMJQ+oK6JgyvUYgdZOsbBCEEcx/hjKJ/FshmxXLBWQ4CBLYN6J87jrCihWvULLtk+s8g\n",
       "AABQK5xsGYAAA4cAABxXQZojbEEP/qpVAgPDAAArfsZ2X9VcdtLBa0/uz3/vgFtdcid8+fusY2d0\n",
       "6qQUeKdmy8PKMlnH/d4mJTkoDjWBLoL7upiaTIsWL823WIX2SSHdrJQJS+IizAjeAPwG0ETFYVNh\n",
       "HGcRWv8sGPpbEJaAbns+LXsaPWuUIlsR0RJUrKciVesYxGkLm8QCRAbo2nKJaUbYqwsXo/CHpBEM\n",
       "glY3xagA5e9r1bDZDz1Hd3Mhd6fYy7rp6ERVB6wG5KkGalQ11e3LgV6X6yR7vlEYgwkGcsSZgZPw\n",
       "8kivHGLrJH3NPRL1/4U+jPLG/D5KXsiHevquiOa0YTRnH1J4QxZWKL6bfkF6UHimLlHcbu+48lcz\n",
       "VgPc2YhtuhCO1vPOxTEkS+p8ln/u/aEKkL83sd/TRBuGYNIzs/+TzJabMnxJcntcnArggn/j5h0g\n",
       "AR2bN5D/qsfJ7lhtc9BVt1JuRQT4Wvc7djVfMDTfPxo8Ct+gsgDZ66CGkHEcHlNSNEqdBHLWzqSa\n",
       "7x5+Kmg3qscCf5K7rr6NEKBXp4YBcvHjI5TJBYU0MGcIFYn/MI4JX4GO5kUfB7WmRSDH+gov14yI\n",
       "5JNtwUh2K3V7TK6H3W2WGloB/F6jWHFiVAh1j/1ODX6lYJ2kCZuRFuuoPvG9mzrJwmzeTu9DjyR9\n",
       "VQrgQgvBCPiCbz1UZidipbFW36bomIQf0tZMlcexBgF19+R0TbIVkoku+9YDgu4zbk80+wVod+Mi\n",
       "8JMITiYfr+7oBtBgiNmP7VnrHUXmDq+HZBBRlQtufMP0RnmrNMNT0e3ym2ZAnfV9Xlx4h/c3QT1z\n",
       "MJWzsqsVv24uJTVUJMpyLAKwMMsQxCDjlBq6ismgOYg2avGIfIMH6DrFHchq6meALDD5c2KIO43X\n",
       "H0OZb8N/ZOaosGUjOAKkog5Xxpz6FmL2h0SHYT8GshN5LDE2GM/y2SIaOtWppf57C/LeO1hF841R\n",
       "q9QdnxEKyi4WHiwGmb56CtamDHL+rn/rniz3A2B+3To+In7YbK6tkp7MK4HPwnUj945YQqT28Q1r\n",
       "BirRDe1WLuLpBnFyKKSJAD36FvEgh4n2XdMLIFRHbaKUBOQYhfQ0A22vVQtZ5QuNZQRmcP0SiIKj\n",
       "lHtq+18lCQI6ei9LCVYrX05ExMN9eQHOfB9mAKrMZaV9AOaXtLsjwoR+zwSV1bvnjCDDpI6LTnv+\n",
       "AUy4IdEBw6Zsut+S+mXGJHWd5GP87dnta1dXN/78CMcGm/6cl16WOoorBHFeiCdbbs9v88kPbZ3b\n",
       "RSw8xH7I30Crur/uNGcC0TTfd5M+rxIFPnm0NpVegdzxBoq6lpJznpmEjhNBb2udhRj+x9Ykzgn0\n",
       "57UyCh0WlNAJJy9wUDMJcP3LhJ0Pytufp8W0gvvc2L5N3kpMFHYk0uLiP3ib5PrMkR5CcjzgI2ks\n",
       "ca23jInq9kJ2AhkKCExP0I4F/sIBKWkawrDBo7iv7EST2MsE5U6rA0PJjXLUVoNuY4eJU5/JY3PY\n",
       "36UG3SUrXuK6tiHqNDxzj7RRZ/TkwO+oRfhqIbqozLh8zj+P2qL8bk5P1ZwPdv5wKnGGRFzEYmUI\n",
       "5CqyuArvQJfNWMnhiY6+/sMPrg9SzYkMXjZbeIXxHfCVRFLkms5bgRrStjSz3JZYG3TvjjlBK17X\n",
       "w006akJFQV1dFGlWqzNZxpjVTovCIlEktdyT3cTv4eUfIv+NujtKSUSkixRhljA0oZQ2hbXDVxV3\n",
       "MvgPKyRDI8i4ONyXvlrF2SR0vACpLh9iCibjZQv2z1ZXdFE+PzaG1veUDRUbFvURMCkD9yIEqvwL\n",
       "mD4/5FHKqWLChGpsFFY8xm9CA1jD/GNVT4H7B0X6D36JGbWVMgEFo7kJ5IcBcsuEBP6mOvzZ2Raf\n",
       "QP+Xy5CBfgeup5gJPvySafe6ARwWV+uOfZ0RnpSgBNDcvRJpj/dNtPVDL7nyUAq0TzYKmfuCTFJO\n",
       "4Z6OLKj/CrTW+CM/423DFAzPuRLjkIY1MUmli462cOJ5b/jGA8y9ns0gn7zNJQXstawGvFoa4GK2\n",
       "nw1Z8RQmsfEundDtmC4aWZGLLAXl1TzhLqBy6zdf78KldAeQZkT5Y/4Pu19WHKIGmUrYRo9OGdUH\n",
       "YoiuKV2vKCzPCgvw8SVzZNaIVdnD/5LwoM7AnYYZKVQZ+5Lc9IcF97hEe4dHGUDB8CxdDx6ScHxK\n",
       "vgV0wqKOOq0G8wNWKffoqZWAO08uhndb2f0QhLGyhEm2ITJjutZEUXN53jfMcrhQVnWm1ZLzBEEA\n",
       "jqlddN5eOqRPxQ4xyo05MMPlgq8CzKikixbz45neQAInZiavqLOWBWALyv5ASryCNw/risPwbKh3\n",
       "VG3Zu5cPlbiEZEnYGLGPT1ZgIANRs5doHiqrCQ/4bKhsjKjIslVmZaRkS+TdRQwu32kt5MCVc53R\n",
       "gd4sUSzSDLu0F+BLIG8bh8O7ed95LydLHLUCIqH9z5Q/Gwm3CG3hT+r/gyiHH52Y87f2qdfenQFB\n",
       "WYYHb7FK5cGsiCMq1GWrpwIbWYa/IJUIeQRpFAY/GQsx2/yG/hf8lv88E+eAgKDbELVppCLx7R91\n",
       "43/dsCu1znitmOdS++6SiknPHU780FX2t+0caFarg9l02olkDTZk4I1tyduCFYFXLPDjSpNbik9B\n",
       "f32pRKXi90NI4rF2XBPKlJi2ma2VdjJnzmE03hH+3LOBDE7jn5GD1DPEJGNdGJxz5j8VGr9pEDQ+\n",
       "3+9ql4CHeHkShzB24YEN4My29xMkCbipiOvNhHtoAdPjFNM8agWuxmD1WAU18BJlZTMMaxRiYnph\n",
       "yhZwU6IikmTocWtqyaIenMWpHc6Kgb5GJR0zIBxv5qgcYWm/v/BCii5su1jOJpqZQcPqOZL9oKUF\n",
       "pQ92TBJ6zjkEmLLN2tg6Z4CvcX9jRQ/TsLrWMsR6MDn1nbn68GuBVhreXPIfRnPGH6GopJP2SSxw\n",
       "WY7XrZz4duGz/WC5+1cPNUPOk/qIM9LDLRvaH+idzfXOR2bMzsju4Sgqxs/MdlOueaojwncc27dn\n",
       "CWKN5dvzc7ELRtUIkh1WN2ItvyBuH6ZJyXnEKd3GVMDDEkS6XBotf4EM7unNMx7OuRom7C0EPqI7\n",
       "/+wLpe9/OJt2MNh31ob4d8xywzfVMHH+iY8YCAIjQQXeCxSr0H72F965+mNDsrP/Bf8OjTHi4Oum\n",
       "wdxFG8mBUd3y+MiklYWW7ryeJMhh2ZRq6ytmrkmo8gb1n7oHVo5cJCWwoncvdioh4Gdew1Id5bKH\n",
       "l9zy57LTq0fT9nOGLMS8qW4h5LgemoxBHpdJYV/XMP7Uf1PDHLf6J2DFYqbT6naYnT2KdyPYBCgY\n",
       "H+rTXQn7IXRNK8l6sMFII/vK5pi4eG3/5dvuOcj4G8Oe1wf/Gj9JPzNQmKj60YVNkYo1mLXeOJig\n",
       "KW66CnYyqdYFiGYWBqAb8Q6r3zCfgVoBntRbrpf50Ge/o1tMq9VMkORGRtJcycVG3dIF0e5Dro3E\n",
       "0XIBf99ZTuZpKErAloDYWUCuB0s2t/9cHfMzT/OL7IMPKtBGIKMiupjlnXlR1BUs4tPilzzU8Ti0\n",
       "D+640F/3VUSZNfkLlFahZjFIdZmkgbQ24AQBwvhWzIc2BAgGuSwR/CWKOK3FJYwoQjKeT69TESh3\n",
       "36mDIuJaZdpLiq0OhzPI2P+um893/BwDo9ztg3BasIYs0qYHoQOtgrmR0HWHcV2mQIMP+9AFDfjN\n",
       "YwDAn0DOGWDiGN+kMcpnv1auv/wLWQGnj18mH42iKpHh7TTrYD1uAQJ40XQ+Zuh6YM5WFalkseqg\n",
       "x47UX+EBuiS4GOeJtav+3wY6lUkIYHDZU+m+1BJj9KY48WIUUstXNui06UWGafJbfKrcv930Tx5e\n",
       "49zM1lS0fXYAAmhWTvywVq7sq5xLQVmm70fDN+/TOfQOREVtP8mpAU+hbF1RJHEgqqdFOvjtXPlI\n",
       "cbL6v17svF54dmrxABrLzgHnUR75TOfki6n6M1zc90ttVEGkg1fdflvTZrFPL78/PcbPUVfhvTCA\n",
       "wGKzp5ZcDAaK+MDxesVhph5RqM+u2cNlTRPQma+kn34eZD0vVdcf0nHhOt6MVvi7eSHhxgOKwG9G\n",
       "vwP+WMV634f/wq5GzJNOaw/4swLzwdufxQK2cWYBCb/Gyh/VisXViKm4NLRgoWuDO8aNhdvOPGeQ\n",
       "Ayz+hqeqIkFf+C38XT/jDqyh9T3URY2EgxKprkKYEiDGFKIa1VRncUWNxDzk+/ntfEdnFryfwP0t\n",
       "Ov31jnw3nc9w6Vfm5ft1NkqKs1d+e1GprHDlVExS3G+4FOoGwsCHr+NqnUpQXKBztI2K+9GbpzpU\n",
       "gCrUxR/h39z3LXsHYRtTL/7JYaIL0/l5sbibEign8MC71bq4klRv9EKA4aU05EUQC/jhf1Obq0ja\n",
       "tmNHureM/AsIGyjB1fh6ZRqoFLpGHTmrn9rD8fLcN9WvD+zJNiogDf2XEjPfxBI0QygPvcHTWKOX\n",
       "j+ev+Y3XOsVQirPVKU/wlMR3No2DuyjqvbCNgg4ZnmI6vVet5EKmGawIcwA2dwxfah6zyd3tF1ot\n",
       "EkyHRmFusTcgnkn5ua6uSL5dUfUnx6NEjxMQ5GKbtT3uCKZfd+i4KS3WhEftst/uMZYg1bpVhuKt\n",
       "AHO/53B3tX6ixbsQdvcB4abJ7n6ejNTmgDaFVInDjJLeu9r39eh/hNcgMDUGJGNMdCfmww23+wbi\n",
       "4nJox/vNhz2MbO0vEAxEaUq++G54V3z4waojrDhG3lMC2qV83gYEng6+FGKRi4VrRzr+7R74FlFy\n",
       "CmRsqrYcdjmh05isaovrckF+1Z33ALyK6n8vCRrd7xOA24cbxeV74Oq4AcUwqrPk7VXt2uEy9V5e\n",
       "djPzdEezBfMIZRSPXN3lA4oTKNSiJPmHxCZj4TXvuAVLaPmsKS4zf3excelKKlnMyKfzmJxCFOhr\n",
       "YCI34bf68QNnk2nXNrTs17xf7k1T9riuo9TbU6rgIrXuvsF6pinNJo74ZXZpOof0dsxHqHd174c3\n",
       "GP7lpxnp+VqH2ph253Yr4jhkMHXjitCyTT1w2mmUOhAn3oaPQyjlEwlNAUz1RAjm8qh//2PYJYNU\n",
       "AVXJXdraMsqSkHFegKdb2zX+W3ZAqs6qO6TNPCS2TdHVk/rSVBf/ypNz0CiYvCc+Q34Xk1Qxujw+\n",
       "rzlo00Wqoe7yWI1U4bkmXa/A/QoExWoLgwhbA2zNmiKIllmYnIHOPexw4fxT2FZgIc8h0F/L+yzn\n",
       "ye7K0uGGwlsVjNAw7x5Aly+99e6BTIK392LgZLjA634AIz+5FwieJgEu9wUD72GWWDgCnSDKmPd4\n",
       "1pZ926iimH5j3nUvGLPc+9kYLUOCANow4FXgXPoW84sPOgEz7MHy8BE05GuduoeC9ZqChmmEBMCq\n",
       "ubOcW09IU8P7qYhMqY6vP0FmSyoYOsNf+Wntpar/bkuPcRh97U0n9KtHGQkwckYw0wTV7HeJ+qAj\n",
       "bX0PngEuGzqkXSJY4zR9mD8xbDvCORaUkrHpp6fLnqejGo7QJg4hQbC1CeemUtXWAXBTrLO6fumU\n",
       "3elIzjhmogs6pXa+1nA8P7GtD7KVnAWO8P8S+iHNWR/UxeBuoxcEfhKP6t8ACa1II0ViUiFaoShN\n",
       "d4RDmt538LrrVI/EgLZvn9AiAuQkN5q5ZmaRxdU9XT399wr0zYixG7BA6SZxrYdvK6n+XeDpZ9GP\n",
       "Qg3PqVhauy2oydDozisLbg/UlfJNQfcjngKl6ExSSFuY1Fukdhda0L7YrBgb8KSNGw6JlIsSIKMX\n",
       "+cvqlCrYAyzb2zfKkpKgyzokcUQc3CFqkpaK+vXjejRuQecGumfdI4SRbYuFRgfNuKZd8CpNEPEx\n",
       "szUGbC14USyxPM1Lw5TidC4SHkqmSuwvzc1gfb1JNQ4ZLr+3MkI3xFYusvwdhp6J7DlZucwWs6t9\n",
       "CKPwGVo4VE60ejD4AFE9zc0ShIfM/TzJaklyZhMv/rtujUQGwq4z4FEo6TqdXfV1hDlmX6C0rqJn\n",
       "DaWOZIFlH6arC4LznEgekILnPyP48CrppXsir20PnoOvW+O0hUYJaQG0Eojpi8fPecSwkUutYMYD\n",
       "j9gtZB9cCO/mjFp1JMRpbhbBcodXgYf9eh9n+P2reySR9zSbrziW6B/ensvPMoVRiBXFV6zISmlq\n",
       "JSBag7Tq4mvUMqduHSr4NmcH7061sT3RqegbbR8ElOgQxs6MIrB6al1SFohW8BlGiRtHAEznMZdO\n",
       "su47qoccVdt42l9tku+8vPj1DOp2c1XCSMiWRcKYttT3PWgbxM8wQUa/Xd4zKOlpxSgYkc3BaRXz\n",
       "fBWA5C9okXjWKOeWZhJvrY1IexD+3iEHowgPikyJJPbUMUPsUPOtgFzy6fEuYpio8uNlgT83YoRe\n",
       "OjwVqcmXoJuS9KkXyIuDyvnY6TccyYEn9O2+4G6kcihngaNPDw3oMI5d9ZkQ6DjhFcZap4QlkVYE\n",
       "n8oy5WG+pPuMsEFnuU+sUplpmW50rGp9IKZ6orCdzPQ6WgXExz6DvJOK5LOeqWfKsCv76edcsfEw\n",
       "r/MKrhe1MHu0V1pbJ1lfmAH8VQrMUlBNF2Zz8SwTE0EJPhH6Q+T8TmERpIMnc5CjVl6hZmF8tKla\n",
       "wI2f4sGVs7FN2wW1vhXjE1oYfDvtLsa2FvCT6L0ECPivPHL94mEMipza2Hg57nlqfwv8GLq/Gqa+\n",
       "vfktDb1ryM2zxdAhZSAZrWNAiRTYbDa+//tmdE+K1ga1e2GUZnx+5hu1Y+PMa44a6A9RtZz3G8sK\n",
       "7soAEIDadP3FZfdEbRe5eIet7kMZ7MsE5XVS93zvxzQitnCBsvNzLxdpuLffZo/SJMZLImvY61r6\n",
       "Dmyu16OSfOyzWxzOJmj49L0cUw7y8LjCxEAZ6fwnqkEhnPAStV5Pmnl44anscKckt+Dcg/Z31YWD\n",
       "RT8u8sclliHBY4/SYRmEXsm5HEKkK1pnWjDhcZHpsPMhjgIZCEdMyYlG1Jx6E0X1dbPPOyhRKHrp\n",
       "pSqwvUKAiePmNSpzRGwcXDHNMBNRGvtCOH6jMGFSfKlX/9MRz/PxE0i0HnN5FaI1A5NXKn4KkzvZ\n",
       "o21PKs0oBs+dW1xi3mg13OXtXNMRTfDJLcRUXsXzGhWMZ7rA/rDPtyfgLQL+9dzDTvA1XjzA5mdT\n",
       "dK9Tul9lXFUCl6KT7mvHd/y79MhPzmIbY7UMQ8IhH28wC5f5vRaJnXWJW7b5xe64jXwcJYMQhYLi\n",
       "5evYDKcG05IDS3xxG7rc5pUDiswzfwPtRFHS9hXGxkHjy8RSpYJeS0w5t6LTMaqidMXlxaRuDVGs\n",
       "Fed/YZFxiCMr3QnlHNf/x0D6Lj+2NLs4nmE/L5UanyRloizuhaGNgSs+Ml5Lw6eD9cgYfv4eTdfp\n",
       "o3Uyct5tlFAsM1BuPGaPj4k6qAVp36QD+NIOzBYCPkE05C3GbdOYz0MgemX+CIXZT1UlZWxoNtpH\n",
       "lPRGL7DQ4l8Lzmv9VX6/lAcqrrTUKQ9FUIEofeHcPIAp4l9Hy3BGED9zz/IPX4ROYPugHpFt7RRz\n",
       "QrANePHS5YYU55ACEzWUSamOgkgOKK8sPPwgwSWZ/oZDXGeotKcrhR7GmJmJxWD1kVLPkT1DdoCX\n",
       "XJb/JCLGTg9JJ5iCv8yyTK+PNCMZ5QcT8gAiKy/n0CZokid/BeytwHYItWszyJ6e+IQWLyuBiOAr\n",
       "FTzD1tD4kIvKzFk0i1wZbursdz4PQ7cq9nGHwOHILgyvzypC5kMWrf4/GfdEBabHWkKCydwyDLU+\n",
       "Yg5dqKniQW6FGCz7sL0xKEY2zyiSsjPTLpQ1ErThT0mMUR72dJFHRQnRu8VuVhJRRMt/ImMQ/b+W\n",
       "+m3UPaQeMMLyNQBbNWwiraR8VB9Ub97tHtmE214z8ZP2NKX/0/UqbhOacZ1dn4NqsnRr9kECeLqk\n",
       "9U03ydFMEp3Y9dO4zgt+ONhsiKq/xaiOD3qFhKSztaBaw9Sffg6+R/KcRp2LWwdVii4P+FKKQVh3\n",
       "FrDv0zPtDUMUTTU7lFZUPGKAEAR1IMjCNX+nK8P5e8vg8KwSEQ0Pyeb/CV7/eU3eUvsKsyPBN5J9\n",
       "r+GQhRLEw4pJ5bhc3rDC/NxMOLmEfP0kNHMU6eLp8Ffq57pC12bQaj0+wkTh8RjPbRJ6hth0vq4T\n",
       "AZi6yb0p5UJrfpaF7Nw8o6jn3JKk5BbHClacWjSuo4t3E5Mo7voaMw+A18KkY2z1AD6Q48BvEa/F\n",
       "mZfh8KDt9qSNi2/j54TID9t4v8bgwri72stSPeqWKWQrekx1ErEPYroS4prncQ8UkdXTuSzgACC9\n",
       "QsM2h7gttwnCmoFKft88EuQhBbclyYX+C/frfBNp4yW1orXxzAAucI2QiQ+WGqQW8RVRNjUuCuVo\n",
       "UJau0WS3N2ZoYeRwl3SIzGX5cRKAtETyFaetcrxKXps0WuSDoUn7nTUnAOInGURy4nDHUqjJemR5\n",
       "DSThWErt06+RTS9bXHVQEjE4tSFMf8H7miM+VXV1GL3Puqq50vbQ4RfjEtRjpi0Nh7Epd/clegFI\n",
       "AQFfEad0/lnRFd7QrZbCo6TRV4eixulolUkLQDEpyqTwPgLhFBQjxcwkptDNPSeVONlOBIoHUnRZ\n",
       "+NcKauV4B1x28y2Hx+25WT+FKtUexyBFZElogNRZVQMr7cE3IM/2NB0CtqjrgsxwlPD5/MD/pR7e\n",
       "mQdfpcL5pm3irSM4XiMuslSqYOC2YgfcRIevx6RHhFMkjNtuTI95nmauosSyVYejY+sanuA03jtV\n",
       "9oDBpMZzhUkfA4jBjq43ghfAJIbQkMe4kF1JJjH4jIUfnSvBq1XKlc2BNqAmYbkBGHJviS8bT0cl\n",
       "zt2/4Bn+EAOM7WGPGZkPzaCbV9wGfPABChaWGJUwJl5YK/8qCvHb6bD7K42BqnREjU8y8z1lMmVS\n",
       "E0T/I25fbVhD5NWkMv5QkdRAk8IbZ6DatL81IQEdyqFsBihrTL8YTpFLaypPQbAQGo10KUo5yOuF\n",
       "he7rQ9Rqu3SRA/b6kxb0Bhw6g6HWG4KFM8+lkvgim0FL2AGwdjkKcE4LdNOKFN8O3l9OrYrR621Y\n",
       "PZC2z46k6jLSnANQegUdPM/CwlQrlTrpzTZ0MJPYIQN8EnWgQo0KvEaPBSsUnAUpI+8PDcRLBecR\n",
       "2ji5TH+oTM7Y5oCekHgdx/0F2fFitTOaZTUyUaPXVhg+9Pm1YwSDPg0LI+Oxy0nnMQesRa/DQWPd\n",
       "F0pXc0ZJGv3NwqS8zRwqquFjDoKpKLe14fWrkGBiklqvd3a83+/e+7W+URN65jwJSU3GA0OPSZ42\n",
       "0kYbYKKr493Hz3VrFa8TJ4GknWFnnEXWlUl7n98w3Uee1l7lC/WHtTSsybOYAjU4hDqe5x9VPyr6\n",
       "TjiTV34zowyuc2h5h02tq8flhGZ87t36jTnZjw7uRI0ABtfxnBcJqdgrPXomjY6GjORA6jDWibW0\n",
       "1JKw4lxgc3ZXijB6yKZJAkDyDR7hEfj9hIHi9Cx2BaQW4hBAumB86jtm9wg1WwWzLmDuuKodnmBg\n",
       "1+N2AP1a5nMDnvx/J5drw+qej0wRXqb+a6MEWU8Fdc5XMPYuf7aJjB/FzmUzmIgph1tpuXRmedFm\n",
       "n1/j8jMFUkctr8r3RwE1n7keNK9Lto6xRbGtdTC19cfs0m+5WqYXr8W+sOZQOM+Jqq1LUsrMsy/C\n",
       "qgwmNKv9DBMzphUbBuZ/8WhgvDpIz/vjlhikkV4B0wAAHXdBnkF4gj8ALNh1wxJroAHaBy//wcHA\n",
       "ol/FUFyO0WVvbJwq70PmON1aUe6oRyHQm1FH+2I+RE++S5RE/guoLZZ8WQqZKYvFSBnZxu765pL9\n",
       "822r+FAR8Gr+IBUWgMju+IhfF4aftOOTfWl4sY3TfiTIy6RPzshMF6HiBUi8d/4nlNvJhu3mHFfK\n",
       "K+OiaCJ1xz9Ppl9oe7qsLBDlVzF4n0JYXIxM/sIMkWYm3+cJB1rv0rrKdRzCWdkJzA5NS6A43eFf\n",
       "Kr/EuHiSNQVo/j4SMml5Ve3U10ijTRRzyBJKMNdioQqaHUGyjBA+6wVE+LEqw0tCGgU2w/Q1dxU5\n",
       "B+tPdvVIum/phpG6oRix62BsPLfzCmWkiTRDzeAtxhY+L7T41JLz7gh/P6xJNr1z/qth1TYWfbjb\n",
       "iuSoUG9bsu8rdQfyTxg9OtXcdOOHZj4PXj+5vF6AGMpB1A0KamGqf8HItN2y/zxcJOIOrVFHndvn\n",
       "sR7VTdCDlC8OZOhYHXyguy09rd3+FuyCf0hzYlipW2+uSAZkA+scMdZXjMAnpUHl9+/j08IwWO0T\n",
       "CaMVG43KJOHQ0HVJKDmnye9vGb9Wfjnoc9+qtO8AbimqsVFINRGjJLEYGcS0ny8bDjbpKdDtbYgG\n",
       "iIuELnLmrPmi8TPHi6mpz4sCvlW5ll+H4hkah44b/orcVFs5W+VafPREICYJ6Tu65LjzbI06I2VH\n",
       "CnHkPL2a2HFqLbyV5dClcUxLLhOfVHRJOkorwiFL39ONcXbEczDLql6dOtvcA2d6q5ZdqZSg8GS2\n",
       "dgc89ZqImUEmC97pKuoaN2U9xe2lE64GgC2C9SlM7zkXmgkCt3d4kCec/fd7h3u7ORLyl6Qwa8RA\n",
       "t7OWORaFaq8xx/ypN6w/+x9Te/DV9hZTRrpQfednrEVCtlXNC6q6V8QOkCVcB602hdD4AOwTcYr7\n",
       "ZX83jsACCVYvTZfiiUgct1OxRely/tRl5/rhgZwFCB42SbfZLMGE0X1zshg4QhWVo1tgLK+Uy55Z\n",
       "F1DZEqqd10tk6xXBNJsmnaSUjMn2uGpkAv0d5QAgeoA0k1Qqi4OvMlw10qq8z+44hzRk38XWkOF9\n",
       "aF5lnDXZl/jp8rHTxx75QRoQUqzTop6A8LUCUprpDchmvDtVHqV+ieR2D+k9LceEIRB99vF4FwBV\n",
       "60xr2rD5zk2UfMyNk+OFAAc4P316X0R2bSz73D0f7Aj+dQEk81j1APzz+zKuFMagPfd18Z/jATEX\n",
       "L5q4RGw4CPV4CddAnXE63LzdcFUXOwnIP5lEIN9giW+fijPmSyJKWmvSAGvH8Wx+IctcKfeTh/3x\n",
       "9mLTbr4BPbeKt3b6/AHQe1XBmUDx+vsmFKlAS5P4VfUeTERAZc3D8fdkuF2BMnnw/al6XCYnI/Cb\n",
       "4HWo6iYrAVbJ6O+Bk21TMNi7O/OjQWcWNyo7GR7u2lbvxTWwtmCbXhR0M9CGhT37VaFgrhcFZ6qf\n",
       "qI4kS2rU1P+hOKcseV5SW4adyQyiBFYJ1WqnJ88fBs6/LbpHThlxOZ4rd5IwVhdnuzDaAMc439yv\n",
       "HUPmQ2VhtnagkYlqP1zGJH4vKedqca40gO+kBp/22A7RDGJat69cwON+vz/2AdqcKOCj4o8zIsaA\n",
       "vEfnjd9u409J2rtbM2J4wYcA2nhV1/JaKMrWYKm0Koc8ljDgBt0t1cyEnc7Cm2azHwCD9HhGpPw5\n",
       "hDqWJ0hWUIEGp+yOIC1usnvxeeAS+92zQoO9CgouY808rndvjsGZJJYNPydWUjrMMuh/ObSJ80yT\n",
       "zjW5fYC4z6iTgBCD8XoT9cV3hAmMnV8GvmJLNuRCLpf//x/MBzo//L9VDnEtCQpF3z1pZ/sapS2Y\n",
       "sZje6g7LyFuH9THNDBIlTwPz6YQAlZoo5Eimhzg9j8lx6lHLJOPytvAnQSgEAlqrs9C4ezoXG6uK\n",
       "SdpRC64r0wlHaGv7PoTXWQZAOe4dPUitxYkwxHeKkA5UgbQ+pbtHU1F4Q1MCHI/9hQwInJVKr/oZ\n",
       "M2D+N+GIBePZEXvUOF9o1ZPs+CE5tQymE50kKMLK0iulgUIo6RrDP8gpldtsObYLKqYpegG6Kdbp\n",
       "MHuVcpXIotDmjLDplh0f7I2ydieAQaq2iybZX/mTczt+YyqXcSSPYbOlwRTmjwq7Ts4zSYNcQF76\n",
       "s0k51YF2KZ1AutDLug3MXz+bn6gc1cEIJ55gr13qQXy+idIY1MYRhtWWQeR1sZ8yG1s+IpxubTIT\n",
       "Cg8d/8VSMF+yRO5lv2mE0f6NgQEiVrrwInuzPLdICk8uxxklO9cP0Chz9ikpntvundfxy4OSp20Z\n",
       "kl8DxdL89Pd6+Vc8ujznTV1gOFrAofxoE5+xDFxZPPSdlapyeJn38kZitrQMAuZpeyTHUeGNhWjd\n",
       "PMPBsQRKSI3wL+FJ7yhfUA3D3nzQs7+PkqdV+jfIPChTqkj1Bq9xJimvoQOwyj+zjmd7r107zoYV\n",
       "Ns1DiJ6GmPYRMRn4m/4E1dZXvm074WzoIDJu4wUvhlf9NT4W+qGeUDBdc69ar+p15lm45Zqj6+B0\n",
       "bJPYmr8bH3TFN1LTh7Q7UIjKignHrrYNHjm4W1We0Kc1E9Q+/5q7u89QzaMjqIXQ2qtQFvctAPyr\n",
       "fG5gkfupdwObd7eEiY5F46ca8HqMUJ+JmGuYGqR3NNHNGz24Yyoe5dUTYuIKZDPG2yfNU+tly8Tu\n",
       "ECABsNQORveBghI5l/sme3BsdFL+iygh/71vVxPYZEk7ld2rm3z/Zuv7UqTV/7/KSvfIuQIkbF/d\n",
       "EjIfr0+twqwpklsDpj7U1VS/qVZ4aWkocUyBIrwDqyJwV8jabkf+1x3T5uNY7X7YLnpzHKrFZw2G\n",
       "qHQlo/HH+7gnJ5WnUoBmpjEXV/+mfweb4DDsieyrZ+miAOcv/w5OkSt9lT1pb3kf6QEFio2aMlvs\n",
       "NJV88JpOnHY+53UIOX00lnqJ7PeZhVgMPWuE2kCcApdEhVBUUH7ZjLgDEGI2J6yQOGbMkRV0ykMt\n",
       "tMk22V4qNPcr48Tqt3+FIaqx8gAG9AquXKzqx4UWAbcc7XFPtfDrB/l7bQU81xwERbyvC9YWOuVS\n",
       "fVDl3BwoPQv2w2tMwLWV1fQoPn9OKuosFY/Qct39K/S0qZWgPK3X8UJYjp9Z16klEyKMzxp8BAXF\n",
       "cr3vwRTFqFV5p1Q0tFGLjPs6yurVaPCYopMYGb/9BmiDhbFtjGlrZ0H48LShAI5RamiRmyaAqRUi\n",
       "AkjCDSNP9H7x9OElSfizVKLU5xUjWnh5h7sDHJakw21GM8n7WoPX90BXxjjFrAN7va7fIsOpHafV\n",
       "bpzF0JmnEBQVBrWuvv1m/Jy8YiLN4CLoEeHJxuIVTaaqt+SjtpPvVG5vD+/YAB6KJ7NvJHjC3mb1\n",
       "/MD0cNVl5iq2dkuupnkV/VlYrJkvndYcOSI/81waaNlyqA59GCay1bNovc71ZCRIUa6xf5x4LzDA\n",
       "ilc+D6WXhH95RIUCxPa9OE6tNtExzrvWhFtJkOOvHefUo/GxBGQv5+jSikqLcMSVoIT/Y7VvbsvY\n",
       "qaeKihR+uPUfVzTET8vSmgYAGBQwx/NsR2abQG8yTK1jLcqyJ8sk9KVXKZXKZh0FzDvAI4Qj4y8z\n",
       "rX8GWqe7cRrzMwjPhDKFVvsCHO8xZMXMgpPZap4Qxvrcbhq7CtuZ8g745X+8zZONELz6ROR1vP4o\n",
       "/MsbEFPk2r/loYXBOCfCeu2ojAZKizWwDHjruljk/vl56mqba1eUpJJUsw6h6AuHifQxpfOnqaPG\n",
       "ObD9Xsqzz10uzy3r0oobI10RRNF3lGUVQdOsTqH261fV9scG6WhEGpy+BxN5njiPYLGXTALxvzye\n",
       "ysKISBwBS7J2m+a0IRMcK0ZFVQWlEc/2ET/GfXzx/B1HOcl2lXetsKxN6QnPhC//feE6Z6A1XNdH\n",
       "7VQXdoP+D4FeLwOt13k2a6pCPZnUCb31ZB3nGuR1hb4nia4JAdpx0v+aRzbq4EOstRrdw6ZpVDlB\n",
       "D2y+lSaWaRjMv5C/EY5/9c6F3FuXuWlDaHt6dts7x2R1jUFsmgenZiEx13ldQZdV9YuYGvQf05hv\n",
       "2yCYclHP6diM7tbhX+GvzioufRt/rxa9lwJAHzziboW/qSqo0YchGX8e3VsIlPBfPOLchxrI5HnB\n",
       "4sQXkneyBOoC8Wrokvss/XuF0NVDUFnyVevm1CungkDVLMvLRqQQpJdo2D38fsxFHimUSMPlwHm1\n",
       "gDRQs5xCdxjSzr42enMeVVH+j8Sfyh8o8fi+AjSxl12oOrLzQhSAi+RgJLiMSxpssyu1NFW8UdpM\n",
       "G4Dy9MD9aKggV3PMYo062+n+G2N58Zf2vfZsdsiF8iMqJgvNT5B8OEoG2cHrwoAiHCQvP9nLQ5Ek\n",
       "bbexQG8OSFfRRBOwYrRMov3DZIvky3PEE4aQJ50Z8N958cUSwFgPur4lyG1TSJzxWilZU8ahAldg\n",
       "lLzoT2Op2gK7Lsw/PYP9W/1Is0Ug/2ZRTzl7Ewg80pumW6y0HfFdK4Wd7LUzn14pJzXWOGk2mH/v\n",
       "0P6w5x4j9Pmcbk5JDAFCyev5GbL5jFQB26QklpDLKM94r7f9Ls/DYWBrDMJpJ/ymA7lxInazRTk7\n",
       "6yYjohzYQt9rKA+tvoa+R/mX3RUr+YaH8MiRU0c1xf/MmPGdvPyZSQxWDr63KhEFMFiofzcW0KcW\n",
       "ly1x+nI9r10DFhHKtaRJncsqcJmNqTIw9kKUgRWj8345suvfvl6Gfz76UeCs4LItEreXNmRKcxV0\n",
       "qOV2Ws3p+s3Hs6Dxi3S0rF/KVFymEweS8T3P0QSEjKWp8ZBoPa9zdjBUPd/vmSMnIjprJ5fDCye/\n",
       "KDmyfBdWosuPtfOJiGDf6E+JRwulH6qKfYiSqxLvV7m5H+6ziy8P3eLCG4oRMtH7gHl3P73naoLf\n",
       "d7x2Xua6tkNouMeqCCx5gOHsQ9ucQMYuNHUYFXFVwUAvBOPPA9M6gDsGIQddqSW1zu2wDCQG8r42\n",
       "672itFEnsKSUhHudXlcCDCDxcG852n+z/0Kl+EXH/zDBwGUvUEbvApJaQV1geDbue5RBmD8jXli2\n",
       "JY/kJvYySmhogH1a+l9nkCAi8OgWrjnjbndINjHxSDOMOeHYeg8n5zMzg/SWjB0xKnrB5z+1SYCo\n",
       "JQ28mXSrqMT/x82Ytx/lc8PmsYyF0FEBudoNHks7CWaq9U/IjAjZjzrVFLHQnUvz6zipzTuna7jJ\n",
       "tp3/UzDixT12TAtUPmpdSKlH4LspAl63WOdSV5wDJW1j4JRkU+yYMgS19rwuBVHmrH1WUDQ00V3R\n",
       "mlTjXHpADpbkS4EKkzYBPXlVGkORmgU8wC7EJ0k61YmiD4NIJnL5LY2CzJJyPAYHDaKEX//54fOJ\n",
       "iZhO0IfqEnp/FhRMYyIjWJeQlNMfI1ZJzCj85mF6UsRVYDLO3ACuJ8OGFc+I1r+LtcLe+Fdw/lPH\n",
       "P3P0Z3niIGNhADE/puUFArTyVs5oyn9JJNOY4PadNrTRMRq7prTYVep+0D8aSIH629qOnQUkCkqa\n",
       "rLYjxgq1FBRHm+1a5fKrsf5S2YS5KC6oYjlWdi66qFCecOvMGm/YrUu8LnOdSVi7PDbg6c40aHNT\n",
       "vV3wD6xfN+73kVtZZSNFVY1l7QoX5bcNgAWv7HrVLgEkGATGJY1E/aOolMVib88RrZqzP86nk/GE\n",
       "9HvByneuXxwgTg/5NqPctwURHXj0GCbZ0Wozb00sIzUHryZ5nFjpt2BYt5i77fqQQV72cuexFqQy\n",
       "uiVGjqgg5wzSghf3akUC+T46HU4+UmpYzfXkHtlqmsU7AN96axnqMau5CTV8YJMnLSpA3wmfdiwL\n",
       "C7gbJoW43TL/ZbpDVIXFRrG/xu8pAOCWI8+W2GxdVaQXOy/9v8dFf18ieGlHwzrY6LnTxqSwugNh\n",
       "QXMvbbREf9jpgvPjljlrJOBHvU39Pm47YF3kWZKGk+g2CgJG0zoGh3Y7epyWObcus4Z0TjRb5Yrj\n",
       "68uCh33pehvDucSenjUwouHb1N5DoVleaDBCw6EMkYtD28bXt52963IBe49wtYqQZxRR6+xF0e6i\n",
       "MoEP/aOpLKVQ4yfZUb3s4vjJLa1bYVoNpoNEEWmxE8bXpx1ivjtbbAxGMv8gGcfaCBIedF2L73Wk\n",
       "PDSc46nkQjO/s5dntS9oVL4Cgvn4rZl72TyHc3sMyT8K+cL766UUCwLA/cRFcueCmlRtSrjUzFQX\n",
       "gjZm1k220Lzy243c2hqJpZd3FMO33Con/2FsIfnRkYw7+J4WwwnHRsxnxV2w31WsqU9wUOEXJze0\n",
       "NpALr1Llaum7vabFEx3SCEULMfBVq0MHpP2VvAyEox9Y5v6r45Hu7cftNoK3Ek2bM/7DDeIzjfGn\n",
       "xodl3+o+DGQXnUmagCJmnQUQv0HhtyOwvXOzQuXKZoBJFArwKtCpNy0uS2r/G+Myvcj7yT4lcMyy\n",
       "Jy2B/+IQTZ8knOjpCnK1oTWKp8EbFKSSu3aXYb2R/Qv73DVXsTA5NI45reK7rNeSfGutRjrLPoYn\n",
       "DNo+2hoyBLW8AdS1FmeQmf0JrvzeD5XDjeaPCuULKXfoa83PRK96/nWFP6Tzk1YKs6NpDCLE8A7L\n",
       "i0P6OzvNjaXPJgoq6YArbeoQEIN6cbwVznaNdjKpUOvCbYmFpQUjdcEcIyV22nMffF5xhEc22zAr\n",
       "elAQ+bXO38Gw1Wxu+nT8VZAi8vaODDcAk1AYNLpFJ67zSp6mMdWDEe1E2y0+Mgn47CZj+TYh/0FQ\n",
       "ZI9LnPLzMofRZNGjMn9nBgznMGB67+w+I7oNfCpIgy/6wdhge72YGOgDGRLiaCywzKU84hP3LQ57\n",
       "XNs6PoKgv/TU0v1MnA24h9wCgQE0wiBA4mcvu5TLG/b1REPUa5/RyBxPJPvFiD+pUdurfhmd5c/x\n",
       "vndUiob1zqTmoANOqwRnCiPecMqiamvygLTioW2wZVxEBQ8cN7v4SB+Y0R9KEOo0+KVEE1ugkaYo\n",
       "58++Vgg/I4xhiAJN7jCtkAi7r2cGkA8Id05a13Ff+WEQcxM92oP7PCViF29aamCeiQ27MXWOJDdy\n",
       "duD8EwoVHYRbraX0wa8w5EpoGs9JY9NxNjNXRa34+D8YaAKTOiQh+2hafGAandFNt4hmi1w3VS5+\n",
       "OIjTW1HTlPc+FweD/rEeLTu9xBpX/Jks7laza3F+9cn2lEvLI+ac0/HsxJcWkntyfjUNi3lDjVSv\n",
       "LaDlfilmMj/xswjgGvppGeN1WIGeoPp43NKQ1q0e2kQmg2dhOBGYNiyDa8NeLveIvipfqdDf0NV1\n",
       "Sd+RrogaktfWG+3QCTQlHa5Pp1K7jdtPc9NgA641DJ/zakzMYfttN7Lvkft+T3N4v25dNTam2zLs\n",
       "b84ycQUeUif5V3PuhS5iIwlGxGh45PiPiY33OmAImGtyX8ThhABqZxG2zu3Kjg6qLyYr3zrdSoVm\n",
       "9JOknQh8KEunK9AKaEJSV/uK5FCckqx/Wcyshq29S5PACSomRCZLR9GuGELmjI+4BiQjShGBA3/1\n",
       "YzpG06U8AlxPUAlBYg/xAp93HnMzZzVlyZYkFGKsSZoMLtooZ2O4tqsnX4hryOHZdR77S0prAHc+\n",
       "Nk/Up6Ulr7I3qtVUKLrINc8P7bhpOtFIpJcMmqRiiIY188TXSIk8zmJ5VrUhrVwwRIQKI0bpqU1M\n",
       "JO1LT328KnrkLdDlkqkZlypv6od89H9cAT11327Fyh5EbQjvOGdJD642oTi//xJTeP3QtHx3He7N\n",
       "u/CFyv2HRX6N4v3XavDzomNOU7Dqc6/5jeAN0L9YYlORwoDRD48efmWMW7G6HB3DgPsJtDldLwwq\n",
       "8vadDxbSuNwPXI2kx1EHKBiIAPN4O6GBs8VFfDkiNuSiQaLSLaLxTBWgq4ei3RueioDTfd0SfFhh\n",
       "9Jc9gW55vxWYS56ggyXDxpyabmaEE0K4Df4l/7JMSQA/nsz6LctV6+0spNBDcu8zZ7sMqomKvGKy\n",
       "RDh4FgF1gbuFdPJocCAec1j7wX8ljHb2cG/xPm+X2be2N/Avd6dq/Ut8+qksxQaA2BtYT/a2n9Mm\n",
       "b3GB66Pp+xXKW7w4mIO+neWt15jaXBQNlDrdYNXN0vSEwP5/g4aCWBcHj4ulvB4dihU24W+YjJIV\n",
       "ONJ9SoHe47yaGzOQWVJFKi7SjGgnZhbh6Q+VanUHJ2gvQeljh96iaFmjNGGljKyOERQMA3Y+ROez\n",
       "MuRAUAOHvVH3ne3TbIzlvtxcg9LV48Yb99Dl0aMFu4Vh0DJQTa9oO0eTHEjqwzdPsQk6SbaXoaz9\n",
       "00JYmgRDnor32/OwCOo7oRs2a/x7OKci971YFLbhkfN7Tkp3IxbVZL195IEUEIPSaoIgcsl2ypBh\n",
       "CoWhD2USEQGjImrWooCxpp2WhJZnH5wSa8D5d6y/GL2kRcUaTVeuSDXEPcXaFSmxqSwKTWjQK4Hu\n",
       "xqP4AQkYOnM2r5AClnkdQZlSq/2ZkuOi/iQir+xuGCP5gJl+zRRu26ECFKvu6lWc3iQ3+i/sU+Bp\n",
       "18GHVLsJsywMkGNEfnp/aNJ+nS3wFKBam5sF9ZLancUsauKyO4AuKjYRWP/DLHLbpjpv6PTO9R6I\n",
       "olzCOy84TML7CwJ8wtT8/EvKWUHDpscCm1udktHD3NDWRSfuxUwpbhHxi1c1WMqTBmhoqJSC39tL\n",
       "Ud0BYLGDB0Pex43Zt8ijXRsr7orEsyHUO7cRsLd7FEh3PF4Dteq2+yCMdMbzGqgsLCclvcwl96Em\n",
       "bU28+/b8P+sZK/6bcBC/2EjRTQXGB0yrJ36aE9XUuuZD4/8eecgT9zoZWtZUahbWyytqKA4RnW6j\n",
       "EaT6Py/UKOABbDgYCYofu8gF2C/ennriBpUsSf3KNB/vaU3+5gjfPx7g5+V4fS8SpXjvWDQ5i+QJ\n",
       "KJ/eOT5V9x053hSs6y32ng8RZ4w+aJk4OKsUix4yrmplzo+svTHmnOp4SbUr9SjzUDwiX0dJyY8o\n",
       "Y4PfpIvkSn0xcHYuO1+rszHyfhVrYabruzXQwAX14gvJCYOoBoZ0IsaqxTlumrd/nOk1JSw/03fu\n",
       "7vWwSfLn+Csox9van8dX7488UQUrTAXTR5wlWRZlxmPdSbOMnK6B0TvOBjXJVME3SWVg/yQvKj4n\n",
       "WCOS/HBRH6ZJfk1DBQmIGBotr2YF+7L+yrncTs+Q3GQkxtdbK/NeVhbmpGuml3BbVD7M9+IKCyK9\n",
       "pLQEr+jqX+1HtVi1PFIuFS64lPM1TvfUDce9Xy1IZecEYBI33hzoIP2JNcjoZgcptEDn34YtPOND\n",
       "v61jWavuZIqWWU0WwQq9WXwe86DTGJnqY1dePfKY9rJJqG82DtRfNio1PHYH1EjLCE9Tx2bB7M9Y\n",
       "Qy3Mh5RSxO+L8beFKNDYeHeDQzBkV8eJg3tCbJcJHnjGSmhN6SqYJXofVZdwTNbWh50mw29LHtfB\n",
       "33n5TaLqNs+Hazs6dPu6Zr2v94/fiF/hnYN8fUTFNa5HiWwyqWGCyTK1RyZjl4mboMO9y8Mn9+MY\n",
       "MaZk99QJ3w9SCAStnAomSvha6rxsGU0JdGp8tzISw0k+DGfoJsu4+ohLQ0AjqzKvdp09liObWZQS\n",
       "gnT3CP4DdoYTFatNGbASXBFfOkIs11QwgFYT+PT/71YKCED9yt0m9Wr8yDe6cdsAB1jTJk2GVFxG\n",
       "i6fu0xGNT57QLmtch9Gw0ZoZ/W1n6WmAi3GNC5ciDQnTsX+EzKapxGB7YhK/p5y/yHbUNBZeNKVC\n",
       "eZdgFEGFJ+xlRZgfGyuqONYi7JufKaS0p5EJRaZT96xAVefvJej27xAQGSwWvYNIb6e2vVtYgVSE\n",
       "XkUmrAgV2sLfv5otrrENfSq20hROdU8ryAtT3iBOSxmfrPoKovM0Hf2uv/zoGLC02B62q6tHsrjm\n",
       "iTBE03bWc63cauWi/wr+hIKYV/2X0P7XSldkQL6uOE0wlor7dyc81yKMH5C32Tb4qn1Qnsy6Uymo\n",
       "JQKx/v7PV2sC7R4euzI2dkLWmne/gyixsSAzKCWxEdC8gmfAuesyP/w91RkvTUjzQ2P066BbHAmf\n",
       "fLyvvbqv2dS92Zw9ujFeFk+/neMmmIjqXFlSGW+DBPoTE9jfBbnhIw3VkTxdRSm6+5dRQBWxAAAY\n",
       "QgGeYmpBDwA1ofPd2ABCnsUhtbshkbhgtYBr+qYUXb+D+d2u3OcfIuSS+rKIG7xfg5t3AW6mbZ/v\n",
       "8in4LjYftgN/sIDG4G0+Gx/wJruC5f21Yf8p6TnUfSSMjOHIaE9851K5ktrvEHwAAHEu/9JT7jbZ\n",
       "h6otQ4rGwARfI3m30wxhRHvB60NfuI2ngfK6hQs6erciuBST+S5dtHFFIfDXQvgJfqzSsrk0t9Av\n",
       "reJhxQO56Y/DDR7/uA+CgevpTT2AHqIM81PGvPzpxpVSyxh4pMXBmjCSvPO87gwkGbNSrdLdvhB6\n",
       "VaEyffvCBr2R3jgx8x44PDn2IVjON4F3cJxI3Mvw1wPwZ7wiig93XDlrT+VH/Ek+t7kyO3yjl/bT\n",
       "vo2+9V1BrBxQKaZRntWb+4e3wuZydoo+6oUYfg+L0uAgqrT7EczdD2YXdqDVSCOKRFsm5oWn+K7c\n",
       "9VkvToa4cKh8McG93uWK1ljPldA9NeowEksTtigKGup6rgeveehdpAHYIWYiuLHIJs8FUlFLt7zF\n",
       "cdYCHtcD2CLv/4WEnK0xsvngsOxMwByj+nvekP2RNYBoMyeQ7mWbdmjd9EG3oeXM92Baj+UVUoZG\n",
       "ymrmm3Cy373tMvEXSpOOwZMg77gzgT5SnuTtcUhG0yI9i3z5ST1UOut/0b8wJWotLcQpv+yeEIcT\n",
       "lHLx2zCiUiq62bOBiXjQh/kfDQ2AaVzFrBhvvNq/9ZPrYh7YFLCN/3/at1ZEPBYatW69QP6nlCrF\n",
       "LwiI0xjyI0Bw5kfMaGdzDzjHq3kBSFnaoQtOIy4o00Lw1PHz9XP4CRJIY/rZ1t/n5h+tpC7Wpk81\n",
       "kGwJsaCDg/QWHXmwHEwt0j8EAjKV+2uKTKa23168PmDLTd5Tzj7mNUWu7ye3ApYOi0gBRj6GpfFt\n",
       "ChEQDZUhh9n/25d3XqRkAgKr6r47eH/NM/DDgvSge3x6U7w0WrSEW2JdwkN8b5oUB2btQK2AoZ0u\n",
       "s98PGnEBvWlmB8z9qTMjD28y6Fq3imM6X4VTb7Xl4WS3u+DLZXlF/lWo/YlkbpN6Eykfv6MXkpLI\n",
       "buwahCD4g2OdFA7kz1LdNteF69R01jhrUa2pGFoZRSSR/T3HU5DOA+vPDv+qRu3Oo/0hJsRd9+DA\n",
       "9exqmgUP1S6ddMJ2rq7cqxz4sGtsARvYDGFs9WOvijsUm7JeZ6WG87h+paFbAWrDpxxhfxLHoW4s\n",
       "wkCv5EVaZr2e6Y/hYZlLRBKlClIEFWOqog+oAIdeiODMSx2Vmadxm5GmGA8w/i/7f6RGMz1OG9mF\n",
       "8d5TlLitB7teq68riVHVGJ+IHzz2ID5MugSIY0Bnk/beu32hmp8u0PPQJc67AC3g+g7rdgT0sj+E\n",
       "ZgWtu/Mzp1/e9eFGW/RFu9jgn1HFIjKzQcbx/P+MeYjrbOf8FqD6r3wUarrYecK76HMhVzzx2e56\n",
       "hFC5lHmeNULpqPHZDGHMI9lOgDb+ICO/eiJLxjlCYCJQj67r4xeGE8TWziR7TMmoUXabXU3sj6xT\n",
       "NdxJfTEmRJE8QH0+/rb19hdA6Uz0ClOu508okxBf5cnTklsWxh2Fd75+f4gQstZTUShjSgIB4yfb\n",
       "C+Al7RtwcOaYNAMrtMsph+pUv0ph6kKXe8re0k6/etlEzDMueCln3DMKwef7+zVO2i2MO0YmRpj7\n",
       "gRB0j3A419AIWTpAjSaacCKp7ZJ7HKCsz9mvWNAYoIoccDmzS56l/d7LudO3pIbwQe9KD8un1oLW\n",
       "OyAp7RwW8dn+Y+q4QxGqAlABONakFevuah+P1M+tXrRBS6Qy/EdukQBJBscfHE3DgAP2/Lq1QvTB\n",
       "kdQU0XhdL8RpQvIYrdKHcgZJ3d0nS8Dx4T8Uh55GzyUTcc+UpgFlmyYm20sTONasgkXu7T7XKdlV\n",
       "w7gd2cTGrzuP4QcqGKWZIAUtosSj1AvwpCdEfmZpXvncSVNfxvGoRgNCcn6dej0zgmqvhhgaNOn9\n",
       "kIqgvDb5kUPEK28+RTtGzKIt/OsWuv9W3YSiafHI9hc9L8x32taP6gCE1ayvcxUIczxP0CHtCQBs\n",
       "igEEealCyhxxdsSIwOjizzvsqRNFMizOn0oEd+lxH/kfofWSPSCD9+Sj6OajVEvJv2EDQnNv8uAX\n",
       "NVkM4goIlS9rNbvshEav1yuMLGxA1G0OGO9K8lGn68QM+QoppeHFU57Fi8qBeg2BMrfYvf/HFAQk\n",
       "0IBjygcTwa1PwqMuqz414xpv4wXr15ttzm+m00ChDt9uDyiKflyziUfKLhUB2L0r2FRnd81LlBlJ\n",
       "qLEnCxZ1sW82YueAxp3geaZMSGq6n6c6J5duGtM+2mV3aQ5NgLnJpWWn5sNwEdIxKY3ocWPpW/hM\n",
       "i3Pf8uYg2p0sT19Gnh0k6qC+KMSdCbmThAou1vgYCadXYLUZ+9yfy92rQKi2H4IasUFA5jpno5vp\n",
       "cZU3rhGyWyQFNAaZemJjDNV2Gu2uj1hF3c2fKJiCf3oqAOQI7knsFHVKXdxVhN4NIBp07BU3tCnb\n",
       "uB406CWcrJM6bIrcM1/thkU11agTZWDHWmS7Vw7hBLR3yRRV5+GVnJpAORXg93qTQOXvQBmD54OD\n",
       "auJs3Xc6R+bvdtwLm1w7mQAximRKJ570VUgS/smlupCR+381A1IrA3ihVxwKzcSa+9k3//ag3a3Q\n",
       "2S9fFXiS05hwpI9anZN4MxYqOaVN4NY6zU5SEEv2pjwfXxP2t9bzleyoDDJ60RK2ODcjfiaDBoSE\n",
       "mENhaYpZTGVoDH5Xs91MAF/lGCNWHln/1K/yzQXhTZAHj8vPG2+OTVulZW/QCX9UXhCU34NK1EhZ\n",
       "veFMyplL1Vm3v7kmPIYu+VqoT+p1GlE12VmJIhkNF8Tcwg70PDM9Lyxq6UcOWLUGfjzyYR57D5dN\n",
       "gXp5/f6fJ73Zp1M7SFmTQsGWhSTvjP20cXliEfcCiwWNS5Ym7CEnwGZiEzx6NM+pit3HJQvLioxq\n",
       "a1jJHG5I191kRSk2oKxQDb8YAZe/gwHmWlx993an8kh/bLaxr2jtzKpuAtgroGD1Id6m9HOVgAVi\n",
       "4KuPcTZw5Ltc45ZSc5JpBFcdbQnD1VjXkXZ76HtJpC/YoCKgno7QFnUh8lQv+ZQTg+GkSzdIcj9b\n",
       "1fK1RGh+oVziSJaEDzbO6QTQmd6xVhMckxSpPkCESCiaiyuuzDA0EAMm+N5Vb/jjipQP71HRSuYX\n",
       "6HejeqYnRg5LqcZnzmptjQerplQeRzX7MKLTTx1uyIDNBSUdurdJ/RQq7qHOwfuYQWfGrOIPwUmm\n",
       "WBxevndlmVt8qDODQuC6i2PRAGj821zWIBKicKC9eu1O6OjV4yh1XqxuLiA1tiE2rXFxVH9J4ISc\n",
       "AB6J6BGr4oPPus59K7FR3uxoz0wvBdbYz5xCRD1Nc2z2wlwM5kaR6+Z3S1yiRtWJAamwjMhrRdCu\n",
       "flYTmbSXmHWWZOhw9ixdSu0esO/vHtuWlHQsVR2soPKWX8uZAW3BwsAUcEZO85IHSXxI0crgXwJd\n",
       "XbrwzrLIyIlqo89qbEcAmkfWCLnsk9oGFUEuhvSyzpaOkBSXjpnTusTwUa1M/Zy/laAC8VwHaY6W\n",
       "2r2tffs1+o1UpWCdandemlwDVWU5rWJ+39bAq8FbdKFTGk14Jn77/lqmEUFZWmEXDa6V7JVm5IOi\n",
       "qewN2lErai6SphIh+PGf1t6HkajOK4wBGOdMtT6uFpIO9BYk03JzZYzqPYiZzx7h7/vpNPyjsKYT\n",
       "0xx2gCIoEbGfT4pXiz/zLarBgfrILLLtH2JLLO8mtdD0q4N53KbDLjwECtUKSaJ+7HhV7jeSOY/P\n",
       "mZx/fiUYzUmwOWZQZwk72AL3ebl+JncdSKq4/LspoNw5NSwKM5VELuy0Yeuup2CrL8M2w8q0WMJZ\n",
       "c8JH+7n/1ZU5rbXltygLrz7fctTD206aDG4iDJax8uG+OxlBtlWP355YwSeNQqyR9mkO2KAh4T+E\n",
       "oA98cbWFlfum2rN3mk6D2emk5JdvPOISeGtkJvLtWsc2hCXJdMeDHMxROMxECfrUGgJ0lCbVn1s1\n",
       "dwzfj5rnxBapTPnahX/+lCuH0PDC4RN5VUWYn89aunfZHwL6vN7LG0PFy20lrTDO1Hi5cUGB5tct\n",
       "Cv4G1I0zMlJFkHMN2n+RMgbugZbOEK8J0Q/wRntXeT6reFVu45etUJc6/KTpF6gvXWWKsFJoDC84\n",
       "UUFGJQAzWboY74vFwMPkj0SwbnGDvcYFYqT46irku+Z2RWRGzD6zVY4i7d8g7sF0Cdqahwa1VBv4\n",
       "oW2ESQ99bH5KcKXyoORKRliIQMqAAK3Kj63ox1fOexZo5JRv9EqxP7iULDSAdsiydFr+otJMHh0a\n",
       "QMMt10tXVu8Nlnco5z4cjQlyabQ61YI6Dk/Do1KKymcxdFNlqzRm3kevJEnmOQNuK8uP88N1XD1u\n",
       "txi3ZNf7aJf/fXRx7vhgUw2lBbi/3yFIWpiG4Ltf1gCxyntBnQjIWuH8oGT4p6gMysGDtxXcJstJ\n",
       "I8oXHoPxdIC0MDxSGHy0TeLGVgTttDIUoIFzXSh97BkiIXtA4gInW/oHQRJKkOPQp8zyrCaimoiM\n",
       "DziaE+VwVmLv8tFike0/qUBkEqv7mh//WErYC/occInoNH7ezHJinRho2gaZlbqN8tdosoHsjBJe\n",
       "akO2yGV0GS2rlBnQp9QtBZ2t1t2cbda7vkMawvHFbSGUuMzDPS5paeV9F4zyYDM1pwNh0l8GsOAP\n",
       "xAungAHgJU9oelRCvYqeBj179/tXojnjrCv5RO96tnE41fSNZby91+8uEfbTa9O7soPb1bZ3XSFR\n",
       "MzUvqOpWyxqsko9052ZNC7J66eXdZ8VHdjO9eepB70QTuFyRkq5rGaLg7CZfgHObA5oaUO5IUdaI\n",
       "5AnbI09xjo5JK6KpY+WMNr5gfiq5wwHbiBK57XO3VKjJZZXY/oXktdnTGVzbf8hX0lxkzE3p/Qgi\n",
       "z1MxvpX+RseSWWop/T/4VyAlL4did3gdIH2p4IxruPa1oAOpNAtr7ObtahgHc1yUUA86xp71xSZ0\n",
       "gFKn1pWJ0sJvCQhRk32nIOaTyRS/BwD5FGU0sNz5h8bl+XddMFzOrndhZQXCRyb2zYqKzzCC5t09\n",
       "arfRrZ916w/hXqBoj5l0EBl1AUFAi3qxyATLXo9vUDLvTk+vu19402oQtKF/pV19L3qIbxXEmXWj\n",
       "wQ/4XIsCje4e5MEQePXXbZvs5MqKZVshNFzALA9jk6+ki5pqc4ReZzQaGZxJ6PfF25bcuD/1AUaY\n",
       "maWZB1RtcXEZFUKPx819lJvOxThkhys2IDF0kx3NiZgjQ/lqRj+oUksArzGJkesca7qQH1ZUie25\n",
       "4JwrG4LUGlE/FJeaqQwekjX1ovsgPt2MR+OCepbga9JdLrqca5nPf79uuxZluHwO1WA53x/D0Shg\n",
       "+6f11MpxjMyU4J9XENVtBDfj66wspfWAPo/Kz2FJJV5AkpJeZlHOAQfOuU/x00Ij1FtaLGcxfGmj\n",
       "RvHwEwoicd9hlc3zEic2f3qpzGSiM8XcjwNJm3Rb6HzYbmZ6QH+MpCHNJVQeNNGww8nx9BQHzSHe\n",
       "8yg7BTqYqYEqUIcbXeYYrwf+pbf6t6tnSImCY7x8jZAXwr96ygvSIFDh20Gd8s2ngz4l81WihV55\n",
       "MDUuWsjDg7QiZKqkIoL2jvF0zMreUGOtv2VrSuxsbrmZbcddNgPmzP3f8/x229rmIls1D+GiOsP2\n",
       "gxSfVeJNtPf2mpCStChs18azWyu2ZthhmPbG2oyvGpyV30WHURXIo2mGCWVZtnvg7Gb7eF1V5/o+\n",
       "KV3UdlnsTuB0TD3e6kAY9oVBFhH54d47Sp81D+x0sCAuV/uzGByF8WE+P50QH/tdEG69O3MydzY3\n",
       "Xbh+YxxbTcmPwrjMAj9ISzAUiWKrOB7yuShodzx9ktN1PQUpOWs2WwVr6SqRjX3uVUR+ZP5Lb2M3\n",
       "o246MZXN0XgcwycrElGE1rV1b1k9Bo4dtOdkvPpBR8LWjzJqb2iZXJRI6kRyPOCd4EoTceQx3d6l\n",
       "/O87TMY0ZnXdMyObKxMQ8CqEBtp43k+AGR+Dm5i4gOVMNFxBhJmfcRagF9N2HT1QXLwjIu6+wtmm\n",
       "wnfdjNgTPNm10iCyk22qfjqsX4Qa4oRV1TtQqaJYqm38B2Zrc/FHndw5YmtDHfdNJZJstJDsr6u8\n",
       "aOFkNOLLrbCR65uP6JLhxsDpAJYZYMjc3gZK0XeWctn0fJ0H9teJK9yci+1RzGV3IbBdGfcwIyKl\n",
       "U28BRpRgiDaYl7KfFf0w47ZaGZ7O0TxCtGDyF5tpvoO4cDniLIxf42x5kaRUamjDilULlGHh+1hl\n",
       "Y5kzFAgDIkcRHK+WrqjNzTCy6IfQZD1qpwpVsTxhjomJsHAxTtTJST9g983fugGSu2JaqZjx5uGx\n",
       "saw0fhXJ8z7pLEVyAr4Zi4mmQA0UB9O8ACvNppCsXKAU06o1xN5QKY8DbkX50Fb7+u/sBn59AK2N\n",
       "/D+7OcviCjIMmDVt5s2Mu1yn0h/3J1bhOItaXmTpp/Z9gE3kI/1RRpISyNB0vWvrv4tcNgHZe7JB\n",
       "os1u1MPhNqGQF//VE+RH+2/nLrhDjHwvji5fliQpfCmcoX4gWQZC/LjZgzjZjfj4d7UEu/1OJ3Bs\n",
       "NRnsmrFGDVIEwGIpDOQ9YXK4yKIgoWTl934AgeOIQoPB+VdfpgPjQkzqBmu5vdZlYY9XoLXVgaan\n",
       "TP63LGPfO/TbXMnQexFxBeVFvaMfR3OlLggpfzgxlx24/6+GT3sG5nVkVxNHhpgl5BRJhA0JWRGH\n",
       "lGjO/HVO7enuaVr11MhBAQ2rev3w/R0J/+x/nkrWcq/WrrBZBh52fwFYwfnb+fUglXFl8N4nopEz\n",
       "9KU8NcCoGdsZA9ggXi+tY/KCwliPR1TLrcLIrggOcci6MT63QqyiYYBe8JDPqY4w0gR5AQtcBHCP\n",
       "ixyJ7edF6ZvXWwBaYDm3Hq5AjtxAJahDVcJ94FcznngPvF9tk7PDZNCABKFqmQ1LXI54FF22R7HP\n",
       "65sDQnvn1q/pEkjqBGoeNzBGC+TAUC76FkXAgpnaJDCTB41PHSr+CNj6BOwWVCCe4V4HlT+3Cfi8\n",
       "j+vJ6JV74pwlpgbfWDvjFX8tPAgs99ratq5uiOwD4uDzF8yJ6ESA4uqbKLHWqbCUQ28X8dEC1+dl\n",
       "v5vE6hHXWmjdOopcX4Lm3W1Fdnr20PqSVb2Sy5QtYRuKbpF7ML+b/aI8eMa06bdiPxgmG1yhMXg/\n",
       "K3hu1XR3+k12FqfWiZXi+LErrICK3Kuzy0n0t+rlDgaizWpHxSqARZPAphFn/f1KSopCaBQSusuF\n",
       "GLK76wuAJ9w4+A1qZimM4P18jqVoojzqPXklOHwOM5BUMYBd6qZO9umL0zBd1fBRwiYi4Hzoy0J0\n",
       "FD6EAwSXslqrV2W7zP2xpSXehW83nPrTkxMddjF240ZQj9ModgrDD+fkTUsBZhsWxw3/l6A/I+wz\n",
       "8xCZgPl2tSD8UsSV3VbrwNSI7DX9X+DnYWC8Z8qSbY0j9KCazilFDBDXrUgqFhslWliTl4Ucevf/\n",
       "sCo+hBM86kH9fLz2OwpB067fjsE16kpGut8OSmjRLuOhrzG4l004HyLGRIELqsZkT5/k8vq5UYCE\n",
       "/aICft6vLTLk+mJ7JxDHGn8vBw3bMQqozDnHHXyxwH3OJ2tk3HBHNOQpZsB4nb195FnkGhG1Gybn\n",
       "+sLCYJHfViII5DplTc7iej05+MAGRt7e4A8iPIPoJSndIQLJckz2p+zG86rLw30TO9sYsbHsRZi0\n",
       "iOW1MTLitKej0QvhwVstr7Rfo6TybaYRJxGFKBc0AQO396AFtIEym5X/q2BKiTQMueFWHUD5RyH0\n",
       "io1g3g5+JWaRAXlWUlPYgpUoWW2h6Wckv0i4F7TV+nNzvsvO14D8NZf5ATWIydVf+AZFKGHFf+r1\n",
       "uQ9utYzydH295FJqs1N5hbsDy63NnoOEDE7j0vGfYJNdtZI0xhuMW8dgtIpoxC3pUyjFhq3G0b7f\n",
       "mLRz0rofspMCVRx/YHTVlsbwMmTrjxER3ZmJWnWPtwdnJJdxXMv0lzo5f99F6CyKygqfSBk4/LpV\n",
       "uRz7t4/ohFaXiCVEhjyPDGf7uc9bZUrJmBuybVK7JeX1my42KCeKfDEBVQ7VOk59Bs+RiQOQtctX\n",
       "Y8avIc0CxF9ZJ8AHnXQitExTP55KIrJhWbwbviM5P62C65RJZqKYGl9f0BimsLLrcV2g/9j+2Yjx\n",
       "mDfzDGw5cc0+8vDuUwDQK1uqQhoYpvgcRAfxlt/9HXj6goZbVQDD3REuBAmH1DVYJR+K8ZCXgAAA\n",
       "C9NBmmRJqEFomUwIIf/+qlUAtSjRuACcjOj1TUy1vX6kpivdBYw1aylnKn8DCb+RVad1OBNZwgEc\n",
       "scwE5jnB7Bam2qR/2TorDLAzcLFv4tJO6oHuvrQO2ttInzxrMnenwRIN49wYBqJUJc/KB/ptJxF3\n",
       "6iT8gazY5Kv0k/Gr/6AvItbjrWZYdGTJmZQf3tST00y167T3+6jnd8ySBYEWN99Nuj5s90KPSDj2\n",
       "PyjMgEsVzMcyzAa5WM6CfJy6fsUuh3nOME5NY7f3BjWiAvu4LKeM2BSCORAH3wVq5VUAnPmF84Dr\n",
       "7AdEKoG8dykWUebF9C7/wPzJ02xbG0kUoTOGRWaEjKVQSatsIdG8qkzv+6dTQRHpXexrx0a8nLYI\n",
       "89s7D9Dwr3RcUeUjGJNFCwBKeedVt0KVWkR/ksisxaCkj6fbJ0envbufhlzKuGjWrnQIXD8hgWNC\n",
       "Cg2h6o2y2CoxhLqbSBMdB7gPB9gudVvIO5LDw9bX3Vmi6H9YmKXg5PG685Zz186U1KekF8ZwDPjI\n",
       "ZQxpPVoSjy26AlszVfzG8fsGI68jt3/YFrwsV/DXsIk2xB0vjrrChi5DyGR8YnzZFvD19YseV5Xa\n",
       "U69uXhRM1aTi0bVeraJ/ePAmlbzF9i7dkDoqN8KtV8mW0jnIifHNcRP6sexhU021+BmW6vyp4axp\n",
       "VHNXhcig08VMwnQ5Oy3zt9uysp/rvQd+eTJze0AsZAtbFbuLz1KpNlcqCmmny6/mudpjUzMqTvFZ\n",
       "nYHcNt8j/jFc4Zh9yBlZaw9i+ykRKs7L2pG+v5OZHPHEFQJwD8BxycYC5W+JMkALJpDbLXCdlLmu\n",
       "SKyhOW3Hhc0p1y22/j/MPmkcqkOsNSCGTD2xd3vDQllW83owcUpN8dkqEAwZwz2m/RggwqYoAibp\n",
       "QZ/SVk/AOOL9DOWRInsGVWuaEYl7KVyWopQdKX5eq6oYhtoPESV+kIX5lima/G8nxubuTdlTNGz8\n",
       "Foa2hTb8mF2+XoqEtteHMugWkSaQNwSlU5wDiE2/4Q61lszKwAVJUMnOekM+jrOI5dUIvPFIL1iH\n",
       "NxkEoVNL/D4WTQ4Y4nBg5Swkxlg86gcSmauYPf/yTuOrTA8dnlR4+oUDjEwPq8lgTIIza6ucNF4J\n",
       "rTsLRHr/5+vW4TH2kPfj0y0LH5BxO/+43/h8MwebRPfI+qT1ncfDYQeakc2cgXKUAK/n024TZEIV\n",
       "yMqj+2VJ4hu91d5dT0xvbop8EuGG2m/AT+NPj1Q9MbzRam5bvgeUvB7Q4fbh7XJOM3eYl4xfMaxQ\n",
       "UIyWWkMgtaTMayW5NQ6EZ45Sh6mwatmgRc1sUx/7MLbWBDfimNbk4fZPoLvI2GGWg2pO3fnNAkH0\n",
       "Aigyf2LiyhutqGrNERzaHOjP0xCfeNE6K/aKTt3fNwMqpsrIBAZeh1w+Fe1ZJJ2EVzsvHPQDAmvo\n",
       "3lzORZm6rJiLTPBhxZkdzQpNy9/9QN4RpmyA4j6C18r4ReUtILbPFEiY6/dVDcp8ViCEjC6+OZTl\n",
       "6GQVsXnHmdY4IxhXCzb22C2pCr7wkGc89cQtFcPwhMvSxV18LwzZlM5jCn45kLkDXQwHAbk27TFr\n",
       "XKPM9mHY4DIGdNSYjF3SaTJIqarzuvWxe5tpRZ2lzCI3viS3oFmwMYPcWiAO6EMmfe/EPk6KFwQj\n",
       "//OteNmTbi+qPtpdn2HoXNdzj8ovXAiFIuiY2Y8V8W8JWz9L3/Uhc1Ipomq/mE6IXsG15sIyrDJy\n",
       "HEjRbntKT1B6oZgXoDoIOke/3G/S744aLj3q8WbKPjZ4O5fqpEir65pMJ69kSEwyjZfAm5IGZUn5\n",
       "5M0jgW2lmUDEKO5VsX9uS4D/ncnGRxA/4btM0SNvoYQ8Vnirn+ydozMrMMTc/6j2PHULZAE8R9ZY\n",
       "mXDUj6jTSuHPYZ+QIbNVmDnFqrVMJp5BYE7vtjQwk9v+GBsZ5VVVnBZ+SoLlPHQH/u0NPYpilw2U\n",
       "cTjE9OhUjAFxOe6y+y7P0fORWwjrNDEuNIyNxlTqWfhcdVRZdq9TPa735Y7PtLCzkHyw4SaM25Mz\n",
       "ouHEppaV+e3LqliBAeV3HZd428y6gNfwLrGWp7xq81hNrF6zV3pUpUUVgH7w92hTfxhhPSLi0Nl2\n",
       "DVkZN+GAnKJo8UxozkpqdYXlqmqWqmFiN3fzKZ/SusIIan+BE5ezCQBGZ921vQoIFYxJEHCzs3UY\n",
       "pHDnwYtRKqVp93Z9jSvnPm1h32l2QZyfV/iPTvmPPzzjuO9lcANLASNhkVbj/MmPfw56Y3OjyhX3\n",
       "DZkn36/bdco2wASBId6frqimJEi2q2KAE906iuL7GbGCn9L+HPg9Axn97Q+3hhHZ/l/E9klR658s\n",
       "tGW8YY39aOpf7l4EkQZ7o9ilP9M9YJ30QYe5QlH9ymkxhOEOPI0DEAw4osHyM9D+rrJdHg1+VPf2\n",
       "iGOq90s0xhGtcQ2qyX3kz4ShbDa39vx77v4lzr00FWV3yiY8K/BoNBfOgJhaKe9Xo01el6FeZMMQ\n",
       "bku3U9BAO4lfhYAOFyWy7NjUstb8mP5sWyPplgrX8O2snNqtQc9MVpVKr1Fk8G3DEARlD2I9iHFv\n",
       "tNeAbCH12sJrhrPI1XOLoyj0bP5+KHM788JpQ258fUCN7Icv0L5iqkZkkQBW1BrmJIREJP/dbjUE\n",
       "YmSIelHiCohsmSKQcUwGSO/pmvFI8gsdppQv3DcjTwdFLbH9NOjqEjixhPYJOfOnQg7csNuvwKXA\n",
       "UfVdT5dcJFsm5w4Mlclp13kTCgTtkYLa7cldsePiL2K5gm+YEWoW2CLs9Fx6ocZfm+0XHmliPPQR\n",
       "9sfUcXS7dL9GNQRQgopCeHxDy2JpRjPvWO1Be/n0dPZLHzhecZqvXjfMX3Rbuo3l764Z5sO8N+Sg\n",
       "Bb5bUXVcVfx3YXiEwWijnviNxdgI4kvLit/XCtHvBV2FroZvJfbQf7bA8iT1Di0//xmbCgShL92U\n",
       "KD/zz4jQq7TmyLOZLYXWVS5SMrmClWd+18O0MzQFZgtzTKK+Ca7QbxSIUL+t7+kUNH7c3bYCaEjg\n",
       "/+TVzCTF7mSO3G7WdJA1nf5VAAdsNC/BjWVW+XhxQpIRN1D27j4OMkKyytZhajR1EulmNJ9q2h05\n",
       "8BExrC6hsBPPtKplDoID6fRTRY++pZtcCO9BucyWjByNzSY6KDBxyGsbGslS1qxac9LBlXexyi3Q\n",
       "qRN+X3aQM8+spWyGSDi60kJ2GTnwumhroXO6AelL0JXaBsYw/NZD4Ow/lll3e2nZsvDqCwmnWkFq\n",
       "DlNby+QCoXxhFj/G6+Tqj0RefLl0rTGwlfq8FqZmnzmEvX3CtGKCm4YcAdxX+yJAS7zwiqa5cLfN\n",
       "UuI9AEcMRZ0c21K2Rzvj4zq7hKc8T7I/iqOoDGNhftvntJlMerG+kzEGTxOe7o+AR703++jc6VSG\n",
       "T4X4kO91d+1qwAJemb7fEqXBGfOUi6cXBy9w5IaIXYGZnGSFEtf04+Rsn1wIbyXauL/YPidBUCKk\n",
       "8pDN1BVLhrpIS3FtY8T9xZH8HB0x+LViJcfUrrb1fXp1xmAtCZCk3Er3Vys5T+9DJYN/izy6M6Lb\n",
       "Ce4B+v99zEZlW8hf/ZQqckukp6MundU6xLg/lu7HVrarEq9SQmKYNja8QRrkCPg+SJcExd9PUie9\n",
       "I750vsPsy6kIs9luMbv8mkN9ijswr/Jh0hWhaNXDx/dDn8NS4sRJaWAgv2l8cuGhPanCQiL5caBw\n",
       "5dZ+0q0UUh1S6N9Xm/p01kKRqtuvQrZRlxfNaYgffUGGinrApFHmZsZV/WONvl3gjZhgyxle/Vi/\n",
       "RFqGnWWKAWSlSa+OZNEK0rymQZ07h9JYJr/GCubBaGRGxCiC0o+9T71CL25wqOu2LQc3t0vaOTmt\n",
       "zxJHfpO1ghUuZTcWXwOt5Gk4mSP7GMLn7UFnT7STfvVGPn3j+ZE9wQ874icju71xkhFX0A1izQHG\n",
       "TCtlq+sJYi6P+DHp1W+btSj0YjRM1/fkL3PjlPumXgFtfYOwOQtzxA0yn4U4ho1GElcIGgXIb1FV\n",
       "1fGPn5siEysAAAfcQZqFSeEKUmUwII///rUqgFsI/9WlAAPumrmJ27xaEc20msl51xsL97J38owq\n",
       "XBCRA4JK8YiQnNo2LWn3JWrcPW2lGxx4/7cTWebf7UotIbYM6LQZrWPsgYmVaPkzlFUr529n080n\n",
       "jo9zCEIlxtddw1pOPwCZyMezsek+TkrqrtuXFbcHszvEG/lJf9kMXcv/NthhiZ9U40ol/xBFoe9S\n",
       "HNKo0jm6iBjyQBByPH4A2lu1KPPamJNrTPDr4AmezDYbsm6ZoIK0ZI4nXLzkbi/LnmJvDCGjV9Nm\n",
       "MPBa9yUyexncWFeJJ0+tcLbrogGQo+gOpi0PpBcn7HbS6SjBS7jGlBv/ZZMpgfMq7jc4VR2OQVR6\n",
       "emqvgxKOLtKpLomgBrgMdrdkeSh48pvtOUQp7JniN99QKaFxA1iVK3yemuRbECTsj2UcYgy2NLS5\n",
       "XJkEnpjqNi8oyURYlwvGlz36cg8TJTgZ8oKZwr21hdY+GIoq2RK2lECBE4bgoLw6MWQ6b13ogMVR\n",
       "mEMY124GQXHj060uPGrXCC+94kUFd89s9cU05D7cAWuoUke8cPNv19MpJQAKlFcgew+leibX6iAS\n",
       "w5h4EK1XS0fa0J3JHjLiS9HGKyXf6f4rzNlmrgIYpGsT6iwxPfXUE2dNsil8VT7F4rb8fD6+xZCL\n",
       "TJfnVEPjX5nbFEgb5rSwJgwzwATApzwD/mwtHO76TRZKPn9WizlrNO2bxN3CbDJtwhVc7vC+nPK2\n",
       "jIsPB49dZL/QA/MA9s3HT0nr+JWG7r/LE0AXdeXLDpGGCB1IDMd+qKV0YFNo4BirfleJzMOibGZ9\n",
       "JhuwSxX65kwoguSkGmHez77YIx/c0YB0BFtKLxOf2WrPxgBFqaY5/rWK931gFYQ4iMBe9J8oYdmf\n",
       "KORS8OEnjv7n0Uz58Sl0RikskSX8oX5rKU9WxYnfh91xh2JwwtY+truaGDI27+Yx86zsMzWGlf3k\n",
       "b+dm11SrC8k2c73EMja4MA+/LrVzTo1DhQak2L1pGMp00p83THHjVIiJKsAva+L8AHoBZMAJaJEv\n",
       "/aBpDKPt55o/sVmgiuZTUSjENcQN1L9DE/dlSow3LumvRYpPbTrAiTrKnBfmTyOxBTKGnxjLdB8P\n",
       "Mrlgh+dBQYZeUkT5ukIT1mKH00gBB9IVfT1QsS9m5fEPA3dV1/jnOzQ+/vFi34oftM+mS6SOOV3Q\n",
       "BQoyO4vppsNKwRvZFdAgjqyAQfcdLq7sKGCtZxqPY+dUvpfIiK0frj0skpL/RiRLok6+wJnJY4jo\n",
       "qg/8o+0KsD0WZTqXSUQ7z56h/aNTn+VM3FjyjXNBhID9tj+QfPUxvQLnCIWtuW02n4/C/kQpfohb\n",
       "pkgT9pUmgm1IY43RjdwF5OOPnB6ewhmdncOMpLdVl6s9Dq2lRicf8SA1Q2EdmUgQ6gS917Zw9lNM\n",
       "mEA8TvvPtaomS7t8RqmTNg1FfhQAeSfCXii56bw6UE/imBTYUiBIX0+eGXrfxgFQlJsCBGqkBwHn\n",
       "dSfdTdXOktVgsbdJG3zxisrrRnPR07/GzE/dIRDAs3UVFqUfz6VMN+ddR6Zhl0oZ+1VgB/S8SurV\n",
       "FfPnKS0QS6otGqFBqShzT3RkqwDt4oywBsl9pwUQ0+hfktodegLjFvq7YCfd2OFwJ89xSVJ+5WbV\n",
       "vJ6vDuPx6Aj5s9/EZ00IpuebrAOCNYVkg8IWU8BxlVBuTCN5RFEfjXkRbwru11krOzwaVtgeFg3T\n",
       "B+mroO/kOIaOooSHYTUrz1/zT0KIbAzvg/jr8e+1TG+aEAcDXoxm/ad7NSpXby+EW4daG+TgmifR\n",
       "U/Q5rxP4YOpAqsiIaowzoCMIcSlBmMpT1dIYs+28kpnv45jfBISmTSoxIGlZPa8gAqLv9ymf7GEq\n",
       "a4q+EgBnhHY3sHBnYSTo/NbWUkzMYs5foEsp0sUa7IY4h5rrM9lo+6KJRtEwVm9wAf5cOD7s278e\n",
       "pvYfZ7yW2Sv4jv7mG4RcCnAmhzERi/szGaivCKfOzthahmuKdwH/Z7pO+XMae8Ba1Q/qgLNdQzw2\n",
       "zXSlhp6xHZKTO8On75vK9PVM9uQE0eZPk0rMWT/C84bUKEeSwiDW/DF6zghfzvfYjqqtf5T4HOQt\n",
       "EpjX6cYxKOw6mICQ/Crhatq9qaWH0FmDT48PSmNJt0746m/q5KKZUW8/6zOOMFY4I2OSoauEwpTN\n",
       "X5ok4zEk/goHPHXD5FhsRui/vcaFIZnQXBL5rSpJvllv/do00WiFn5aQI4nuJMduaKCc23O7UBA4\n",
       "m1lNbxKDm9jjL1jlygO0B1pHJEMyX4ifFHrqH9LjvFNIur4AXOXypAqR407PYdBCg5ldpthismQX\n",
       "WhVOM46/wPWkq2J5aJKkbAUATp0Oc2zP+sng0Z+y6tY/yEsrFVus/1UUmbOwfqQbC0u4KoZnYh0M\n",
       "uenga5zbGof64nnnUvSDAcueaTTn0Of2baTi4Om+ukS/MxEOTFUMR5OO8wJS0rxky2+dRPvJXDHB\n",
       "pCrLOtP2n1y1JIfnbOOlidWwNmI3tv2MM0yv+oZcoD7HdGTPCpc09bdZ8X/OiGrAWQ4gmGVGL6Qv\n",
       "eVfmj07KqIX44C3uCVRuij1g4NP2Mwlvod4ZXCgx7eeXlwogPdTWVaztlfdnXTWXKNCzeVDsVfNA\n",
       "d/FfAMo5PNIherATrvdSLZai5gmq8dn5MlcANSEAAArUQZqmSeEOiZTAgh/+qlUAtkVvcZuACcld\n",
       "rP1KEtAnt+tgBTZPw1EAWmkRfkD3IUCl5Loy9xOvRYx5J5GMPRGsAuE4qVNuu0YCfXk1LnH4VKO7\n",
       "a7RXszs5Rz8hAF8wV151xWKBLjSAT9qkza+Y8mo7jU8YOHrbBT/9d3f/EGEhIlZEP/e6rFRCcTsR\n",
       "8zOLbmBvYg4vRU1ZaiTGAgEU+Oye4EEwCTvX/OqGebuUdTVPVvUsZTPlbLuc6Xs9Hb1vqu+ESpgo\n",
       "N4PxFjSgxgAe9KZnrc1EjTwl1180L3qFQQamGzNq7gNZPOpD57jhoWrODArV9SzrLVhtWmetsfxg\n",
       "9iiH3RKvLKP6MfrX8hq8kqxbFjJHPZ7noAhsbPuzqaXVv2Bb9bPY4uhy6BHx3F3xoEyZDs6t1btO\n",
       "9MnpBur0bSVAnieRhAzBv3P8PCqLOdloSZe6NMfoetrAZMrQKVTYGohIv/NwvGqfCrSGym2HjBTe\n",
       "zdQjL2SILJBP0Oww/pA1/8FiD2Jui8km0lih+SUlY27pR3eIcHbvAKJQXPhSyjTSsB5JkcaEa6/n\n",
       "M8HKBdPZ/OEPEPg0o6Cs0Nu+7VFB+F0SJ5DBSTik8ZL1E37yYGCqrLgOpBVvIT6N3PbWBoN3wxiO\n",
       "AGqPOH5iPywHvZltM2kIE9wAcHCoHZRSz6jkZGOO7bT0cuI7FHvMxCNFUUpAtAln2UOlQ0zU3i2E\n",
       "Um303ML3Z0OkR9aH7829aMDk51rFr5PWzXdcxPxGAls6PeIrAW49sazKjWgCwJOalvpHDGHrjtR1\n",
       "mg+y10DRtdce4t1cZ4/r1XrgL1qlsNckDgQymYUfqWiRyo8Oz3hegPR/AKOMyHWeKvxoGSevKwLw\n",
       "nFi12Y4RPLm0A2ZRC+gJzGpGPl0A3M6Y8wfsbHO8SNFc4bBN20ulwvdnt1rIvrTDXHAilZ7GKmP1\n",
       "MGAe9nOb2dZ0CMU7y0RxHkxiLrmVxF5EjtUOwLMk7zYFaVXwbZT2ja2zei4K9mPSFGJGAT52GN34\n",
       "T1TZVAOFSkPmlLmrT7w2NyD6b1v/+b3X/vwszDwc3mxe+/OHGuw59zGTv3vpfk08XrnqNwr1PgUz\n",
       "+1gVrqGcZDIGgi7xDHfpp2CM78RJufK5bP0cCHGeodwz/DoonFg2ALRDhOH6MeM4TY+qJsFCEdyy\n",
       "2fqpOttCI+Rj5zcfBOPgXhX918IUyYyoHC6BhFYpRo0DDJtp09t/z/y8yZooxK48MChVaoE2kBQZ\n",
       "7UCYNXjoTmkImFOmKrr2Ogjm+pTJ8QiMb+xVv9VHqcdeE+caH3fGavX+uXKOQOuBtbbzu3e93+Ne\n",
       "AFUPYFw8GQCRqGKXbbERGq3Cn97WjeIJrZjq9vy4UEf8KobpvrN7TzE2e6ymaf1Wh0PYwyBg/szW\n",
       "jcx5+sjKJeRJmmLJZAYZ/ZriETQmyAvocKoMskquIgAOBWEV9v1hETY7DEbbtOv2laIWpnmX7kH+\n",
       "nzG9xISEJSF7Sf/9P/D/S48L4FeOxtgYzSsyzXYrLTVDuvjgxeOMR6kSg7e5bBKOGxz9wXDeaN8k\n",
       "1eX28KzPjb/e/3gj4Il1RoN0sKqLTLCncdcgPrxw7HqlL2QtBulbvFb/UhgmzyUmKDp/PddSBBWy\n",
       "2E+b1nlx1l7pR64wX20TuwOmSSWG8HdN+6uKzGVXBrLzRDAcS59sFYG2iy25Q4eMnGEE4TDwcxhr\n",
       "NOVg4kvivLFR+bWcfxhaaXTTq1BsMlYIya8FjFpzqjbXejsUnxGSiRFrb/Y/wOHieGLfgnER80ZX\n",
       "b1OpPgRfpCD7MaXkVxulqdonv6gd5Z6onFxDE/pDB1cgSBf3XDPmwJbqsGw/Q7n3tmOR2WE7njwS\n",
       "bSwk7qyTklAwHaIWctKFd1ZSarPViV0eCa/mdIuYjnkiSzU2QcLyXHnlyUUpdqy6m+mMfUooDiYD\n",
       "tdARJcN6sjUbGZAHaGpMGbsD50eieJlvmPWNFfXRfEvWklKFSB7/WCHcqTZ9xBBTEK0UKxhfFNTx\n",
       "XRNl0NU8tph84yyzwqF5Ma2tnHu4yMnqnf1xRTJg54KHfUx749vMoW1FTZnHgMjNQHoE/+lO9mvt\n",
       "uZaEK1R0g+OgmKviklV/qcTulZeCm8VRt0Wg9UrDx/+nUXUr7Qzsqh+rnsQ8chvaC/mtwhqxrzKJ\n",
       "gYcq9RKw+MJXJKDQ8CZkNGLfb862EKjq5E8mJjEPoHIZ7gvLvQzV8Pj/Y2chWvA+uzdyFrpuSe8C\n",
       "IdISmwsMx3vQLunDxQ8rPAz+H8THwDiW08ranNnt070Oq/bt7Y/f/YOBHmQHL6lATd8GOezaGqfu\n",
       "OV+X6wRkIBIuoPosm9gJYjydSA1s2+zS/MBmlNa+pPszt8vtabkPyyDAEaeL9UC6Y7xHSPkPp3+a\n",
       "R7cFSJT5Mm0yPojS8ijg+1dCD37xG+Eft6fzM8oPOmm11KqQ+lMFP/WIBqjf2w0p1n3b+iIEY7TB\n",
       "Nr9kIzbuYOuLz3gDhcdsNzcFRkcTIX10C4TdYU4jLyJbVx/buPEAmRLZPe4C5FWG6R/g+Gf4DZ+x\n",
       "Y+z5s9uLiPE2BLftjkVHUqnjBfepP2PZ4HLTnqU7Pj7VE1wQHd2T70g0gzhhDlCYGUf8JxWaLMir\n",
       "h6rEN07/7ASKl9Mi/awyMT5MmT0ePHYVpUN/3r8qF0P9g1PpO1b+8z/mIgT/eThnHceV1bJrCZiK\n",
       "WQRe/R/6JvVJx9f1bsOp2QP7sxYrKEd0sXwgne88lYD1UmWyW0tXxiBA0vgrEL5S2i0+n8/tJntQ\n",
       "ZYCb/3npfSPJPVY6B2rt3GZn0h3CGcMu/iwRqVPXQHhVkJ02nUq6Xm+RkzcKnZUZ2PuQifEDYvCd\n",
       "cUoPutjmv/kHKiyPTtbc5Rd0aBbsBDp17D9VBrRbiyuTV2LpaCa3t0hzsBDpM370xQ7x8I21V/+G\n",
       "iYZ2/T1hj+PgCkcDU3LQe50cCdE4sYpLFDkXZRaCdDg018V5U9UGnjioRcg13zl49n0F6V9FDnIQ\n",
       "NyT6JkTugKZoDKs7JhKvaGlHTM6OzsudBBUfbnd3POmYA9GKX1c5GSPMf69QFcntBbeLhy2uge+6\n",
       "otXvz6DLMVPmfAcloGjLAvmgxzHSMsiWTgb3da8XEYictvGt3pi21Bs0DzlbP5X/1FrWv4Z+cgD9\n",
       "PQRL5Zs6x+jHKdPVfbALHCE7/YdofopzeRGUFfrkboYLlvgj/3Q7D01eupSqS2FYuJlUmo6onBDm\n",
       "BGEKKLK07Vp7wpT5spFJ8fc0HeKW791K4PAg84mObLvbhGY8JNULBN3FJWsrufNggIgp7lSePYxM\n",
       "DMe9Z7CgBb/e7/FPB956ah+eCPW+Zq+PGFKSU0UFxymDlZArxCU5ZZQ3kWEwoWSv8NJQDUR4E4Xk\n",
       "QZZbK9xuFvicGVDU6OF3AQLahzwdK8dYSIl1IMGRP4xf52H9P4PAtF0is3SKObKIh2FlxHT+SKia\n",
       "mcYhXswEZYtBUxwbWfAM/Sezzl0xZ9EHs79p/wjI91lq4nOwM2K+68uYIT8YUOLyirbxShlaZTjB\n",
       "FXqQYVP0lKXzA0839hqdIcoFkg7r8JybYQp5AO1O2zBpUfvzq0+euvZQUw3C+Xqab1GknVKhzSF9\n",
       "bdB4a4U1lpqNc1FUqV3kGUcAh4rEiIAqHimhvPSfA87UqnNGbt2uC1s2ikgwH542WtXKD+ny9qF/\n",
       "e3/Wpusdg2GsNCIPAAADvUGax0nhDyZTAgh//qpVALR9YNwz/NwAXHG7/+EI1gNzSWP+LPFcdAAZ\n",
       "ts539wfn4b+nvgxTXqg4aUrO6RxMG8+5XbNbURQapydPTYWMZ5S2V2CMU5yui6KUBGFO9x96T2wX\n",
       "N1g9YJNY5yZuEx5kQ10A0BxC9OFZcFOs5fqz0v41OEnWMrUF772VjyohcQw7j/CyQQfBo27+D+dZ\n",
       "jetWjlHl1qju/UUdet6YGntORFIEzBTGqaLlahD+LrOEIsijjd2F+jFOWNUfBcMP7fXMVmUK+jmZ\n",
       "dCKIbJjpyAoI3FU6BQZ1nIgxColCAqN2ZRlQnqc+bm/pUJluWfQZyWWzHzRm6c/lgzqZ6dG+hzmJ\n",
       "p56m9RXTIPPKF3eSDgEOJw4k3SylVUR9OaS5UMseUak5nV81zz1tzXFTA8BQ1/IUu9WWlGJ+I1H8\n",
       "dRmveTHYV7PZSvO3WxiezokpSm88Ew52BgBB/0104mNpIEc7rRpFPBzMcxumqWSY8iOtmBoia8K8\n",
       "JLci0pZ2YZVDGejoqvK3wOPz5oh04HRp4elY7k+a8kWuPiEHkudCkaxT4DyiWr4bC5B2MQ3ube0R\n",
       "S6+KV6fJ3K3ib1rk1K/E1NihN3qe/Cpw/qfaOc4ueNMIgQB/Jvhppxk/xmzutAd08XXa65W84srX\n",
       "0jnMw6M60/wk+2qdJraH654ZweQwM5+DLVH4qPnZq4SGpp3EHN61HqiEaAaC2np3r7mvuiEz01RS\n",
       "H9Q/DB4Zjg0rl6OVNRUZ00mtBKN8OJtZPoJ1tj4hoSJw2FF68ENi3EGr1yLTIRa3C+Fv33P0etGQ\n",
       "e/ydQOeurt90ZJj+shhJBlZIV5vq/ad+YoTz+AUZTNQUzmgKnnt+kuj/h7XQcYR06EGaZwsvItZD\n",
       "iM+G/dGjNLocDpT1TV+QjIJG1L1Qc2g75Mmt/OpdM/PGBtnzyEUUWEao+Rbd4F4SRd+9SU6LhQyR\n",
       "upXCVrrtt7h/PdwdL4NqQMLXv7CHFQQpB9ju2cbvm1iVBt5FODBwXWqERNtUchH6H4+N4hn9Z3Ti\n",
       "rLsNVXHYlI+J9wEL4HDp2u9PrliUBJLhmEvslIenBOG9ShcDNHDGYlPH75ZDvRu659uvFY22VLga\n",
       "iJNfLzqD/XIgX/WHxPe1nBBKt1fjwLVS2Wp/7Qivn9DH+rRyyIts3lRrTNbwVkfS7MmXwpPPyIdj\n",
       "99I4pdjRZKTyNPDgFgsg6ip6jlLdo5Cm4yQGxbMklcsUtjHSv1TlHv0zZU/6eYn5MWqY9j1SRGCe\n",
       "7D0GjQAAAoVBmuhJ4Q8mUwIJf/61KoBa+tfVq2ACHVT5wx6p6LGyBsYxvP3T5MrxFmlmr4P7VpVH\n",
       "EIygnsh4FgczA2dIaG2wk8Qxos/5mhcxuVBJifc9gt/xko7b71X2gpuwsjT0+JVl+I6DWD9j7VF8\n",
       "KCKDwL3+Iw7ALY/6VrFyYwl/ikO752yZzeJwR0Lirne5S06wZ+mTa4IQw64B/w4h4ee2NHbdmB4I\n",
       "2qmgJZFfHuabVi+1x7t2Az5WcmRq29MFobX8vZ9RVEfaaDIdPwk2lZ39jZGLCXpofWDaQa5Ng7ZY\n",
       "HVWxExTzGwLJGHy1pDZNu1eo9KU2KLmLUskKRTJIou5r2b23BjywVYUOpkge/tB2GCvz1Rm4ccmg\n",
       "Zjv6l0hVDiM8GcBCkoHAxlB1c6jTDauXFrJ6dI8km7p8Rs059yVNYZCG1j1A11tM9hxT8Nl3EutL\n",
       "wUIiPec94uaHzkIPoKyz5rPkUFfi5vesO4J2xubm33nrCC1osQh+fdPmHCfRLUm8BR5FB6DrBctx\n",
       "Qb9b2zaru5YcnqObn8BbObSUFReunTlPVC2gq2fT3jXUVR+eCO6breFvDUBN1fsFXbiwBk06ZM6o\n",
       "chs5hqFJRaZZFnGV4/nlnhdjYevAC4cYeOCFuPNONryBHB/WZ65Iz20RWIpjJKV4dIh2UoT8rY5J\n",
       "VlNwyKze05suD1bLCBoDgqJLDRxgFgJABPrf2Lgv7KiJzPt3vL8bupP2Z1J8zKanLHBR3/j7j1GN\n",
       "raiBQN0lJo+yAqAtLJ6W66XgDXxNxtkoeyoERXweRHj427NxNkeUZjDC1hziZZdSlVurhoxAkl7e\n",
       "XKZNRheVVFPdS+anpWuVB4cTzU7mAXIuCygAAAIYQZsKSeEPJlMFETwQ//6qVQJWkIQSf018ukxv\n",
       "SVf96QAC9Q5bcr3AkaUGqByBbMuEwB/pngcHIA6ZF0QD6S5Mw8RGePg0LtaxEPS1cWRJYCB2hdjm\n",
       "uF1W858scFziL1v0zLg5PsiLS2PkE1t7tk0GDzQ/uZeRBpe2IGBy+ZO43sJcb37YxpIn3cfjYvdU\n",
       "HeC6iusMz9V+L+nRfPOjLx0KcsA11yRetPKnnI08cWXwLxUmRBbU6XcNlMBQu8VywuX17kixLVNS\n",
       "ZuUaDkr79TAJvSgMkDYB6/707vLUf2KOjcaY+euFezCIm6sJnvYMPc4QfCfTdNQ0btg0DMq8pcAf\n",
       "FxsIl+yqQU/mb96vUDSncx7jfFSPTIEVQBpB1cJMAwpT3VVROgGudHNywMD1MuliBHykQX2N3Kcn\n",
       "np+i829fpF7h6ding3NK+atAMCP5u7XG91kUzodgDQCpxCZ7VhzaEBEyoTzSk85oBg1Qxe5vv7y/\n",
       "Ns+C6/PRxUkOvkEB/JkXmSuxmc3S8aabkCruJA1Mix3AE4MOCEsh4kUlFmHcyj3iR9PGW7047t5k\n",
       "jVF8h5vPCY4c1oKqqW6WyxHPGk3XXbRZMnX/X+radtqLVdIRbsnfcfEAliusp9MktcOmNtigq3de\n",
       "dYUJibo1YrtZUPPcFogIwiqG47a2fI+rinKK8trWc5rj/uws5n3Urr825/MNrzJhxcQAYUAAAAEE\n",
       "AZ8pakEPAFafNJB9EABfXy4AN0Ph1r8SUhUJD7IdkfD4igHFB17hylbpnUDdVdFxpx1STjYAolmw\n",
       "+Y7v5KujMnz3k6HozfT1/La5SBkfZwO9EmnDLL1rQpWNz47rLQZmtq5OksDXJwM/ku4bKSZHgY12\n",
       "D21rn6azVXi/fYfZ/FiDqtz3ACivEx757lwUzt8G6PDX5frE0ZEqnamJJl52kcYtVR+weWZTUYtG\n",
       "2fuDDS/oRV0ZeRNKexzeIfBQxLyuWADpKrTiIl0g12VmFuK2dN83Emgy/Fnzqa2NIoqLH9ArvZBE\n",
       "Vrgm5mAh2+k6ykV21wZ8HOfBZUkBsvI3vHnoOvPA3oEAAAOLbW9vdgAAAGxtdmhkAAAAAAAAAAAA\n",
       "AAAAAAAD6AAACr4AAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAA\n",
       "AABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAArV0cmFrAAAAXHRraGQAAAADAAAA\n",
       "AAAAAAAAAAABAAAAAAAACr4AAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAA\n",
       "AAAAAAAAAABAAAAABRAAAAGwAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAAq+AAAgAAABAAAA\n",
       "AAItbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAABAAAAAsABVxAAAAAAALWhkbHIAAAAAAAAAAHZp\n",
       "ZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAB2G1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAA\n",
       "ACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAZhzdGJsAAAAtHN0c2QAAAAAAAAA\n",
       "AQAAAKRhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAABRABsABIAAAASAAAAAAAAAABAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMmF2Y0MBZAAf/+EAGWdkAB+s2UBRDehA\n",
       "AAADAEAAAAMCA8YMZYABAAZo6+PLIsAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0\n",
       "dHMAAAAAAAAAAQAAAAsAABAAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAABAY3R0cwAAAAAAAAAGAAAA\n",
       "AQAAIAAAAAABAABAAAAAAAIAABAAAAAABQAAIAAAAAABAAAwAAAAAAEAABAAAAAAHHN0c2MAAAAA\n",
       "AAAAAQAAAAEAAAALAAAAAQAAAEBzdHN6AAAAAAAAAAAAAAALAABNWwAAHFsAAB17AAAYRgAAC9cA\n",
       "AAfgAAAK2AAAA8EAAAKJAAACHAAAAQgAAAAUc3RjbwAAAAAAAAABAAAALAAAAGJ1ZHRhAAAAWm1l\n",
       "dGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAA\n",
       "AB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#Make animation of fitting process\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython import display\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "#fig.set_dpi(100)\n",
    "fig.set_size_inches(18, 6)\n",
    "plt.suptitle(\"Sample-baseb Fit\")\n",
    "\n",
    "skip_N = 10\n",
    "def update(frame):\n",
    "    mmd_fit_grammar.load_state_dict(mmd_fit.grammar_iters[frame])\n",
    "    for ax in axs:\n",
    "        ax.cla()\n",
    "    make_figure_for_grammar(mmd_fit_grammar, axs, N=10)\n",
    "    plt.suptitle(\"Sample-based fit, iter %02d\" % frame)\n",
    "    for ax in axs:\n",
    "        ax.set_xlim([-8, 8.])\n",
    "        ax.set_ylim([0., 0.7])\n",
    "ani = FuncAnimation(fig, update, frames=range(0, len(mmd_fit.grammar_iters), skip_N), blit=False, interval=250.)\n",
    "video = ani.to_html5_video()\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()                   # avoid plotting a spare static plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "py36_pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
