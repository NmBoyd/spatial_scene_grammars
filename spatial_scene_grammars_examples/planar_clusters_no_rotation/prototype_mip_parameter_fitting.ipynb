{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using one big MIP to do parameter fitting\n",
    "\n",
    "Given a dataset of observed object sets drawn from the grammar, with the constraint that the grammar uses a subset of the rules that admit convex formulations of the log joint probability in both the continuous variables and the parameters, create a big MIP that optimizes the grammar parameters and parses for each scene simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.visualization import *\n",
    "from spatial_scene_grammars_examples.planar_clusters_no_rotation.grammar import *\n",
    "from spatial_scene_grammars.parsing import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "\n",
    "import meshcat\n",
    "import meshcat.geometry as meshcat_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n",
      "Meshcat url:  http://127.0.0.1:7000/static/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "    <iframe src=\"http://127.0.0.1:7000/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'vis' not in globals():\n",
    "    vis = meshcat.Visualizer()\n",
    "\n",
    "base_url = \"http://127.0.0.1\"\n",
    "meshcat_url = base_url + \":\" + vis.url().split(\":\")[-1]\n",
    "print(\"Meshcat url: \", meshcat_url)\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "    <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
    "    <iframe src=\"{url}\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
    "</div>\n",
    "\"\"\".format(url=meshcat_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 scenes.\n"
     ]
    }
   ],
   "source": [
    "# Sample a dataset of scenes from the default grammar params.\n",
    "# Draw a random sample from the grammar and visualize it.\n",
    "# (Cache output.)\n",
    "torch.random.manual_seed(2)\n",
    "N_samples = 10\n",
    "RESAMPLE = True\n",
    "scenes_file = \"sampled_scenes_%d.dat\" % N_samples\n",
    "\n",
    "ground_truth_grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4)\n",
    ")\n",
    "\n",
    "if not os.path.exists(scenes_file) or RESAMPLE:\n",
    "    samples = []\n",
    "    for k in range(N_samples):\n",
    "        tree = ground_truth_grammar.sample_tree(detach=True)\n",
    "        observed_nodes = tree.get_observed_nodes()\n",
    "        samples.append((tree, observed_nodes))\n",
    "\n",
    "    with open(scenes_file, \"wb\") as f:\n",
    "        pickle.dump(samples, f)\n",
    "\n",
    "with open(scenes_file, \"rb\") as f:\n",
    "    samples = pickle.load(f)\n",
    "print(\"Loaded %d scenes.\" % len(samples))\n",
    "observed_node_sets = [x[1] for x in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup time:  104.38579440116882\n",
      "Num vars:  101390\n",
      "Num constraints:  352739\n"
     ]
    }
   ],
   "source": [
    "import pydrake\n",
    "from pydrake.all import (\n",
    "    CommonSolverOption,\n",
    "    MathematicalProgram,\n",
    "    MakeSolver,\n",
    "    MixedIntegerBranchAndBound,\n",
    "    RigidTransform,\n",
    "    RollPitchYaw,\n",
    "    RotationMatrix,\n",
    "    GurobiSolver,\n",
    "    SnoptSolver,\n",
    "    OsqpSolver,\n",
    "    Solve,\n",
    "    SolverOptions,\n",
    "    SolutionResult,\n",
    "    VPolytope,\n",
    "    MixedIntegerRotationConstraintGenerator,\n",
    "    IntervalBinning,\n",
    "    Variable\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize a grammar with random parameter guesses\n",
    "# (which will be thrown out).\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Desk,\n",
    "    root_node_tf = torch.eye(4),\n",
    "    sample_params_from_prior=True\n",
    ")\n",
    "\n",
    "\n",
    "GrammarInferenceResults = namedtuple(\n",
    "    \"GrammarInferenceResults\",\n",
    "    [\"solver\", \"optim_result\", \"grammar\", \"all_supertrees\", \"observed_node_sets\"]\n",
    ")\n",
    "def fit_grammar_params_to_observed_nodes(grammar, observed_node_sets, verbose=False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Setup fit of grammar parameters + parse of each tree.\n",
    "    prog = MathematicalProgram()    \n",
    "    grammar = prepare_grammar_for_mip_parsing(prog, grammar, optimize_parameters=True)\n",
    "    all_trees = []\n",
    "    all_obs = []\n",
    "    for observed_nodes in observed_node_sets:\n",
    "        tree, obs = add_mle_tree_parsing_to_prog(\n",
    "            prog, grammar, observed_nodes, verbose=False\n",
    "        )\n",
    "        all_trees.append(tree)\n",
    "        all_obs.append(obs)\n",
    "\n",
    "    setup_time = time.time()\n",
    "    if verbose:\n",
    "        print(\"Setup time: \", setup_time - start_time)\n",
    "        print(\"Num vars: \", prog.num_vars())\n",
    "        print(\"Num constraints: \", sum([c.evaluator().num_constraints() for c in prog.GetAllConstraints()]))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    solver = GurobiSolver()\n",
    "    options = SolverOptions()\n",
    "    logfile = \"/tmp/gurobi.log\"\n",
    "    os.system(\"rm %s\" % logfile)\n",
    "    options.SetOption(solver.id(), \"LogFile\", logfile)\n",
    "    gap = 0.05\n",
    "    options.SetOption(solver.id(), \"MIPGap\", gap)\n",
    "    logging.info(\"MIP gap set to %d\\%\", gap*100.)\n",
    "    result = solver.Solve(prog, None, options)\n",
    "    if verbose:\n",
    "        print(\"Optimization success?: \", result.is_success())\n",
    "        print(\"Logfile: \")\n",
    "        with open(logfile) as f:\n",
    "            print(f.read())\n",
    "\n",
    "    solve_time = time.time() \n",
    "    if verbose:\n",
    "            print(\"Solve time: \", solve_time-setup_time)\n",
    "            print(\"Total time: \", solve_time - start_time)\n",
    "\n",
    "    # If successful, go fill the grammar ConstrainedParameter values back in.\n",
    "    if result.is_success():\n",
    "        logging.info(\"TODO: Node parameters\")\n",
    "        for node_type in grammar.all_types:\n",
    "            for ((xyz_params, rot_params), (fit_xyz_params, fit_rot_params)) in zip(\n",
    "                    grammar.rule_params_by_node_type[node_type.__name__],\n",
    "                    grammar.rule_params_by_node_type_optim[node_type.__name__]):\n",
    "                for key in xyz_params.keys():\n",
    "                    xyz_params[key].set(torch.tensor(result.GetSolution(fit_xyz_params[key])))\n",
    "                for key in rot_params.keys():\n",
    "                    rot_params[key].set(torch.tensor(result.GetSolution(fit_rot_params[key])))\n",
    "                \n",
    "    else:\n",
    "        logging.warn(\"Parameter fitting optimization failed; grammar params left alone.\")\n",
    "        \n",
    "        \n",
    "    return GrammarInferenceResults(solver, result, grammar, all_trees, all_obs)\n",
    "    \n",
    "results = fit_grammar_params_to_observed_nodes(grammar, observed_node_sets, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare solved-out grammar params to original grammar params\n",
    "fit_params = {key: value for key, value in results.grammar.named_parameters()}\n",
    "def print_compare(name, orig, fit):\n",
    "    print(name + \":\")\n",
    "    print(\"\\t Orig: %s\" % orig().detach().numpy())\n",
    "    print(\"\\t Fit:  %s\" % fit().detach().numpy())\n",
    "    \n",
    "for node_type in ground_truth_grammar.all_types:\n",
    "    for (k, ((xyz_params, rot_params), (fit_xyz_params, fit_rot_params))) in enumerate(zip(\n",
    "            ground_truth_grammar.rule_params_by_node_type[node_type.__name__],\n",
    "            grammar.rule_params_by_node_type[node_type.__name__])):\n",
    "        prefix = \"%s:%d:\" % (node_type.__name__, k)\n",
    "        for key in xyz_params.keys():\n",
    "            print_compare(prefix + key, xyz_params[key], fit_xyz_params[key])\n",
    "        for key in rot_params.keys():\n",
    "            print_compare(prefix + key, rot_params[key], rot_xyz_params[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "py36_pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
