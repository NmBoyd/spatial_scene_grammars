{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2    \n",
    "# Autoreload isn't working for the ssg stuff,\n",
    "# unclear why, I think it has too many layers of imports.\n",
    "\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from functools import reduce \n",
    "import operator\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "import pydrake\n",
    "import tensorflow\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pytorch_lightning as pl\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoname import scope\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.sampling import *\n",
    "from spatial_scene_grammars.torch_utils import *\n",
    "from spatial_scene_grammars.neural_grammar_proposal import *\n",
    "\n",
    "from spatial_scene_grammars_examples.planar_box_stacks_complex.grammar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from pregen_dataset_train_10000.torch\n",
      "Loading dataset from pregen_dataset_val_300.torch\n",
      "Sampled 300 envs in 0.000546 secs = 549712.188729/sec\n"
     ]
    }
   ],
   "source": [
    "root_inst_dict = {\"xy\": dist.Normal(torch.tensor([0., 0.]), torch.tensor([0.001, 0.001]))}\n",
    "grammar = SceneGrammar(Ground, root_inst_dict)\n",
    "\n",
    "class RegeneratingObservedEnvDataset(Dataset):\n",
    "    def __init__(self, grammar, project=True):\n",
    "        super().__init__()\n",
    "        # Detach the grammar, as we don't need any gradients.\n",
    "        # TODO: make this a grammar func\n",
    "        self.grammar = deepcopy(grammar)\n",
    "        self.project = project\n",
    "        for k, v in self.grammar.default_params.items():\n",
    "            v.set_unconstrained(v.get_unconstrained_value().detach())\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        success = False\n",
    "        if self.project is True:\n",
    "            constraints = [NonpenetrationConstraint(0.001)]\n",
    "        else:\n",
    "            constraints = []\n",
    "        while not success:\n",
    "            scene_trees, success = sample_tree_from_grammar_with_constraints(\n",
    "                self.grammar,\n",
    "                constraints=constraints,\n",
    "                max_num_attempts=1000,\n",
    "                backend=\"rejection\",#\"metropolis_procedural_modeling\",\n",
    "            )\n",
    "        return scene_trees[0], [n for n in scene_trees[0].nodes if isinstance(n, TerminalNode)]\n",
    "\n",
    "class PregeneratedObservedEnvDataset(Dataset):\n",
    "    def __init__(self, grammar, project=True, N=100):\n",
    "        super().__init__()\n",
    "        # Detach the grammar, as we don't need any gradients.\n",
    "        # TODO: make this a grammar func\n",
    "        self.N = N\n",
    "        self.project = project\n",
    "        self.grammar = deepcopy(grammar)\n",
    "        for k, v in self.grammar.default_params.items():\n",
    "            v.set_unconstrained(v.get_unconstrained_value().detach())\n",
    "        self.scene_trees = []\n",
    "        self.observed_nodes = []\n",
    "        for k in range(self.N):\n",
    "            tree, nodes = self.make_env()\n",
    "            self.scene_trees.append(tree)\n",
    "            self.observed_nodes.append(nodes)\n",
    "            \n",
    "    def make_env(self):\n",
    "        success = False\n",
    "        if self.project is True:\n",
    "            constraints = [NonpenetrationConstraint(0.001)]\n",
    "        else:\n",
    "            constraints = []\n",
    "        while not success:\n",
    "            scene_trees, success = sample_tree_from_grammar_with_constraints(\n",
    "                self.grammar,\n",
    "                constraints=constraints,\n",
    "                max_num_attempts=1000,\n",
    "                backend=\"rejection\",#\"metropolis_procedural_modeling\",\n",
    "            )\n",
    "        return scene_trees[0], [n for n in scene_trees[0].nodes if isinstance(n, TerminalNode)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.scene_trees[idx], self.observed_nodes[idx]\n",
    "        \n",
    "dynamic_dataset = RegeneratingObservedEnvDataset(grammar, project=True)\n",
    "\n",
    "def load_pregen_dataset(N, prefix):\n",
    "    # Pregenerated dataset: pregen once, save out.\n",
    "    dataset_path = \"pregen_dataset_%s_%d.torch\" % (prefix, N)\n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(\"Generating dataset %s...\" % (dataset_path))\n",
    "        dataset = PregeneratedObservedEnvDataset(grammar, project=True, N=N)\n",
    "        torch.save(dataset, dataset_path)\n",
    "        print(\"Saved dataset to %s\" % dataset_path)\n",
    "    else:\n",
    "        print(\"Loading dataset from %s\" % dataset_path)\n",
    "        dataset = torch.load(dataset_path)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = load_pregen_dataset(10000, \"train\")\n",
    "val_dataset = load_pregen_dataset(300, \"val\")\n",
    "\n",
    "def collate_fn(x):\n",
    "    return list(y[0] for y in x), list(y[1] for y in x)\n",
    "train_data_loader = DataLoader(train_dataset, num_workers=0, collate_fn=collate_fn, batch_size=300)\n",
    "val_data_loader = DataLoader(val_dataset, num_workers=0, collate_fn=collate_fn, batch_size=300)\n",
    "dynamic_data_loader = DataLoader(dynamic_dataset, num_workers=0, collate_fn=collate_fn, batch_size=300)\n",
    "start_time = time.time()\n",
    "observed_trees_for_test, observed_nodes_for_test = [list(x) for x in iter(train_data_loader).next()]\n",
    "elapsed = time.time() - start_time\n",
    "print(\"Sampled %d envs in %f secs = %f/sec\" % (\n",
    "    len(observed_trees_for_test), elapsed, len(observed_trees_for_test)/elapsed)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start vec:  tensor([0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Stop vec:  tensor([0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "X shape:  torch.Size([300, 10, 8])\n",
      "Z shape:  torch.Size([300, 192])\n",
      "X recon shape:  torch.Size([300, 10, 8])\n",
      "Out of range entry at 1, 1\n",
      "Out of range entry at 1, 2\n",
      "Out of range entry at 1, 3\n",
      "Out of range entry at 1, 4\n",
      "Out of range entry at 1, 5\n",
      "Out of range entry at 1, 7\n",
      "Out of range entry at 1, 8\n",
      "Out of range entry at 1, 9\n",
      "Out of range entry at 2, 0\n",
      "Out of range entry at 2, 1\n",
      "Out of range entry at 2, 4\n",
      "Out of range entry at 2, 6\n",
      "Out of range entry at 2, 7\n",
      "Out of range entry at 2, 8\n",
      "Out of range entry at 2, 9\n",
      "Out of range entry at 3, 0\n",
      "Out of range entry at 3, 2\n",
      "Out of range entry at 3, 3\n",
      "Out of range entry at 3, 4\n",
      "Out of range entry at 3, 5\n",
      "Out of range entry at 3, 6\n",
      "Out of range entry at 4, 1\n",
      "Out of range entry at 4, 3\n",
      "Out of range entry at 4, 4\n",
      "Out of range entry at 4, 5\n",
      "Out of range entry at 4, 9\n",
      "Out of range entry at 5, 0\n",
      "Out of range entry at 5, 3\n",
      "Out of range entry at 5, 4\n",
      "Out of range entry at 5, 6\n",
      "Out of range entry at 5, 8\n",
      "Out of range entry at 6, 4\n",
      "Out of range entry at 6, 8\n",
      "Out of range entry at 6, 9\n",
      "Out of range entry at 7, 5\n",
      "Out of range entry at 8, 1\n",
      "Out of range entry at 8, 3\n",
      "Out of range entry at 8, 5\n",
      "Out of range entry at 8, 6\n",
      "Out of range entry at 9, 5\n",
      "Out of range entry at 9, 6\n",
      "Out of range entry at 9, 8\n",
      "Out of range entry at 10, 0\n",
      "Out of range entry at 10, 6\n",
      "Out of range entry at 10, 7\n",
      "Out of range entry at 10, 8\n",
      "Out of range entry at 11, 8\n",
      "Out of range entry at 12, 0\n",
      "Out of range entry at 12, 1\n",
      "Out of range entry at 12, 8\n",
      "Out of range entry at 13, 1\n",
      "Out of range entry at 13, 4\n",
      "Out of range entry at 13, 5\n",
      "Out of range entry at 13, 6\n",
      "Out of range entry at 14, 0\n",
      "Out of range entry at 14, 2\n",
      "Out of range entry at 14, 5\n",
      "Out of range entry at 14, 6\n",
      "Out of range entry at 15, 3\n",
      "Out of range entry at 15, 4\n",
      "Out of range entry at 15, 7\n",
      "Out of range entry at 15, 8\n",
      "Out of range entry at 16, 5\n",
      "Out of range entry at 16, 6\n",
      "Out of range entry at 16, 7\n",
      "Out of range entry at 17, 0\n",
      "Out of range entry at 17, 1\n",
      "Out of range entry at 17, 2\n",
      "Out of range entry at 17, 6\n",
      "Out of range entry at 17, 8\n",
      "Out of range entry at 18, 2\n",
      "Out of range entry at 18, 5\n",
      "Out of range entry at 18, 7\n",
      "Out of range entry at 18, 8\n",
      "Out of range entry at 19, 6\n",
      "Out of range entry at 20, 2\n",
      "Out of range entry at 21, 0\n",
      "Out of range entry at 21, 9\n",
      "Out of range entry at 22, 0\n",
      "Out of range entry at 22, 1\n",
      "Out of range entry at 22, 3\n",
      "Out of range entry at 22, 4\n",
      "Out of range entry at 22, 5\n",
      "Out of range entry at 22, 8\n",
      "Out of range entry at 23, 1\n",
      "Out of range entry at 23, 3\n",
      "Out of range entry at 23, 7\n",
      "Out of range entry at 24, 5\n",
      "Out of range entry at 24, 6\n",
      "Out of range entry at 24, 7\n",
      "Out of range entry at 24, 8\n",
      "Out of range entry at 25, 0\n",
      "Out of range entry at 25, 9\n",
      "Out of range entry at 26, 2\n",
      "Out of range entry at 26, 8\n",
      "Out of range entry at 27, 4\n",
      "Out of range entry at 28, 4\n",
      "Out of range entry at 28, 5\n",
      "Out of range entry at 28, 6\n",
      "Out of range entry at 28, 8\n",
      "Out of range entry at 29, 0\n",
      "Out of range entry at 29, 3\n",
      "Out of range entry at 29, 9\n",
      "Out of range entry at 30, 0\n",
      "Out of range entry at 31, 0\n",
      "Out of range entry at 31, 4\n",
      "Out of range entry at 32, 1\n",
      "Out of range entry at 32, 2\n",
      "Out of range entry at 32, 3\n",
      "Out of range entry at 32, 6\n",
      "Out of range entry at 32, 9\n",
      "Out of range entry at 33, 1\n",
      "Out of range entry at 33, 7\n",
      "Out of range entry at 34, 2\n",
      "Out of range entry at 34, 3\n",
      "Out of range entry at 34, 5\n",
      "Out of range entry at 34, 7\n",
      "Out of range entry at 34, 8\n",
      "Out of range entry at 35, 0\n",
      "Out of range entry at 35, 2\n",
      "Out of range entry at 35, 5\n",
      "Out of range entry at 35, 8\n",
      "Out of range entry at 36, 0\n",
      "Out of range entry at 36, 3\n",
      "Out of range entry at 36, 5\n",
      "Out of range entry at 37, 2\n",
      "Out of range entry at 37, 5\n",
      "Out of range entry at 37, 6\n",
      "Out of range entry at 37, 7\n",
      "Out of range entry at 37, 8\n",
      "Out of range entry at 38, 2\n",
      "Out of range entry at 38, 8\n",
      "Out of range entry at 39, 0\n",
      "Out of range entry at 39, 2\n",
      "Out of range entry at 39, 7\n",
      "Out of range entry at 39, 8\n",
      "Out of range entry at 40, 4\n",
      "Out of range entry at 40, 5\n",
      "Out of range entry at 41, 0\n",
      "Out of range entry at 41, 1\n",
      "Out of range entry at 41, 4\n",
      "Out of range entry at 41, 9\n",
      "Out of range entry at 42, 1\n",
      "Out of range entry at 42, 3\n",
      "Out of range entry at 42, 4\n",
      "Out of range entry at 43, 1\n",
      "Out of range entry at 43, 6\n",
      "Out of range entry at 43, 8\n",
      "Out of range entry at 43, 9\n",
      "Out of range entry at 44, 2\n",
      "Out of range entry at 44, 4\n",
      "Out of range entry at 44, 7\n",
      "Out of range entry at 45, 1\n",
      "Out of range entry at 45, 9\n",
      "Out of range entry at 46, 2\n",
      "Out of range entry at 47, 2\n",
      "Out of range entry at 47, 4\n",
      "Out of range entry at 47, 9\n",
      "Out of range entry at 48, 1\n",
      "Out of range entry at 48, 7\n",
      "Out of range entry at 48, 9\n",
      "Out of range entry at 49, 7\n",
      "Out of range entry at 49, 9\n",
      "Out of range entry at 50, 1\n",
      "Out of range entry at 50, 4\n",
      "Out of range entry at 50, 8\n",
      "Out of range entry at 51, 0\n",
      "Out of range entry at 51, 3\n",
      "Out of range entry at 51, 6\n",
      "Out of range entry at 52, 0\n",
      "Out of range entry at 52, 4\n",
      "Out of range entry at 52, 6\n",
      "Out of range entry at 53, 3\n",
      "Out of range entry at 53, 4\n",
      "Out of range entry at 53, 7\n",
      "Out of range entry at 53, 9\n",
      "Out of range entry at 54, 0\n",
      "Out of range entry at 54, 6\n",
      "Out of range entry at 54, 9\n",
      "Out of range entry at 55, 2\n",
      "Out of range entry at 55, 9\n",
      "Out of range entry at 56, 1\n",
      "Out of range entry at 56, 2\n",
      "Out of range entry at 56, 5\n",
      "Out of range entry at 56, 6\n",
      "Out of range entry at 56, 7\n",
      "Out of range entry at 57, 0\n",
      "Out of range entry at 57, 3\n",
      "Out of range entry at 57, 4\n",
      "Out of range entry at 58, 2\n",
      "Out of range entry at 58, 4\n",
      "Out of range entry at 58, 5\n",
      "Out of range entry at 58, 8\n",
      "Out of range entry at 58, 9\n",
      "Out of range entry at 59, 1\n",
      "Out of range entry at 59, 2\n",
      "Out of range entry at 59, 6\n",
      "Out of range entry at 59, 8\n",
      "Out of range entry at 60, 0\n",
      "Out of range entry at 60, 6\n",
      "Out of range entry at 60, 8\n",
      "Out of range entry at 61, 0\n",
      "Out of range entry at 61, 1\n",
      "Out of range entry at 61, 2\n",
      "Out of range entry at 61, 4\n",
      "Out of range entry at 61, 7\n",
      "Out of range entry at 61, 9\n",
      "Out of range entry at 62, 5\n",
      "Out of range entry at 62, 7\n",
      "Out of range entry at 62, 9\n",
      "Out of range entry at 63, 0\n",
      "Out of range entry at 63, 3\n",
      "Out of range entry at 64, 0\n",
      "Out of range entry at 64, 1\n",
      "Out of range entry at 64, 4\n",
      "Out of range entry at 64, 6\n",
      "Out of range entry at 64, 7\n",
      "Out of range entry at 65, 4\n",
      "Out of range entry at 65, 6\n",
      "Out of range entry at 65, 8\n",
      "Out of range entry at 66, 3\n",
      "Out of range entry at 66, 4\n",
      "Out of range entry at 66, 6\n",
      "Out of range entry at 66, 7\n",
      "Out of range entry at 66, 9\n",
      "Out of range entry at 67, 4\n",
      "Out of range entry at 67, 7\n",
      "Out of range entry at 68, 1\n",
      "Out of range entry at 68, 2\n",
      "Out of range entry at 68, 4\n",
      "Out of range entry at 68, 8\n",
      "Out of range entry at 68, 9\n",
      "Out of range entry at 69, 5\n",
      "Out of range entry at 69, 6\n",
      "Out of range entry at 70, 0\n",
      "Out of range entry at 70, 5\n",
      "Out of range entry at 70, 7\n",
      "Out of range entry at 71, 5\n",
      "Out of range entry at 71, 8\n",
      "Out of range entry at 71, 9\n",
      "Out of range entry at 72, 4\n",
      "Out of range entry at 72, 6\n",
      "Out of range entry at 72, 8\n",
      "Out of range entry at 73, 5\n",
      "Out of range entry at 73, 7\n",
      "Out of range entry at 73, 9\n",
      "Out of range entry at 74, 4\n",
      "Out of range entry at 74, 7\n",
      "Out of range entry at 75, 1\n",
      "Out of range entry at 75, 6\n",
      "Out of range entry at 75, 7\n",
      "Out of range entry at 75, 8\n",
      "Out of range entry at 76, 2\n",
      "Out of range entry at 76, 4\n",
      "Out of range entry at 76, 7\n",
      "Out of range entry at 76, 8\n",
      "Out of range entry at 77, 1\n",
      "Out of range entry at 77, 2\n",
      "Out of range entry at 77, 3\n",
      "Out of range entry at 77, 4\n",
      "Out of range entry at 77, 6\n",
      "Out of range entry at 77, 7\n",
      "Out of range entry at 77, 9\n",
      "Out of range entry at 78, 7\n",
      "Out of range entry at 78, 9\n",
      "Out of range entry at 79, 0\n",
      "Out of range entry at 79, 2\n",
      "Out of range entry at 79, 4\n",
      "Out of range entry at 80, 4\n",
      "Out of range entry at 81, 0\n",
      "Out of range entry at 81, 3\n",
      "Out of range entry at 81, 4\n",
      "Out of range entry at 81, 5\n",
      "Out of range entry at 82, 2\n",
      "Out of range entry at 82, 6\n",
      "Out of range entry at 82, 7\n",
      "Out of range entry at 83, 6\n",
      "Out of range entry at 83, 9\n",
      "Out of range entry at 84, 0\n",
      "Out of range entry at 84, 1\n",
      "Out of range entry at 84, 3\n",
      "Out of range entry at 84, 8\n",
      "Out of range entry at 85, 4\n",
      "Out of range entry at 86, 3\n",
      "Out of range entry at 86, 9\n",
      "Out of range entry at 87, 1\n",
      "Out of range entry at 87, 2\n",
      "Out of range entry at 87, 3\n",
      "Out of range entry at 87, 5\n",
      "Out of range entry at 87, 6\n",
      "Out of range entry at 88, 4\n",
      "Out of range entry at 88, 8\n",
      "Out of range entry at 88, 9\n",
      "Out of range entry at 89, 4\n",
      "Out of range entry at 89, 6\n",
      "Out of range entry at 89, 7\n",
      "Out of range entry at 89, 9\n",
      "Out of range entry at 90, 0\n",
      "Out of range entry at 90, 3\n",
      "Out of range entry at 90, 9\n",
      "Out of range entry at 91, 2\n",
      "Out of range entry at 91, 8\n",
      "Out of range entry at 91, 9\n",
      "Out of range entry at 92, 1\n",
      "Out of range entry at 93, 1\n",
      "Out of range entry at 93, 2\n",
      "Out of range entry at 93, 4\n",
      "Out of range entry at 93, 5\n",
      "Out of range entry at 93, 7\n",
      "Out of range entry at 95, 2\n",
      "Out of range entry at 95, 8\n",
      "Out of range entry at 96, 0\n",
      "Out of range entry at 96, 8\n",
      "Out of range entry at 97, 2\n",
      "Out of range entry at 97, 3\n",
      "Out of range entry at 97, 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of range entry at 98, 1\n",
      "Out of range entry at 98, 7\n",
      "Out of range entry at 99, 2\n",
      "Out of range entry at 99, 3\n",
      "Out of range entry at 99, 4\n",
      "Out of range entry at 99, 6\n",
      "Out of range entry at 99, 9\n",
      "Out of range entry at 100, 1\n",
      "Out of range entry at 100, 3\n",
      "Out of range entry at 100, 4\n",
      "Out of range entry at 101, 0\n",
      "Out of range entry at 101, 1\n",
      "Out of range entry at 101, 3\n",
      "Out of range entry at 101, 4\n",
      "Out of range entry at 101, 8\n",
      "Out of range entry at 102, 0\n",
      "Out of range entry at 102, 1\n",
      "Out of range entry at 102, 2\n",
      "Out of range entry at 102, 9\n",
      "Out of range entry at 103, 0\n",
      "Out of range entry at 103, 2\n",
      "Out of range entry at 103, 5\n",
      "Out of range entry at 103, 9\n",
      "Out of range entry at 104, 0\n",
      "Out of range entry at 104, 1\n",
      "Out of range entry at 104, 2\n",
      "Out of range entry at 104, 6\n",
      "Out of range entry at 104, 9\n",
      "Out of range entry at 105, 0\n",
      "Out of range entry at 105, 7\n",
      "Out of range entry at 106, 1\n",
      "Out of range entry at 106, 6\n",
      "Out of range entry at 107, 3\n",
      "Out of range entry at 107, 4\n",
      "Out of range entry at 107, 5\n",
      "Out of range entry at 108, 0\n",
      "Out of range entry at 108, 4\n",
      "Out of range entry at 108, 6\n",
      "Out of range entry at 109, 3\n",
      "Out of range entry at 109, 4\n",
      "Out of range entry at 109, 8\n",
      "Out of range entry at 109, 9\n",
      "Out of range entry at 110, 6\n",
      "Out of range entry at 110, 7\n",
      "Out of range entry at 110, 8\n",
      "Out of range entry at 111, 4\n",
      "Out of range entry at 111, 8\n",
      "Out of range entry at 112, 4\n",
      "Out of range entry at 112, 9\n",
      "Out of range entry at 113, 0\n",
      "Out of range entry at 113, 5\n",
      "Out of range entry at 113, 6\n",
      "Out of range entry at 113, 8\n",
      "Out of range entry at 114, 1\n",
      "Out of range entry at 114, 9\n",
      "Out of range entry at 115, 5\n",
      "Out of range entry at 115, 7\n",
      "Out of range entry at 115, 8\n",
      "Out of range entry at 116, 6\n",
      "Out of range entry at 117, 3\n",
      "Out of range entry at 117, 4\n",
      "Out of range entry at 117, 5\n",
      "Out of range entry at 117, 6\n",
      "Out of range entry at 117, 8\n",
      "Out of range entry at 118, 2\n",
      "Out of range entry at 118, 8\n",
      "Out of range entry at 118, 9\n",
      "Out of range entry at 119, 6\n",
      "Out of range entry at 120, 0\n",
      "Out of range entry at 120, 1\n",
      "Out of range entry at 120, 2\n",
      "Out of range entry at 120, 3\n",
      "Out of range entry at 120, 4\n",
      "Out of range entry at 121, 1\n",
      "Out of range entry at 121, 8\n",
      "Out of range entry at 121, 9\n",
      "Out of range entry at 122, 0\n",
      "Out of range entry at 122, 4\n",
      "Out of range entry at 122, 5\n",
      "Out of range entry at 122, 7\n",
      "Out of range entry at 123, 2\n",
      "Out of range entry at 123, 3\n",
      "Out of range entry at 123, 5\n",
      "Out of range entry at 123, 6\n",
      "Out of range entry at 123, 8\n",
      "Out of range entry at 123, 9\n",
      "Out of range entry at 124, 1\n",
      "Out of range entry at 124, 5\n",
      "Out of range entry at 124, 6\n",
      "Out of range entry at 125, 4\n",
      "Out of range entry at 125, 7\n",
      "Out of range entry at 125, 8\n",
      "Out of range entry at 125, 9\n",
      "Out of range entry at 126, 1\n",
      "Out of range entry at 126, 2\n",
      "Out of range entry at 126, 7\n",
      "Out of range entry at 127, 2\n",
      "Out of range entry at 127, 4\n",
      "Out of range entry at 127, 8\n",
      "Out of range entry at 127, 9\n",
      "Out of range entry at 128, 0\n",
      "Out of range entry at 128, 1\n",
      "Out of range entry at 128, 4\n",
      "Out of range entry at 128, 8\n",
      "Out of range entry at 129, 1\n",
      "Out of range entry at 129, 2\n",
      "Out of range entry at 129, 3\n",
      "Out of range entry at 129, 5\n",
      "Out of range entry at 130, 5\n",
      "Out of range entry at 130, 6\n",
      "Out of range entry at 130, 7\n",
      "Out of range entry at 130, 8\n",
      "Out of range entry at 130, 9\n",
      "Out of range entry at 131, 5\n",
      "Out of range entry at 131, 6\n",
      "Out of range entry at 132, 5\n",
      "Out of range entry at 133, 1\n",
      "Out of range entry at 133, 3\n",
      "Out of range entry at 133, 4\n",
      "Out of range entry at 133, 5\n",
      "Out of range entry at 133, 6\n",
      "Out of range entry at 133, 7\n",
      "Out of range entry at 134, 2\n",
      "Out of range entry at 135, 8\n",
      "Out of range entry at 136, 3\n",
      "Out of range entry at 136, 5\n",
      "Out of range entry at 136, 6\n",
      "Out of range entry at 136, 7\n",
      "Out of range entry at 137, 2\n",
      "Out of range entry at 137, 7\n",
      "Out of range entry at 138, 1\n",
      "Out of range entry at 138, 2\n",
      "Out of range entry at 138, 5\n",
      "Out of range entry at 139, 0\n",
      "Out of range entry at 139, 9\n",
      "Out of range entry at 140, 5\n",
      "Out of range entry at 140, 7\n",
      "Out of range entry at 140, 8\n",
      "Out of range entry at 140, 9\n",
      "Out of range entry at 141, 5\n",
      "Out of range entry at 142, 2\n",
      "Out of range entry at 142, 3\n",
      "Out of range entry at 142, 9\n",
      "Out of range entry at 144, 0\n",
      "Out of range entry at 144, 1\n",
      "Out of range entry at 144, 6\n",
      "Out of range entry at 145, 1\n",
      "Out of range entry at 145, 3\n",
      "Out of range entry at 145, 8\n",
      "Out of range entry at 145, 9\n",
      "Out of range entry at 146, 6\n",
      "Out of range entry at 146, 7\n",
      "Out of range entry at 148, 1\n",
      "Out of range entry at 148, 3\n",
      "Out of range entry at 148, 4\n",
      "Out of range entry at 149, 3\n",
      "Out of range entry at 149, 7\n",
      "Out of range entry at 149, 9\n",
      "Out of range entry at 150, 0\n",
      "Out of range entry at 150, 2\n",
      "Out of range entry at 150, 4\n",
      "Out of range entry at 150, 7\n",
      "Out of range entry at 150, 8\n",
      "Out of range entry at 150, 9\n",
      "Out of range entry at 151, 4\n",
      "Out of range entry at 152, 2\n",
      "Out of range entry at 152, 4\n",
      "Out of range entry at 152, 7\n",
      "Out of range entry at 153, 1\n",
      "Out of range entry at 153, 2\n",
      "Out of range entry at 153, 9\n",
      "Out of range entry at 154, 1\n",
      "Out of range entry at 154, 3\n",
      "Out of range entry at 154, 4\n",
      "Out of range entry at 154, 9\n",
      "Out of range entry at 155, 0\n",
      "Out of range entry at 155, 1\n",
      "Out of range entry at 155, 2\n",
      "Out of range entry at 155, 8\n",
      "Out of range entry at 156, 0\n",
      "Out of range entry at 156, 1\n",
      "Out of range entry at 156, 8\n",
      "Out of range entry at 156, 9\n",
      "Out of range entry at 157, 5\n",
      "Out of range entry at 157, 6\n",
      "Out of range entry at 158, 6\n",
      "Out of range entry at 158, 7\n",
      "Out of range entry at 158, 9\n",
      "Out of range entry at 159, 0\n",
      "Out of range entry at 159, 3\n",
      "Out of range entry at 160, 3\n",
      "Out of range entry at 160, 6\n",
      "Out of range entry at 160, 7\n",
      "Out of range entry at 160, 8\n",
      "Out of range entry at 161, 0\n",
      "Out of range entry at 161, 4\n",
      "Out of range entry at 162, 1\n",
      "Out of range entry at 162, 2\n",
      "Out of range entry at 162, 9\n",
      "Out of range entry at 163, 3\n",
      "Out of range entry at 164, 0\n",
      "Out of range entry at 164, 2\n",
      "Out of range entry at 164, 5\n",
      "Out of range entry at 164, 7\n",
      "Out of range entry at 164, 8\n",
      "Out of range entry at 164, 9\n",
      "Out of range entry at 165, 7\n",
      "Out of range entry at 166, 0\n",
      "Out of range entry at 166, 1\n",
      "Out of range entry at 166, 8\n",
      "Out of range entry at 167, 1\n",
      "Out of range entry at 167, 2\n",
      "Out of range entry at 167, 4\n",
      "Out of range entry at 167, 6\n",
      "Out of range entry at 168, 3\n",
      "Out of range entry at 168, 7\n",
      "Out of range entry at 168, 8\n",
      "Out of range entry at 169, 3\n",
      "Out of range entry at 169, 4\n",
      "Out of range entry at 169, 6\n",
      "Out of range entry at 169, 7\n",
      "Out of range entry at 169, 9\n",
      "Out of range entry at 170, 0\n",
      "Out of range entry at 170, 3\n",
      "Out of range entry at 170, 8\n",
      "Out of range entry at 171, 1\n",
      "Out of range entry at 171, 3\n",
      "Out of range entry at 171, 9\n",
      "Out of range entry at 172, 2\n",
      "Out of range entry at 173, 0\n",
      "Out of range entry at 173, 2\n",
      "Out of range entry at 173, 3\n",
      "Out of range entry at 173, 9\n",
      "Out of range entry at 174, 1\n",
      "Out of range entry at 174, 2\n",
      "Out of range entry at 174, 6\n",
      "Out of range entry at 175, 0\n",
      "Out of range entry at 175, 5\n",
      "Out of range entry at 175, 7\n",
      "Out of range entry at 175, 8\n",
      "Out of range entry at 176, 1\n",
      "Out of range entry at 176, 2\n",
      "Out of range entry at 177, 2\n",
      "Out of range entry at 177, 6\n",
      "Out of range entry at 177, 7\n",
      "Out of range entry at 177, 9\n",
      "Out of range entry at 178, 3\n",
      "Out of range entry at 178, 6\n",
      "Out of range entry at 178, 8\n",
      "Out of range entry at 178, 9\n",
      "Out of range entry at 179, 1\n",
      "Out of range entry at 179, 3\n",
      "Out of range entry at 179, 5\n",
      "Out of range entry at 179, 6\n",
      "Out of range entry at 179, 7\n",
      "Out of range entry at 180, 0\n",
      "Out of range entry at 180, 1\n",
      "Out of range entry at 180, 2\n",
      "Out of range entry at 180, 4\n",
      "Out of range entry at 180, 7\n",
      "Out of range entry at 181, 2\n",
      "Out of range entry at 181, 3\n",
      "Out of range entry at 181, 4\n",
      "Out of range entry at 181, 9\n",
      "Out of range entry at 182, 5\n",
      "Out of range entry at 183, 1\n",
      "Out of range entry at 183, 3\n",
      "Out of range entry at 183, 4\n",
      "Out of range entry at 183, 6\n",
      "Out of range entry at 183, 7\n",
      "Out of range entry at 184, 0\n",
      "Out of range entry at 184, 2\n",
      "Out of range entry at 184, 8\n",
      "Out of range entry at 185, 0\n",
      "Out of range entry at 185, 1\n",
      "Out of range entry at 185, 3\n",
      "Out of range entry at 186, 1\n",
      "Out of range entry at 186, 3\n",
      "Out of range entry at 186, 5\n",
      "Out of range entry at 187, 2\n",
      "Out of range entry at 187, 6\n",
      "Out of range entry at 187, 7\n",
      "Out of range entry at 187, 8\n",
      "Out of range entry at 187, 9\n",
      "Out of range entry at 188, 0\n",
      "Out of range entry at 188, 4\n",
      "Out of range entry at 188, 8\n",
      "Out of range entry at 189, 0\n",
      "Out of range entry at 189, 5\n",
      "Out of range entry at 189, 7\n",
      "Out of range entry at 189, 8\n",
      "Out of range entry at 190, 1\n",
      "Out of range entry at 190, 6\n",
      "Out of range entry at 191, 1\n",
      "Out of range entry at 191, 2\n",
      "Out of range entry at 191, 5\n",
      "Out of range entry at 191, 6\n",
      "Out of range entry at 192, 4\n",
      "Out of range entry at 192, 8\n",
      "Out of range entry at 192, 9\n",
      "Out of range entry at 193, 2\n",
      "Out of range entry at 193, 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of range entry at 194, 3\n",
      "Out of range entry at 194, 6\n",
      "Out of range entry at 194, 8\n",
      "Out of range entry at 194, 9\n",
      "Out of range entry at 195, 2\n",
      "Out of range entry at 195, 3\n",
      "Out of range entry at 195, 4\n",
      "Out of range entry at 195, 6\n",
      "Out of range entry at 195, 8\n",
      "Out of range entry at 196, 1\n",
      "Out of range entry at 196, 2\n",
      "Out of range entry at 196, 8\n",
      "Out of range entry at 197, 2\n",
      "Out of range entry at 197, 3\n",
      "Out of range entry at 198, 2\n",
      "Out of range entry at 198, 3\n",
      "Out of range entry at 198, 5\n",
      "Out of range entry at 199, 2\n",
      "Out of range entry at 199, 4\n",
      "Out of range entry at 199, 7\n",
      "Out of range entry at 199, 8\n",
      "Out of range entry at 200, 1\n",
      "Out of range entry at 200, 3\n",
      "Out of range entry at 201, 0\n",
      "Out of range entry at 201, 3\n",
      "Out of range entry at 201, 5\n",
      "Out of range entry at 201, 9\n",
      "Out of range entry at 202, 2\n",
      "Out of range entry at 202, 4\n",
      "Out of range entry at 203, 1\n",
      "Out of range entry at 203, 4\n",
      "Out of range entry at 203, 9\n",
      "Out of range entry at 205, 0\n",
      "Out of range entry at 205, 1\n",
      "Out of range entry at 206, 4\n",
      "Out of range entry at 207, 1\n",
      "Out of range entry at 207, 2\n",
      "Out of range entry at 207, 6\n",
      "Out of range entry at 207, 7\n",
      "Out of range entry at 208, 0\n",
      "Out of range entry at 208, 5\n",
      "Out of range entry at 208, 7\n",
      "Out of range entry at 209, 0\n",
      "Out of range entry at 209, 2\n",
      "Out of range entry at 209, 6\n",
      "Out of range entry at 210, 0\n",
      "Out of range entry at 210, 2\n",
      "Out of range entry at 210, 3\n",
      "Out of range entry at 210, 5\n",
      "Out of range entry at 211, 0\n",
      "Out of range entry at 211, 2\n",
      "Out of range entry at 211, 4\n",
      "Out of range entry at 211, 8\n",
      "Out of range entry at 211, 9\n",
      "Out of range entry at 212, 0\n",
      "Out of range entry at 212, 1\n",
      "Out of range entry at 212, 6\n",
      "Out of range entry at 212, 7\n",
      "Out of range entry at 213, 1\n",
      "Out of range entry at 213, 9\n",
      "Out of range entry at 214, 0\n",
      "Out of range entry at 214, 3\n",
      "Out of range entry at 214, 5\n",
      "Out of range entry at 215, 2\n",
      "Out of range entry at 215, 6\n",
      "Out of range entry at 215, 8\n",
      "Out of range entry at 216, 0\n",
      "Out of range entry at 216, 1\n",
      "Out of range entry at 216, 4\n",
      "Out of range entry at 216, 8\n",
      "Out of range entry at 216, 9\n",
      "Out of range entry at 217, 3\n",
      "Out of range entry at 217, 4\n",
      "Out of range entry at 218, 2\n",
      "Out of range entry at 218, 4\n",
      "Out of range entry at 218, 5\n",
      "Out of range entry at 218, 7\n",
      "Out of range entry at 218, 9\n",
      "Out of range entry at 219, 4\n",
      "Out of range entry at 219, 5\n",
      "Out of range entry at 220, 1\n",
      "Out of range entry at 220, 4\n",
      "Out of range entry at 220, 6\n",
      "Out of range entry at 220, 9\n",
      "Out of range entry at 221, 4\n",
      "Out of range entry at 221, 6\n",
      "Out of range entry at 221, 8\n",
      "Out of range entry at 222, 1\n",
      "Out of range entry at 222, 4\n",
      "Out of range entry at 222, 6\n",
      "Out of range entry at 223, 0\n",
      "Out of range entry at 223, 1\n",
      "Out of range entry at 223, 6\n",
      "Out of range entry at 223, 8\n",
      "Out of range entry at 224, 3\n",
      "Out of range entry at 224, 9\n",
      "Out of range entry at 225, 2\n",
      "Out of range entry at 225, 3\n",
      "Out of range entry at 225, 6\n",
      "Out of range entry at 225, 9\n",
      "Out of range entry at 226, 0\n",
      "Out of range entry at 226, 3\n",
      "Out of range entry at 226, 5\n",
      "Out of range entry at 227, 1\n",
      "Out of range entry at 227, 4\n",
      "Out of range entry at 227, 6\n",
      "Out of range entry at 228, 0\n",
      "Out of range entry at 228, 2\n",
      "Out of range entry at 228, 3\n",
      "Out of range entry at 228, 4\n",
      "Out of range entry at 228, 5\n",
      "Out of range entry at 228, 8\n",
      "Out of range entry at 229, 3\n",
      "Out of range entry at 229, 7\n",
      "Out of range entry at 229, 9\n",
      "Out of range entry at 230, 0\n",
      "Out of range entry at 230, 4\n",
      "Out of range entry at 230, 7\n",
      "Out of range entry at 231, 4\n",
      "Out of range entry at 231, 9\n",
      "Out of range entry at 232, 1\n",
      "Out of range entry at 232, 3\n",
      "Out of range entry at 232, 5\n",
      "Out of range entry at 232, 8\n",
      "Out of range entry at 233, 0\n",
      "Out of range entry at 233, 5\n",
      "Out of range entry at 233, 8\n",
      "Out of range entry at 235, 3\n",
      "Out of range entry at 235, 8\n",
      "Out of range entry at 236, 3\n",
      "Out of range entry at 236, 6\n",
      "Out of range entry at 236, 7\n",
      "Out of range entry at 236, 8\n",
      "Out of range entry at 236, 9\n",
      "Out of range entry at 237, 0\n",
      "Out of range entry at 237, 1\n",
      "Out of range entry at 237, 3\n",
      "Out of range entry at 237, 9\n",
      "Out of range entry at 238, 3\n",
      "Out of range entry at 238, 4\n",
      "Out of range entry at 238, 8\n",
      "Out of range entry at 239, 1\n",
      "Out of range entry at 239, 8\n",
      "Out of range entry at 240, 6\n",
      "Out of range entry at 240, 9\n",
      "Out of range entry at 241, 3\n",
      "Out of range entry at 241, 5\n",
      "Out of range entry at 241, 6\n",
      "Out of range entry at 241, 8\n",
      "Out of range entry at 241, 9\n",
      "Out of range entry at 242, 0\n",
      "Out of range entry at 242, 4\n",
      "Out of range entry at 242, 9\n",
      "Out of range entry at 243, 3\n",
      "Out of range entry at 244, 3\n",
      "Out of range entry at 245, 0\n",
      "Out of range entry at 245, 5\n",
      "Out of range entry at 245, 6\n",
      "Out of range entry at 246, 3\n",
      "Out of range entry at 246, 5\n",
      "Out of range entry at 246, 7\n",
      "Out of range entry at 247, 0\n",
      "Out of range entry at 247, 3\n",
      "Out of range entry at 247, 4\n",
      "Out of range entry at 247, 8\n",
      "Out of range entry at 247, 9\n",
      "Out of range entry at 248, 2\n",
      "Out of range entry at 248, 3\n",
      "Out of range entry at 248, 4\n",
      "Out of range entry at 249, 0\n",
      "Out of range entry at 249, 9\n",
      "Out of range entry at 250, 2\n",
      "Out of range entry at 250, 3\n",
      "Out of range entry at 250, 4\n",
      "Out of range entry at 251, 4\n",
      "Out of range entry at 251, 8\n",
      "Out of range entry at 251, 9\n",
      "Out of range entry at 252, 2\n",
      "Out of range entry at 252, 3\n",
      "Out of range entry at 253, 2\n",
      "Out of range entry at 253, 4\n",
      "Out of range entry at 253, 8\n",
      "Out of range entry at 254, 0\n",
      "Out of range entry at 254, 9\n",
      "Out of range entry at 255, 1\n",
      "Out of range entry at 255, 3\n",
      "Out of range entry at 255, 4\n",
      "Out of range entry at 255, 6\n",
      "Out of range entry at 256, 0\n",
      "Out of range entry at 256, 1\n",
      "Out of range entry at 256, 2\n",
      "Out of range entry at 256, 8\n",
      "Out of range entry at 258, 0\n",
      "Out of range entry at 258, 2\n",
      "Out of range entry at 258, 4\n",
      "Out of range entry at 258, 5\n",
      "Out of range entry at 258, 9\n",
      "Out of range entry at 259, 1\n",
      "Out of range entry at 259, 2\n",
      "Out of range entry at 259, 3\n",
      "Out of range entry at 260, 4\n",
      "Out of range entry at 260, 6\n",
      "Out of range entry at 261, 3\n",
      "Out of range entry at 261, 4\n",
      "Out of range entry at 261, 7\n",
      "Out of range entry at 262, 0\n",
      "Out of range entry at 262, 2\n",
      "Out of range entry at 262, 3\n",
      "Out of range entry at 262, 5\n",
      "Out of range entry at 262, 7\n",
      "Out of range entry at 262, 8\n",
      "Out of range entry at 262, 9\n",
      "Out of range entry at 263, 1\n",
      "Out of range entry at 263, 3\n",
      "Out of range entry at 263, 4\n",
      "Out of range entry at 263, 6\n",
      "Out of range entry at 263, 7\n",
      "Out of range entry at 264, 0\n",
      "Out of range entry at 264, 1\n",
      "Out of range entry at 264, 9\n",
      "Out of range entry at 265, 7\n",
      "Out of range entry at 266, 0\n",
      "Out of range entry at 266, 5\n",
      "Out of range entry at 266, 6\n",
      "Out of range entry at 266, 8\n",
      "Out of range entry at 267, 1\n",
      "Out of range entry at 267, 4\n",
      "Out of range entry at 267, 5\n",
      "Out of range entry at 267, 6\n",
      "Out of range entry at 268, 3\n",
      "Out of range entry at 268, 4\n",
      "Out of range entry at 268, 9\n",
      "Out of range entry at 269, 4\n",
      "Out of range entry at 269, 8\n",
      "Out of range entry at 270, 3\n",
      "Out of range entry at 270, 9\n",
      "Out of range entry at 271, 2\n",
      "Out of range entry at 271, 5\n",
      "Out of range entry at 271, 7\n",
      "Out of range entry at 271, 8\n",
      "Out of range entry at 271, 9\n",
      "Out of range entry at 272, 0\n",
      "Out of range entry at 272, 1\n",
      "Out of range entry at 273, 3\n",
      "Out of range entry at 273, 4\n",
      "Out of range entry at 273, 6\n",
      "Out of range entry at 274, 1\n",
      "Out of range entry at 274, 5\n",
      "Out of range entry at 274, 8\n",
      "Out of range entry at 275, 1\n",
      "Out of range entry at 275, 2\n",
      "Out of range entry at 275, 3\n",
      "Out of range entry at 275, 5\n",
      "Out of range entry at 275, 6\n",
      "Out of range entry at 275, 7\n",
      "Out of range entry at 275, 8\n",
      "Out of range entry at 275, 9\n",
      "Out of range entry at 276, 0\n",
      "Out of range entry at 276, 5\n",
      "Out of range entry at 276, 7\n",
      "Out of range entry at 277, 1\n",
      "Out of range entry at 277, 3\n",
      "Out of range entry at 279, 0\n",
      "Out of range entry at 279, 1\n",
      "Out of range entry at 279, 5\n",
      "Out of range entry at 279, 6\n",
      "Out of range entry at 279, 8\n",
      "Out of range entry at 280, 0\n",
      "Out of range entry at 280, 2\n",
      "Out of range entry at 280, 7\n",
      "Out of range entry at 281, 0\n",
      "Out of range entry at 281, 1\n",
      "Out of range entry at 281, 2\n",
      "Out of range entry at 281, 3\n",
      "Out of range entry at 281, 4\n",
      "Out of range entry at 281, 6\n",
      "Out of range entry at 281, 9\n",
      "Out of range entry at 282, 9\n",
      "Out of range entry at 283, 2\n",
      "Out of range entry at 283, 4\n",
      "Out of range entry at 283, 6\n",
      "Out of range entry at 284, 2\n",
      "Out of range entry at 285, 0\n",
      "Out of range entry at 285, 1\n",
      "Out of range entry at 285, 9\n",
      "Out of range entry at 286, 1\n",
      "Out of range entry at 286, 6\n",
      "Out of range entry at 286, 7\n",
      "Out of range entry at 287, 0\n",
      "Out of range entry at 287, 1\n",
      "Out of range entry at 287, 2\n",
      "Out of range entry at 287, 4\n",
      "Out of range entry at 288, 4\n",
      "Out of range entry at 288, 5\n",
      "Out of range entry at 288, 9\n",
      "Out of range entry at 289, 0\n",
      "Out of range entry at 289, 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of range entry at 289, 3\n",
      "Out of range entry at 290, 0\n",
      "Out of range entry at 290, 3\n",
      "Out of range entry at 290, 6\n",
      "Out of range entry at 291, 2\n",
      "Out of range entry at 291, 3\n",
      "Out of range entry at 291, 5\n",
      "Out of range entry at 291, 6\n",
      "Out of range entry at 292, 3\n",
      "Out of range entry at 292, 4\n",
      "Out of range entry at 293, 0\n",
      "Out of range entry at 293, 5\n",
      "Out of range entry at 293, 7\n",
      "Out of range entry at 294, 0\n",
      "Out of range entry at 294, 4\n",
      "Out of range entry at 295, 0\n",
      "Out of range entry at 295, 2\n",
      "Out of range entry at 295, 6\n",
      "Out of range entry at 296, 3\n",
      "Out of range entry at 296, 5\n",
      "Out of range entry at 296, 6\n",
      "Out of range entry at 296, 7\n",
      "Out of range entry at 297, 1\n",
      "Out of range entry at 297, 5\n",
      "Out of range entry at 298, 7\n",
      "Out of range entry at 299, 4\n",
      "Out of range entry at 299, 6\n",
      "Out of range entry at 299, 9\n",
      "Top row should match middle row, but probably not bottom row\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADfCAYAAACj4kcNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAJRUlEQVR4nO3cTWhl5RnA8edNcmeYLxs12lQxtQZpRcmm1l2nkBIodFE6rXXZuijVjSC2RTuCiA0ODIMg3ZQu6qaFwTLQXWHARRYtdTaiI/W7aURpR7GpmSQ2yc3pIs3gR3JvMmTuee69v99yzrnc974vOf/JyXtuqaoqACCbgboHAABbESgAUhIoAFISKABSEigAUhIoAFISKABSEigAUhIoAFISKABSEigAUhIoAFISKABSEigAUhIoAFISKABSEigAUhIoAFISKABSEigAUhqqewB7afz09ExEjLU4Ze7Ne44f7dR4AOpw/MVjba+F0xNn0l8LeypQsbEg77c5DtDreuJa6BYfACkJFAApCRQAKQkUACkJFAAp9dQuvrJUhquh6sZtj6+VxU6OB/rdLU+farXdee6tBx5Kv9W5S80trw3dVVVlcKuDS2uN5vjp6ZmPP3YzOXWi5Vo9d/bhjq9VTwVq/2sH5iPijRanjHRoKMCGVtudu2KrczeanjhzdPz09Gzsbqt5urVyiw+AlAQKgJQECoCUBAqAlAQKgJQECoCUOrLNfGrg7rZf/X52/dlLe+zbfFV8q6+Jn4uIsYHVajSq+Mz+/4GVqjk5dWKmjv38V1Kb+f3E3FK/flqvfW9fHG4eaWz5bOLgwqrnEq+Q2x95aqbcWkarxjbPhZZoRiOe/8S/fbg4HPu2XqtYqWetOvUc1G6/+v2y9uO//OSDRyMiJqdOzF7O67tYuucXaKlv1uumU+fnY/tnE0fiZAcH01/G9r9+4HyL4yOb18tNg+demY9Wa1UDt/gASEmgAEhJoABISaAASEmgAEipU7v45qLNNvNdnP/pc3f7fjt5fbfpt8/b7fppvfrps2ay22tuu9fUslalqqo63hcAWnKLD4CUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlAQKgJQECoCUBAqAlIbqHsBeGj89PRMRYy1OmXvznuNHOzUegDocf/FY22vh9MSZ9NfCngpUbCzI+22OA/S6nrgWusUHQEoCBUBKAgVASgIFQEoCBUBKPbWLryyV4WqounHb42tlsZPjgX53y9OnWm13nnvrgYfSb3XuUnPLa0N3VVUZ3Org0lqjOX56eubjj91MTp1ouVbPnX2442vVU4Ha/9qB+Yh4o8UpIx0aCrCh1Xbnrtjq3I2mJ84cHT89PRu722qebq3c4gMgJYECICWBAiAlgQIgJYECIKWO7OKbGri77Tfrnl1/di+2MM5FxNjAajUaVXxme+XAStWcnDoxU8d2SdjU5udhr34WUtj39sXh5pHGlo9+DC6seuzjCrn9kadmyq1ltGps89hNiWY04vlP/NuHi8Oxb+u1ipV61qpT28x39c26bb4qftuviX/5yQePRkRMTp2YbfF+Pbe1tZ8ueD0i3XbeK+WmU+fnY/tHP0biZAcH01/G9r9+4HyL4yOb18tNg+demY9Wa1WDrM9B9c0P8B4xX0DP8TcoAFISKABSEigAUhIoAFISKABS6tQuvrlo8xzULs7/9Lm7fb+dvL7b9Nvn7Xb9tF799Fkz2e01t91ralmrUlVVHe8LAC25xQdASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEoCBUBKAgVASgIFQEpDdQ+gna/87PH55pHGoe2ODy6sLr5y8rHhDg4JoGt87ZlH1+JwNbjtCRdL89yPfpmyBSkH9XHNI41DA8vNlVbHOzkegK5yuBqMj8p6y+NJpQ/UJa/9K/595g8HSkRc853vLa/fNlr3iLpaKaWMxNdPRlRfPRTjP5+tnjlX95i63V3l+09cjHfvHY6bf/Pn6veP1z2ebvet8vSDjRh5ohkf/n09YuJP1X1V3WPqZuWDlRj99Xul2ajiwn2fr+Jwo+4htdU6UKWci4jrOjOUrQ0+9sTQ/rXVwbW/vBqLsRAlSlz/11cPDNx6bURE/He9lChlts4xRlXdvKPzEsznpgsxUL4ZH9ywElU5Fstno5T5usd0yU7nMyLVnB6KO2+8GMsDB+Mfj0Yp99Y9nku6dD6/FI+Nvhuj+wbjqtt/FT+ejXJ/jkB12XyWZ38RpaoG9r16MQ7/s0RVSnzw5kJZn7g6IiKqjXHO1jnG7ea03W9Q10XE+3s+mF0pY1WUqpq8I6753eslokT1jYmqirJ5PKL2Me5YgvnccG2sx7cjGi/FkYPfjbffiYjlusd0mdLM6Q9iZeBMfO76u+OjC5FkTJchzXweiz+u/jauGhuNvy3eEEvv1T2ey5RhPr8YEbFyx+G4cNtCrA9FNL98/aUr6P/VPcYtdc0tvqEvXBVX//SHOf4H1QMGIuLJePndusfRS+6PFy/cH3Gh7nH0iql44T9T8cJLdY+jZxxuxMJPxiIiPh2ntGwzByCl9L9BHZxfWl8aPrhtSA/OL22/OwWgz5WFqqqOlG1/aSoLVdo7U6VqNbaNP5ylvDeZSlXduaPzzOfO7HQ+I8zpTpjPvWU+9942c+oWHwApCRQAKbW+xQcANfEbFAApCRQAKQkUACkJFAApCRQAKQkUACn9Dwkr544bMPQHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make node embedding units to encode / decode nodes to a fixed, common node embedding size.\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, PackedSequence\n",
    "class ObservedSceneAutoencoder(torch.nn.Module):\n",
    "    '''\n",
    "        Consumes an observed scene as a list of observed nodes\n",
    "        from the specified grammar, and produces a fixed-size\n",
    "        encoding vector for each observed scene.\n",
    "        \n",
    "        Observed set representation: Each observed node set is transformed\n",
    "        into a PackedSequence of tensors, one for each node, which encode\n",
    "        the node by concatenating its continuous variables (zero-padded to the\n",
    "        max # of vars for any node) with a one-hot vector indicating the node type.\n",
    "        Two additional node types (\"start\" and \"stop\") are added as additional\n",
    "        one-hot slots.\n",
    "        \n",
    "        Encoding: Feed the PackedSequence into a GRU, and grab the output from\n",
    "        the last iteration as the encoded \"context\" vector. (Borrowing terminology\n",
    "        from seq2seq networks here.)\n",
    "        \n",
    "        Decoding: Create a GRU whose initial hidden state is the encoded context,\n",
    "            and process its top GRU layer hidden state with a small densely connected\n",
    "            network to produce a node fixed-size encoding (one-hot and variable regression).\n",
    "            The first input is a \"start\" node, and every following input is the last\n",
    "            output of the decoder.\n",
    "    '''\n",
    "    def __init__(self, grammar,\n",
    "                 context_size=64,\n",
    "                 num_layers=3):\n",
    "        super().__init__()\n",
    "        # Figure out what size the nodes need to be padded out to,\n",
    "        # and the size of the one-hot encoding.\n",
    "        self.unique_node_types = sorted(list(grammar.get_all_types_in_grammar()), key=lambda x: x.__class__.__name__)\n",
    "        # Add \"start\" and \"stop\" symbols to node types\n",
    "        self.num_node_types_without_extras = len(self.unique_node_types)\n",
    "        self.num_node_types = len(self.unique_node_types) + 2\n",
    "        self.start_symbol_offset = len(self.unique_node_types)\n",
    "        self.stop_symbol_offset = len(self.unique_node_types) + 1\n",
    "        \n",
    "        self.node_type_to_index = {}\n",
    "        self.node_type_to_num_vars = {}\n",
    "        for k, node_type in enumerate(self.unique_node_types):\n",
    "            self.node_type_to_index[node_type] = k\n",
    "            self.node_type_to_num_vars[node_type] = node_type.get_num_continuous_variables()\n",
    "        self.padded_node_var_size = max(self.node_type_to_num_vars.values())\n",
    "\n",
    "        self.encoder_input_size = self.num_node_types + self.padded_node_var_size\n",
    "        self.context_size = context_size\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = torch.nn.GRU(\n",
    "            input_size=self.encoder_input_size,\n",
    "            hidden_size=self.context_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.decoder_input_size = self.encoder_input_size\n",
    "        # Offsets into decoder top-level hidden state\n",
    "        self.decoder = torch.nn.GRU(\n",
    "            input_size=self.decoder_input_size,\n",
    "            hidden_size=self.context_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder_common_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.context_size, self.context_size),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.decoder_vars_head = torch.nn.Linear(self.context_size, self.padded_node_var_size)\n",
    "        self.decoder_onehot_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.context_size, self.num_node_types),\n",
    "            torch.nn.Softmax()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def make_start_vec(self):\n",
    "        stop_vec = torch.zeros(self.encoder_input_size, device=self.get_device())\n",
    "        stop_vec[self.start_symbol_offset] = 1.\n",
    "        return stop_vec\n",
    "\n",
    "    def make_stop_vec(self):\n",
    "        stop_vec = torch.zeros(self.encoder_input_size, device=self.get_device())\n",
    "        stop_vec[self.stop_symbol_offset] = 1.\n",
    "        return stop_vec\n",
    "    \n",
    "    def get_device(self):\n",
    "        return self.encoder._flat_weights[0].device\n",
    "        \n",
    "    def pack_observed_nodes_batch(self, observed_nodes_batch):\n",
    "        # Packs a list of lists of observed nodes (so a batch of observed scenes)\n",
    "        # into a PackedSequence of encoded node sets.\n",
    "        batch_size = len(observed_nodes_batch)\n",
    "        seq_sizes = [len(x) for x in observed_nodes_batch]\n",
    "        max_seq_size = max(seq_sizes)\n",
    "\n",
    "        # Make input: for each node, make a one-hot vector of its\n",
    "        # type, and concatenate with the node continuous vars, padded\n",
    "        # out to a max length that fits all node types.\n",
    "        xs = torch.zeros(batch_size, max_seq_size, self.encoder_input_size, device=self.get_device())\n",
    "        for batch_k, nodes in enumerate(observed_nodes_batch):\n",
    "            for k, node in enumerate(nodes):\n",
    "                node_type = node.__class__\n",
    "                index = self.node_type_to_index[node_type]\n",
    "                n_vars = self.node_type_to_num_vars[node_type]\n",
    "                # Make one-hot indicating the type.\n",
    "                xs[batch_k, k, index] = 1.\n",
    "                # Stick in the node variable valuesl.\n",
    "                xs[batch_k, k, self.num_node_types:self.num_node_types + n_vars] = \\\n",
    "                    node.get_all_continuous_variables_as_vector()\n",
    "        encoded_node_batches = pack_padded_sequence(xs, seq_sizes, batch_first=True, enforce_sorted=False)\n",
    "        return encoded_node_batches\n",
    "        \n",
    "    def unpack_observed_nodes_batch(self, x):\n",
    "        # Use pack_observed_nodes_batch to create the appropriate input.\n",
    "        assert isinstance(x, PackedSequence)\n",
    "        x_padded, seq_lens = pad_packed_sequence(x, batch_first=True)\n",
    "        assert x_padded.shape[2] == self.encoder_input_size\n",
    "        observed_nodes_batch = []\n",
    "        \n",
    "        for seq_k, (seq_len, vec) in enumerate(zip(seq_lens, x_padded)):\n",
    "            nodes = []\n",
    "            for node_k in range(seq_len):\n",
    "                node_type_weights = vec[node_k, :][:self.num_node_types]\n",
    "                if not torch.isclose(torch.sum(node_type_weights), torch.tensor(1.0)):\n",
    "                    print(\"Bad entry at %d, %d\" % (seq_k, node_k))\n",
    "                    continue\n",
    "                node_type = pyro.sample(\n",
    "                    \"unpack_%d_%d\" % (seq_k, node_k),\n",
    "                    dist.Categorical(node_type_weights)\n",
    "                )\n",
    "                if (node_type < self.num_node_types_without_extras):\n",
    "                    node = self.unique_node_types[node_type].init_with_default_parameters()\n",
    "                    node_vars = vec[node_k, :][self.num_node_types:]\n",
    "                    derived, local = node.get_continuous_variables_from_vector(node_vars)\n",
    "                    derived_variable_dists = {key: dist.Delta(val) for key,  val in derived.items()} \n",
    "                    local_variable_dists = {key: dist.Delta(val) for key,  val in local.items()}\n",
    "                    node.instantiate(derived_variable_distributions=derived_variable_dists,\n",
    "                                     local_variable_distributions_override=local_variable_dists)\n",
    "                    nodes.append(node)\n",
    "                else:\n",
    "                    print(\"Out of range entry at %d, %d\" % (seq_k, node_k))\n",
    "            observed_nodes_batch.append(nodes)\n",
    "        return observed_nodes_batch\n",
    "\n",
    "    def encode(self, x):\n",
    "        assert isinstance(x, PackedSequence)\n",
    "        _, last_hidden = self.encoder(x)\n",
    "        batch_size = last_hidden.shape[1]\n",
    "        return last_hidden.permute([1, 2, 0]).reshape((batch_size, -1))\n",
    "\n",
    "    def decode(self, z, target_x=None, max_n_objects=50, teacher_forcing=0.5):\n",
    "        assert isinstance(z, torch.Tensor) and z.shape[1] == self.context_size * self.num_layers\n",
    "        batch_size = z.shape[0]\n",
    "        \n",
    "        if target_x is not None:\n",
    "            assert isinstance(target_x, PackedSequence)\n",
    "            target_x, seq_sizes = pad_packed_sequence(target_x, batch_first=True)\n",
    "            assert target_x.shape[0] == batch_size and target_x.shape[2] == self.encoder_input_size\n",
    "            max_n_objects = torch.max(seq_sizes) + 1\n",
    "\n",
    "        # Run GRU up to some max number of times to produce samples, feeding its output\n",
    "        # back in as input, starting with the start vector.\n",
    "        last_node_output = torch.empty((batch_size, 1, self.decoder_input_size), device=z.device)\n",
    "        last_node_output[:, 0, :] = self.make_start_vec()\n",
    "        hidden = z.reshape((batch_size, self.context_size, self.num_layers)).permute([2, 0, 1]).contiguous()\n",
    "        output_steps = []\n",
    "        for k in range(max_n_objects):\n",
    "            # Single-step the GRU\n",
    "            _, hidden = self.decoder(last_node_output, hidden)\n",
    "            last_hidden = hidden[-1, ...]\n",
    "            # Apply the regression heads to get the node prediction and calculate\n",
    "            # the next input.\n",
    "            common = self.decoder_common_head(last_hidden)\n",
    "            node_choice = self.decoder_onehot_head(common)\n",
    "            node_vars = self.decoder_vars_head(common)\n",
    "            last_node_output = torch.cat([node_choice, node_vars], dim=-1)\n",
    "            output_steps.append(last_node_output.clone())\n",
    "            last_node_output = last_node_output.unsqueeze(1)\n",
    "            \n",
    "            if target_x is not None:\n",
    "                last_node_output = target_x[:, k:k+1, :]\n",
    "                # TODO: teacher forcing?\n",
    "            else:\n",
    "                # If all nodes are \"stop\", we can stop early.\n",
    "                if torch.all(torch.argmax(node_choice, dim=1) == self.stop_symbol_offset):\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        x = torch.stack(output_steps, dim=1) # batch_size x max_repeats x node encoding size    \n",
    "        # If we have a target sequence, we need to have the same number of repeats as that\n",
    "        # sequence, minimum.\n",
    "        # Create an output PackedSequence by computing the number of actual repeats before\n",
    "        # a \"stop\" in each output sequence.\n",
    "        stops = (torch.argmax(x[:, :, :self.num_node_types], dim=-1) == self.stop_symbol_offset).int()\n",
    "        ever_stopped, _ = torch.max(stops, dim=-1)\n",
    "        num_repeats = torch.where(ever_stopped.bool(), torch.argmax(stops, dim=1), \n",
    "                                  torch.ones(batch_size, device=z.device).long()*max_n_objects)\n",
    "        # We do need to clip all sequences to min length 1 to be able to pack, unfortunately.\n",
    "        num_repeats = torch.clip(num_repeats, 1)\n",
    "        # And if we have a target sequeunce, we need as many repeats as that target sequence,\n",
    "        # even if it's multiple stops, to get training signal.\n",
    "        if target_x is not None:\n",
    "            num_repeats = torch.maximum(num_repeats.cpu(), seq_sizes + 1)\n",
    "        \n",
    "        return pack_padded_sequence(x, num_repeats.cpu(), batch_first=True, enforce_sorted=False)\n",
    "    \n",
    "test_scene_autoenc = ObservedSceneAutoencoder(grammar)\n",
    "x = test_scene_autoenc.pack_observed_nodes_batch(observed_nodes_for_test)\n",
    "print(\"Start vec: \", test_scene_autoenc.make_start_vec())\n",
    "print(\"Stop vec: \", test_scene_autoenc.make_stop_vec())\n",
    "z = test_scene_autoenc.encode(x)\n",
    "x_recon = test_scene_autoenc.decode(z, target_x=None, max_n_objects=10)\n",
    "#x_recon = test_scene_autoenc.decode(z, target_x=x)\n",
    "print(\"X shape: \", pad_packed_sequence(x, batch_first=True)[0].shape)\n",
    "print(\"Z shape: \", z.shape)\n",
    "print(\"X recon shape: \", pad_packed_sequence(x_recon, batch_first=True)[0].shape)\n",
    "\n",
    "def make_observed_to_tree(obs):\n",
    "    tree = SceneTree()\n",
    "    for obs_node in obs:\n",
    "        tree.add_node(obs_node)\n",
    "    return tree\n",
    "\n",
    "observed_nodes_unpacked = test_scene_autoenc.unpack_observed_nodes_batch(x)\n",
    "observed_nodes_autoencoded = test_scene_autoenc.unpack_observed_nodes_batch(x_recon)\n",
    "N = 5\n",
    "for k in range(N):\n",
    "    plt.subplot(3, N, k+1)\n",
    "    draw_boxes(make_observed_to_tree(observed_nodes_for_test[k]), fig=plt.gcf(), ax=plt.gca())\n",
    "    plt.subplot(3, N, k+N+1)\n",
    "    draw_boxes(make_observed_to_tree(observed_nodes_unpacked[k]), fig=plt.gcf(), ax=plt.gca())\n",
    "    plt.subplot(3, N, k+N+N+1)\n",
    "    draw_boxes(make_observed_to_tree(observed_nodes_autoencoded[k]), fig=plt.gcf(), ax=plt.gca())\n",
    "plt.tight_layout()\n",
    "print(\"Top row should match middle row, but probably not bottom row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  AutoencoderTrainingModule(\n",
      "  (grammar): SceneGrammar()\n",
      "  (scene_autoenc): ObservedSceneAutoencoder(\n",
      "    (encoder): GRU(8, 64, num_layers=3, batch_first=True)\n",
      "    (decoder): GRU(8, 64, num_layers=3, batch_first=True)\n",
      "    (decoder_common_head): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (decoder_vars_head): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (decoder_onehot_head): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=6, bias=True)\n",
      "      (1): Softmax(dim=None)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Make sure we can train the node embeddings on their own.\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "class AutoencoderTrainingModule(pl.LightningModule):\n",
    "    def __init__(self, grammar):\n",
    "        super().__init__()\n",
    "        self.grammar = grammar\n",
    "        self.context_size = 64\n",
    "        self.scene_autoenc = ObservedSceneAutoencoder(\n",
    "            grammar=grammar,\n",
    "            context_size=self.context_size\n",
    "        )\n",
    "\n",
    "    def forward(self, observed_nodes_batch):\n",
    "        x = self.scene_autoenc.pack_observed_nodes_batch(observed_nodes_batch)\n",
    "        z = self.scene_autoenc.encode(x)\n",
    "        x_pred = self.scene_autoenc.decode(z, target_x=x)\n",
    "        return x, z, x_pred\n",
    "        \n",
    "    def compute_loss(self, x, x_pred):\n",
    "        x_full, seq_lens = pad_packed_sequence(x, batch_first=True)\n",
    "        x_pred_full, pred_seq_lens = pad_packed_sequence(x_pred, batch_first=True)\n",
    "\n",
    "        # Up to the gt num_seqs, penalize error in the complete reconstructed x.\n",
    "        overlap = min(x_full.shape[1], x_pred_full.shape[1])\n",
    "        node_reconstruction_err = (x_full[:, :overlap, :] - x_pred_full[:, :overlap, :]).square().sum(dim=-1)\n",
    "        # Above that, penalize error from the \"stop\" vector.\n",
    "        stop_err = (x_pred_full - self.scene_autoenc.make_stop_vec()).square().sum(dim=-1)\n",
    "        total_recon_loss = 0.\n",
    "        total_stop_loss = 0.\n",
    "        for batch_k, seq_len in enumerate(seq_lens):\n",
    "            total_recon_loss = total_recon_loss + node_reconstruction_err[batch_k, :seq_len].sum()\n",
    "            total_stop_loss = total_stop_loss + stop_err[batch_k, seq_len].sum()\n",
    "        total_recon_loss = total_recon_loss / x_full.shape[0]\n",
    "        total_stop_loss = total_stop_loss / x_full.shape[0]\n",
    "        return total_recon_loss, total_stop_loss\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, observed_nodes_batch = batch\n",
    "        x, z, x_pred = self.forward(observed_nodes_batch)\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        recon_loss, stop_loss = self.compute_loss(x, x_pred)\n",
    "        metrics = {\"recon_loss\": recon_loss, \"stop_loss\": stop_loss, \"loss\": recon_loss + stop_loss}\n",
    "        self.log_dict(metrics)\n",
    "        return (recon_loss + stop_loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, observed_nodes_batch = batch\n",
    "        x, z, x_pred = self.forward(observed_nodes_batch)\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        recon_loss, stop_loss = self.compute_loss(x, x_pred)\n",
    "        metrics = {\"val_recon_loss\": recon_loss, \"val_stop_loss\": stop_loss, \"val_loss\": recon_loss + stop_loss}\n",
    "        self.log_dict(metrics)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, observed_nodes_batch = batch\n",
    "        x, z, x_pred = self.forward(observed_nodes_batch)\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        recon_loss, stop_loss = self.compute_loss(x, x_pred)\n",
    "        metrics = {\"test_recon_loss\": recon_loss, \"test_stop_loss\": stop_loss, \"test_loss\": recon_loss + stop_loss}\n",
    "        self.log_dict(metrics)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1E-2)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            'lr_scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5),\n",
    "            'monitor': 'loss'\n",
    "        }\n",
    "                                                  \n",
    "    \n",
    "retrain = False\n",
    "autoenc_model = AutoencoderTrainingModule(grammar)\n",
    "if retrain or not os.path.exists(\"saved_autoenc.ckpt\"):\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"target_env_autoenc\")\n",
    "    #logger = None\n",
    "    #lr_monitor = None\n",
    "    trainer = pl.Trainer(gpus=1, logger=logger, max_epochs=250, callbacks=[lr_monitor, early_stopping],\n",
    "                         gradient_clip_val=1.0, flush_logs_every_n_steps=5)\n",
    "    trainer.fit(autoenc_model, train_data_loader, val_data_loader)\n",
    "    trainer.test(test_dataloaders=dynamic_data_loader)\n",
    "    trainer.save_checkpoint(\"saved_autoenc.ckpt\")\n",
    "else:\n",
    "    autoenc_model = autoenc_model.load_from_checkpoint(checkpoint_path=\"saved_autoenc.ckpt\", grammar=grammar)\n",
    "    print(\"Loaded \", autoenc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'> <class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'>\n",
      "<class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'> <class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'>\n",
      "<class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'> <class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'>\n",
      "<class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'> <class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'>\n",
      "<class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'> <class 'spatial_scene_grammars_examples.planar_box_stacks_complex.grammar.Box'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = autoenc_model.scene_autoenc.pack_observed_nodes_batch(observed_nodes_for_test)\n",
    "z = autoenc_model.scene_autoenc.encode(x)\n",
    "x_recon = autoenc_model.scene_autoenc.decode(z)\n",
    "\n",
    "observed_nodes_unpacked = autoenc_model.scene_autoenc.unpack_observed_nodes_batch(x)\n",
    "observed_nodes_autoencoded = autoenc_model.scene_autoenc.unpack_observed_nodes_batch(x_recon)\n",
    "N = 5\n",
    "offset = 3\n",
    "for k in range(N):\n",
    "    plt.subplot(2, N, k+1)\n",
    "    draw_boxes(make_observed_to_tree(observed_nodes_for_test[offset+k]), fig=plt.gcf(), ax=plt.gca())\n",
    "    plt.subplot(2, N, k+N+1)\n",
    "    draw_boxes(make_observed_to_tree(observed_nodes_autoencoded[offset+k]), fig=plt.gcf(), ax=plt.gca())\n",
    "    print(type(observed_nodes_for_test[offset+k][0]), type(observed_nodes_autoencoded[offset+k][0]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the pilot network\n",
    "\n",
    "Uses scene autoencoder to get a context vector for the environment.\n",
    "\n",
    "For each node type, create an RNN that conditions on an instantiated node of that type + the full scene context, and produces a distribution over child nodes. The RNN output at each step is a (soft) one-hot output to select the output type from the node's list of child types, plus a \"stop\" symbol; and for each type, a vector of distribution parameters (gaussian mean field approx) for that node's derived and continuous attributes. The output node is sampled from that info, and the node details formed back into a vector and fed into the RNN as the next input in a seq2seq way.\n",
    "\n",
    "Training examples "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "py36_pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
