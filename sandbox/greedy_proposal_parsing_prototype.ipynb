{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "from spatial_scene_grammars.nodes import *\n",
    "from spatial_scene_grammars.rules import *\n",
    "from spatial_scene_grammars.scene_grammar import *\n",
    "from spatial_scene_grammars.parsing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Detaching BinghamDistribution parameters.\n",
      "WARNING:root:Prior over parameters of WorldFrameBinghamRotationRule are Deltas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed 8 objects\n",
      "Objects:  [<spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Root object at 0x7ff245005358>, <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Object object at 0x7ff245005f28>, <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Object object at 0x7ff245071898>, <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Object object at 0x7ff2450716d8>, <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Object object at 0x7ff245071a20>, <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Object object at 0x7ff245071a90>, <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Object object at 0x7ff245071b00>, <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Object object at 0x7ff245071b70>]\n"
     ]
    }
   ],
   "source": [
    "from spatial_scene_grammars_examples.singles_pairs.grammar_constituency import *\n",
    "#from spatial_scene_grammars_examples.singles_pairs.grammar_dependency import *\n",
    "pyro.set_rng_seed(42)\n",
    "\n",
    "grammar = SpatialSceneGrammar(\n",
    "    root_node_type = Root,\n",
    "    root_node_tf = torch.eye(4)\n",
    ")\n",
    "ground_truth_tree = grammar.sample_tree(detach=True)\n",
    "observed_nodes = ground_truth_tree.get_observed_nodes()\n",
    "print(\"Observed %d objects\" % len(observed_nodes))\n",
    "print(\"Objects: \", observed_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Singles object at 0x7ff2451f5f28> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Singles object at 0x7ff245097390> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Singles object at 0x7ff245097748> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Singles object at 0x7ff245097b70> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Singles object at 0x7ff245097f98> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Singles object at 0x7ff245208400> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Singles object at 0x7ff245208828> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2452089b0> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff245208a58> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff245208b00> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff245208ba8> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff245208d68> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff245208f28> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff245208fd0> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2451fb128> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2451fb400> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2451fb588> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2451fb6d8> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2451fb860> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2451fb9e8> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Candidate <spatial_scene_grammars_examples.singles_pairs.grammar_constituency.Pairs object at 0x7ff2451fbb70> with pose tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "5 top-down, 21 bottom-up candidates.\n"
     ]
    }
   ],
   "source": [
    "# Build up a big set of candidate intermediate nodes with both\n",
    "# top-down and bottom-up generation.\n",
    "candidate_intermediate_nodes = generate_candidate_intermediate_nodes(\n",
    "    grammar, observed_nodes, max_recursion_depth=10, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization success?:  True\n",
      "Logfile: \n",
      "\n",
      "Gurobi 9.0.2 (linux64) logging started Tue Nov 30 18:15:46 2021\n",
      "\n",
      "Gurobi Optimizer version 9.0.2 build v9.0.2rc0 (linux64)\n",
      "Optimize a model with 189 rows, 473 columns and 996 nonzeros\n",
      "Model fingerprint: 0x8f935942\n",
      "Variable types: 0 continuous, 473 integer (473 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [4e-01, 1e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 108 rows and 107 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 81 rows, 366 columns, 838 nonzeros\n",
      "Variable types: 0 continuous, 366 integer (366 binary)\n",
      "\n",
      "Root relaxation: objective 7.691758e+02, 132 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                     769.1758337   -2.98656   100%     -    0s\n",
      "     0     0     cutoff    0       769.17583  769.17583  0.00%     -    0s\n",
      "\n",
      "Explored 0 nodes (185 simplex iterations) in 0.01 seconds\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 769.176 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-03)\n",
      "Best objective 7.691758336805e+02, best bound 7.691758336805e+02, gap 0.0000%\n",
      "\n",
      "Building tree for sol 0...\n",
      "Parsing edge Root_2 --(0, score 0.000000)-> Singles_34\n",
      "Parsing edge Root_2 --(1, score 0.000000)-> Pairs_35\n",
      "Parsing edge Singles_34 --(2, score -9.543487)-> Object_1\n",
      "Parsing edge Singles_34 --(0, score -5.888394)-> Object_2\n",
      "Parsing edge Singles_34 --(1, score -6.061471)-> Object_3\n",
      "Parsing edge Pairs_35 --(1, score -8.182841)-> Pair_30\n",
      "Parsing edge Pairs_35 --(0, score -8.483766)-> Pair_31\n",
      "Parsing edge Pair_30 --(1, score -180.872134)-> Object_4\n",
      "Parsing edge Pair_30 --(0, score -187.887813)-> Object_5\n",
      "Parsing edge Pair_31 --(1, score -183.391901)-> Object_6\n",
      "Parsing edge Pair_31 --(0, score -175.779911)-> Object_7\n"
     ]
    }
   ],
   "source": [
    "parse_trees = infer_mle_tree_with_mip_from_proposals(\n",
    "    grammar, observed_nodes, candidate_intermediate_nodes, verbose=True, N_solutions=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "py36_pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
